[
  {
    "objectID": "r_basics.html",
    "href": "r_basics.html",
    "title": "Up and Running with R",
    "section": "",
    "text": "In this chapter, we’re going to get an introduction to the R language, so we can dive right into programming. We’re going to create a pair of virtual dice that can generate random numbers. No need to worry if you’re new to programming. We’ll return to many of the concepts here in more detail later.\nTo simulate a pair of dice, we need to break down each die into its essential features. A die can only show one of six numbers: 1, 2, 3, 4, 5, and 6. We can capture the die’s essential characteristics by saving these numbers as a group of values in the computer. Let’s save these numbers first and then figure out a way to “roll” our virtual die.\n\n\nThe RStudio interface is simple. You type R code into the bottom line of the RStudio console pane and then click Enter to run it. The code you type is called a command, because it will command your computer to do something for you. The line you type it into is called the command line.\n\n\n\n\n\n\nFigure 1: Your computer does your bidding when you type R commands at the prompt in the bottom line of the console pane. Don’t forget to hit the Enter key. When you first open RStudio, the console appears in the pane on your left, but you can change this with File &gt; Tools &gt; Global Options in the menu bar.\n\n\n\nWhen you type a command at the prompt and hit Enter, your computer executes the command and shows you the results. Then RStudio displays a fresh prompt for your next command. For example, if you type 1 + 1 and hit Enter, RStudio will display:\n&gt; 1 + 1\n[1] 2\n&gt;\nYou’ll notice that a [1] appears next to your result. R is just letting you know that this line begins with the first value in your result. Some commands return more than one value, and their results may fill up multiple lines. For example, the command 100:130 returns 31 values; it creates a sequence of integers from 100 to 130. Notice that new bracketed numbers appear at the start of the second and third lines of output. These numbers just mean that the second line begins with the 14th value in the result, and the third line begins with the 25th value. You can mostly ignore the numbers that appear in brackets:\n&gt; 100:130\n [1] 100 101 102 103 104 105 106 107 108 109 110 111 112\n[14] 113 114 115 116 117 118 119 120 121 122 123 124 125\n[25] 126 127 128 129 130\n\n\n\n\n\n\nTip\n\n\n\nThe colon operator (:) returns every integer between two integers. It is an easy way to create a sequence of numbers.\n\n\n\n\n\n\n\n\nWhen do we compile?\n\n\n\nIn some languages, like C, Java, and FORTRAN, you have to compile your human-readable code into machine-readable code (often 1s and 0s) before you can run it. If you’ve programmed in such a language before, you may wonder whether you have to compile your R code before you can use it. The answer is no. R is a dynamic programming language, which means R automatically interprets your code as you run it.\n\n\nIf you type an incomplete command and press Enter, R will display a + prompt, which means R is waiting for you to type the rest of your command. Either finish the command or hit Escape to start over:\n&gt; 5 -\n+\n+ 1\n[1] 4\nIf you type a command that R doesn’t recognize, R will return an error message. If you ever see an error message, don’t panic. R is just telling you that your computer couldn’t understand or do what you asked it to do. You can then try a different command at the next prompt:\n&gt; 3 % 5\nError: unexpected input in \"3 % 5\"\n&gt;\n\n\n\n\n\n\nTip\n\n\n\nWhenever you get an error message in R, consider googling the error message. You’ll often find that someone else has had the same problem and has posted a solution online. Simply cutting-and-pasting the error message into a search engine will often work\n\n\nOnce you get the hang of the command line, you can easily do anything in R that you would do with a calculator. For example, you could do some basic arithmetic:\n\n2 * 3   \n\n[1] 6\n\n4 - 1   \n\n[1] 3\n\n# this obeys order-of-operations\n6 / (4 - 1)   \n\n[1] 2\n\n\n\n\n\n\n\n\nTip\n\n\n\nR treats the hashtag character, #, in a special way; R will not run anything that follows a hashtag on a line. This makes hashtags very useful for adding comments and annotations to your code. Humans will be able to read the comments, but your computer will pass over them. The hashtag is known as the commenting symbol in R.\n\n\n\n\n\n\n\n\nCancelling commands\n\n\n\nSome R commands may take a long time to run. You can cancel a command once it has begun by pressing ctrl + c or by clicking the “stop sign” if it is available in Rstudio. Note that it may also take R a long time to cancel the command.\n\n\n\n\nThat’s the basic interface for executing R code in RStudio. Think you have it? If so, try doing these simple tasks. If you execute everything correctly, you should end up with the same number that you started with:\n\nChoose any number and add 2 to it.\nMultiply the result by 3.\nSubtract 6 from the answer.\nDivide what you get by 3.\n\n\n10 + 2\n\n[1] 12\n\n12 * 3\n\n[1] 36\n\n36 - 6\n\n[1] 30\n\n30 / 3\n\n[1] 10\n\n\n\n\n\n\nNow that you know how to use R, let’s use it to make a virtual die. The : operator from a couple of pages ago gives you a nice way to create a group of numbers from one to six. The : operator returns its results as a vector (we are going to work with vectors in more detail), a one-dimensional set of numbers:\n1:6\n## 1 2 3 4 5 6\nThat’s all there is to how a virtual die looks! But you are not done yet. Running 1:6 generated a vector of numbers for you to see, but it didn’t save that vector anywhere for later use. If we want to use those numbers again, we’ll have to ask your computer to save them somewhere. You can do that by creating an R object.\nR lets you save data by storing it inside an R object. What is an object? Just a name that you can use to call up stored data. For example, you can save data into an object like a or b. Wherever R encounters the object, it will replace it with the data saved inside, like so:\n\na &lt;- 1\na\n\n[1] 1\n\n\n\na + 2\n\n[1] 3\n\n\n\n\n\n\n\n\nWhat just happened?\n\n\n\n\nTo create an R object, choose a name and then use the less-than symbol, &lt;, followed by a minus sign, -, to save data into it. This combination looks like an arrow, &lt;-. R will make an object, give it your name, and store in it whatever follows the arrow. So a &lt;- 1 stores 1 in an object named a.\nWhen you ask R what’s in a, R tells you on the next line.\nYou can use your object in new R commands, too. Since a previously stored the value of 1, you’re now adding 1 to 2.\n\n\n\n\n\n\n\n\n\nAssignment vs expressions\n\n\n\nEverything that you type into the R console can be assigned to one of two categories:\n\nAssignments\nExpressions\n\nAn expression is a command that tells R to do something. For example, 1 + 2 is an expression that tells R to add 1 and 2. When you type an expression into the R console, R will evaluate the expression and return the result. For example, if you type 1 + 2 into the R console, R will return 3. Expressions can have “side effects” but they don’t explicitly result in anything being added to R memory.\n\n5 + 2\n\n[1] 7\n\n28 %% 3\n\n[1] 1\n\n3^2\n\n[1] 9\n\n5 + 4 * 4 + 4 ^ 4 / 10\n\n[1] 46.6\n\n\nWhile using R as a calculator is interesting, to do useful and interesting things, we need to assign values to objects. To create objects, we need to give it a name followed by the assignment operator &lt;- (or, entirely equivalently, =) and the value we want to give it:\n\nweight_kg &lt;- 55\n\n\n\nSo, for another example, the following code would create an object named die that contains the numbers one through six. To see what is stored in an object, just type the object’s name by itself:\n\ndie &lt;- 1:6\ndie\n\n[1] 1 2 3 4 5 6\n\n\nWhen you create an object, the object will appear in the environment pane of RStudio, as shown in Figure 2. This pane will show you all of the objects you’ve created since opening RStudio.\n\n\n\n\n\n\nFigure 2: Assignment creates an object in the environment pane.\n\n\n\nYou can name an object in R almost anything you want, but there are a few rules. First, a name cannot start with a number. Second, a name cannot use some special symbols, like ^, !, $, @, +, -, /, or *:\n\n\n\nGood names\nNames that cause errors\n\n\n\n\na\n1trial\n\n\nb\n$\n\n\nFOO\n^mean\n\n\nmy_var\n2nd\n\n\n.day\n!bad\n\n\n\n\n\n\n\n\n\nCapitalization matters\n\n\n\nR is case-sensitive, so name and Name will refer to different objects:\n&gt; Name = 0\n&gt; Name + 1\n[1] 1\n&gt; name + 1\nError: object 'name' not found\nThe error above is a common one!\n\n\nFinally, R will overwrite any previous information stored in an object without asking you for permission. So, it is a good idea to not use names that are already taken:\n\nmy_number &lt;- 1\nmy_number \n\n[1] 1\n\n\n\nmy_number &lt;- 999\nmy_number\n\n[1] 999\n\n\nYou can see which object names you have already used with the function ls:\nls()\nYour environment will contain different names than mine, because you have probably created different objects.\nYou can also see which names you have used by examining RStudio’s environment pane.\nWe now have a virtual die that is stored in the computer’s memory and which has a name that we can use to refer to it. You can access it whenever you like by typing the word die.\nSo what can you do with this die? Quite a lot. R will replace an object with its contents whenever the object’s name appears in a command. So, for example, you can do all sorts of math with the die. Math isn’t so helpful for rolling dice, but manipulating sets of numbers will be your stock and trade as a data scientist. So let’s take a look at how to do that:\n\ndie - 1\n\n[1] 0 1 2 3 4 5\n\ndie / 2\n\n[1] 0.5 1.0 1.5 2.0 2.5 3.0\n\ndie * die\n\n[1]  1  4  9 16 25 36\n\n\nR uses element-wise execution when working with a vector like die. When you manipulate a set of numbers, R will apply the same operation to each element in the set. So for example, when you run die - 1, R subtracts one from each element of die.\nWhen you use two or more vectors in an operation, R will line up the vectors and perform a sequence of individual operations. For example, when you run die * die, R lines up the two die vectors and then multiplies the first element of vector 1 by the first element of vector 2. R then multiplies the second element of vector 1 by the second element of vector 2, and so on, until every element has been multiplied. The result will be a new vector the same length as the first two {Figure 3}.\n\n\n\n\n\n\nFigure 3: “When R performs element-wise execution, it matches up vectors and then manipulates each pair of elements independently.”\n\n\n\nIf you give R two vectors of unequal lengths, R will repeat the shorter vector until it is as long as the longer vector, and then do the math, as shown in Figure 4. This isn’t a permanent change–the shorter vector will be its original size after R does the math. If the length of the short vector does not divide evenly into the length of the long vector, R will return a warning message. This behavior is known as vector recycling, and it helps R do element-wise operations:\n\n1:2\n\n[1] 1 2\n\n1:4\n\n[1] 1 2 3 4\n\ndie\n\n[1] 1 2 3 4 5 6\n\ndie + 1:2\n\n[1] 2 4 4 6 6 8\n\ndie + 1:4\n\nWarning in die + 1:4: longer object length is not a multiple of shorter object\nlength\n\n\n[1] 2 4 6 8 6 8\n\n\n\n\n\n\n\n\nFigure 4: “R will repeat a short vector to do element-wise operations with two vectors of uneven lengths.”\n\n\n\nElement-wise operations are a very useful feature in R because they manipulate groups of values in an orderly way. When you start working with data sets, element-wise operations will ensure that values from one observation or case are only paired with values from the same observation or case. Element-wise operations also make it easier to write your own programs and functions in R.\n\n\n\n\n\n\nElement-wise operations are not matrix operations\n\n\n\nIt is important to know that operations with vectors are not the same that you might expect if you are expecting R to perform “matrix” operations. R can do inner multiplication with the %*% operator and outer multiplication with the %o% operator:\n# Inner product (1*1 + 2*2 + 3*3 + 4*4 + 5*5 + 6*6)\ndie %*% die\n# Outer product\ndie %o% die\n\n\nNow that you can do math with your die object, let’s look at how you could “roll” it. Rolling your die will require something more sophisticated than basic arithmetic; you’ll need to randomly select one of the die’s values. And for that, you will need a function.\n\n\n\nR has many functions and puts them all at our disposal. We can use functions to do simple and sophisticated tasks. For example, we can round a number with the round function, or calculate its factorial with the factorial function. Using a function is pretty simple. Just write the name of the function and then the data you want the function to operate on in parentheses:\n\nround(3.1415)\n\n[1] 3\n\nfactorial(3)\n\n[1] 6\n\n\nThe data that you pass into the function is called the function’s argument. The argument can be raw data, an R object, or even the results of another R function. In this last case, R will work from the innermost function to the outermost Figure 5.\n\nmean(1:6)\n\n[1] 3.5\n\nmean(die)\n\n[1] 3.5\n\nround(mean(die))\n\n[1] 4\n\n\n\n\n\n\n\n\nFigure 5: “When you link functions together, R will resolve them from the innermost operation to the outermost. Here R first looks up die, then calculates the mean of one through six, then rounds the mean.”\n\n\n\nReturning to our die, we can use the sample function to randomly select one of the die’s values; in other words, the sample function can simulate rolling the die.\nThe sample function takes two arguments: a vector named x and a number named size. sample will return size elements from the vector:\n\nsample(x = 1:4, size = 2)\n\n[1] 1 2\n\n\nTo roll your die and get a number back, set x to die and sample one element from it. You’ll get a new (maybe different) number each time you roll it:\n\nsample(x = die, size = 1)\n\n[1] 5\n\nsample(x = die, size = 1)\n\n[1] 1\n\nsample(x = die, size = 1)\n\n[1] 4\n\n\nMany R functions take multiple arguments that help them do their job. You can give a function as many arguments as you like as long as you separate each argument with a comma.\nYou may have noticed that I set die and 1 equal to the names of the arguments in sample, x and size. Every argument in every R function has a name. You can specify which data should be assigned to which argument by setting a name equal to data, as in the preceding code. This becomes important as you begin to pass multiple arguments to the same function; names help you avoid passing the wrong data to the wrong argument. However, using names is optional. You will notice that R users do not often use the name of the first argument in a function. So you might see the previous code written as:\n\nsample(die, size = 1)\n\n[1] 1\n\n\nOften, the name of the first argument is not very descriptive, and it is usually obvious what the first piece of data refers to anyways.\nBut how do you know which argument names to use? If you try to use a name that a function does not expect, you will likely get an error:\nround(3.1415, corners = 2)\n## Error in round(3.1415, corners = 2) : unused argument(s) (corners = 2)\nIf you’re not sure which names to use with a function, you can look up the function’s arguments with args. To do this, place the name of the function in the parentheses behind args. For example, you can see that the round function takes two arguments, one named x and one named digits:\n\nargs(round)\n\nfunction (x, digits = 0, ...) \nNULL\n\n\nDid you notice that args shows that the digits argument of round is already set to 0? Frequently, an R function will take optional arguments like digits. These arguments are considered optional because they come with a default value. You can pass a new value to an optional argument if you want, and R will use the default value if you do not. For example, round will round your number to 0 digits past the decimal point by default. To override the default, supply your own value for digits:\n\nround(3.1415)\n\n[1] 3\n\nround(3.1415, digits = 2)\n\n[1] 3.14\n\n# pi happens to be a built-in value in R\npi\n\n[1] 3.141593\n\nround(pi)\n\n[1] 3\n\n\nYou should write out the names of each argument after the first one or two when you call a function with multiple arguments. Why? First, this will help you and others understand your code. It is usually obvious which argument your first input refers to (and sometimes the second input as well). However, you’d need a large memory to remember the third and fourth arguments of every R function. Second, and more importantly, writing out argument names prevents errors.\nIf you do not write out the names of your arguments, R will match your values to the arguments in your function by order. For example, in the following code, the first value, die, will be matched to the first argument of sample, which is named x. The next value, 1, will be matched to the next argument, size:\n\nsample(die, 1)\n\n[1] 3\n\n\nAs you provide more arguments, it becomes more likely that your order and R’s order may not align. As a result, values may get passed to the wrong argument. Argument names prevent this. R will always match a value to its argument name, no matter where it appears in the order of arguments:\n\nsample(size = 1, x = die)\n\n[1] 6\n\n\n\n\nIf you set size = 2, you can almost simulate a pair of dice. Before we run that code, think for a minute why that might be the case. sample will return two numbers, one for each die:\n\nsample(die, size = 2)\n\n[1] 5 4\n\n\nI said this “almost” works because this method does something funny. If you use it many times, you’ll notice that the second die never has the same value as the first die, which means you’ll never roll something like a pair of threes or snake eyes. What is going on?\nBy default, sample builds a sample without replacement. To see what this means, imagine that sample places all of the values of die in a jar or urn. Then imagine that sample reaches into the jar and pulls out values one by one to build its sample. Once a value has been drawn from the jar, sample sets it aside. The value doesn’t go back into the jar, so it cannot be drawn again. So if sample selects a six on its first draw, it will not be able to select a six on the second draw; six is no longer in the jar to be selected. Although sample creates its sample electronically, it follows this seemingly physical behavior.\nOne side effect of this behavior is that each draw depends on the draws that come before it. In the real world, however, when you roll a pair of dice, each die is independent of the other. If the first die comes up six, it does not prevent the second die from coming up six. In fact, it doesn’t influence the second die in any way whatsoever. You can recreate this behavior in sample by adding the argument replace = TRUE:\n\nsample(die, size = 2, replace = TRUE)\n\n[1] 5 3\n\n\nThe argument replace = TRUE causes sample to sample with replacement. Our jar example provides a good way to understand the difference between sampling with replacement and without. When sample uses replacement, it draws a value from the jar and records the value. Then it puts the value back into the jar. In other words, sample replaces each value after each draw. As a result, sample may select the same value on the second draw. Each value has a chance of being selected each time. It is as if every draw were the first draw.\nSampling with replacement is an easy way to create independent random samples. Each value in your sample will be a sample of size one that is independent of the other values. This is the correct way to simulate a pair of dice:\n\nsample(die, size = 2, replace = TRUE)\n\n[1] 2 4\n\n\nCongratulate yourself; you’ve just run your first simulation in R! You now have a method for simulating the result of rolling a pair of dice. If you want to add up the dice, you can feed your result straight into the sum function:\n\ndice &lt;- sample(die, size = 2, replace = TRUE)\ndice\n\n[1] 2 5\n\nsum(dice)\n\n[1] 7\n\n\nWhat would happen if you call dice multiple times? Would R generate a new pair of dice values each time? Let’s give it a try:\n\ndice\n\n[1] 2 5\n\ndice\n\n[1] 2 5\n\ndice\n\n[1] 2 5\n\n\nThe name dice refers to a vector of two numbers. Calling more than once does not change the favlue. Each time you call dice, R will show you the result of that one time you called sample and saved the output to dice. R won’t rerun sample(die, 2, replace = TRUE) to create a new roll of the dice. Once you save a set of results to an R object, those results do not change.\nHowever, it would be convenient to have an object that can re-roll the dice whenever you call it. You can make such an object by writing your own R function.\n\n\n\n\nTo recap, you already have working R code that simulates rolling a pair of dice:\n\ndie &lt;- 1:6\ndice &lt;- sample(die, size = 2, replace = TRUE)\nsum(dice)\n\n[1] 4\n\n\nYou can retype this code into the console anytime you want to re-roll your dice. However, this is an awkward way to work with the code. It would be easier to use your code if you wrapped it into its own function, which is exactly what we’ll do now. We’re going to write a function named roll that you can use to roll your virtual dice. When you’re finished, the function will work like this: each time you call roll(), R will return the sum of rolling two dice:\nroll()\n## 8 \n\nroll()\n## 3\n\nroll()\n## 7\nFunctions may seem mysterious or fancy, but they are just another type of R object. Instead of containing data, they contain code. This code is stored in a special format that makes it easy to reuse the code in new situations. You can write your own functions by recreating this format.\n\n\nEvery function in R has three basic parts: a name, a body of code, and a set of arguments. To make your own function, you need to replicate these parts and store them in an R object, which you can do with the function function. To do this, call function() and follow it with a pair of braces, {}:\n\nmy_function &lt;- function() {}\n\nThis function, as written, doesn’t do anything (yet). However, it is a valid function. You can call it by typing its name followed by an open and closed parenthesis:\n\nmy_function()\n\nNULL\n\n\nfunction will build a function out of whatever R code you place between the braces. For example, you can turn your dice code into a function by calling:\n\nroll &lt;- function() {\n  die &lt;- 1:6\n  dice &lt;- sample(die, size = 2, replace = TRUE)\n  sum(dice)\n}\n\n\n\n\n\n\n\nIndentation and readability\n\n\n\nNotice each line of code between the braces is indented. This makes the code easier to read but has no impact on how the code runs. R ignores spaces and line breaks and executes one complete expression at a time. Note that in other languages like python, spacing is extremely important and part of the language.\n\n\nJust hit the Enter key between each line after the first brace, {. R will wait for you to type the last brace, }, before it responds.\nDon’t forget to save the output of function to an R object. This object will become your new function. To use it, write the object’s name followed by an open and closed parenthesis:\n\nroll()\n\n[1] 8\n\n\nYou can think of the parentheses as the “trigger” that causes R to run the function. If you type in a function’s name without the parentheses, R will show you the code that is stored inside the function. If you type in the name with the parentheses, R will run that code:\n\nroll\n\nfunction() {\n  die &lt;- 1:6\n  dice &lt;- sample(die, size = 2, replace = TRUE)\n  sum(dice)\n}\n\nroll()\n\n[1] 12\n\n\nThe code that you place inside your function is known as the body of the function. When you run a function in R, R will execute all of the code in the body and then return the result of the last line of code. If the last line of code doesn’t return a value, neither will your function, so you want to ensure that your final line of code returns a value. One way to check this is to think about what would happen if you ran the body of code line by line in the command line. Would R display a result after the last line, or would it not?\nHere’s some code that would display a result:\ndice\n1 + 1\nsqrt(2)\nAnd here’s some code that would not:\ndice &lt;- sample(die, size = 2, replace = TRUE)\ntwo &lt;- 1 + 1\na &lt;- sqrt(2)\nAgain, this is just showing the distinction between expressions and assignments.\n\n\n\n\nWhat if we removed one line of code from our function and changed the name die to bones (just a name–don’t think of it as important), like this?\n\nroll2 &lt;- function() {\n  dice &lt;- sample(bones, size = 2, replace = TRUE)\n  sum(dice)\n}\n\nNow I’ll get an error when I run the function. The function needs the object bones to do its job, but there is no object named bones to be found (you can check by typing ls() which will show you the names in the environment, or memory).\nroll2()\n## Error in sample(bones, size = 2, replace = TRUE) : \n##   object 'bones' not found\nYou can supply bones when you call roll2 if you make bones an argument of the function. To do this, put the name bones in the parentheses that follow function when you define roll2:\n\nroll2 &lt;- function(bones) {\n  dice &lt;- sample(bones, size = 2, replace = TRUE)\n  sum(dice)\n}\n\nNow roll2 will work as long as you supply bones when you call the function. You can take advantage of this to roll different types of dice each time you call roll2.\nRemember, we’re rolling pairs of dice:\n\nroll2(bones = 1:4)\n\n[1] 3\n\nroll2(bones = 1:6)\n\n[1] 7\n\nroll2(1:20)\n\n[1] 34\n\n\nNotice that roll2 will still give an error if you do not supply a value for the bones argument when you call roll2:\nroll2()\n## Error in sample(bones, size = 2, replace = TRUE) : \n##   argument \"bones\" is missing, with no default\nYou can prevent this error by giving the bones argument a default value. To do this, set bones equal to a value when you define roll2:\n\nroll2 &lt;- function(bones = 1:6) {\n  dice &lt;- sample(bones, size = 2, replace = TRUE)\n  sum(dice)\n}\n\nNow you can supply a new value for bones if you like, and roll2 will use the default if you do not:\n\nroll2()\n\n[1] 7\n\n\nYou can give your functions as many arguments as you like. Just list their names, separated by commas, in the parentheses that follow function. When the function is run, R will replace each argument name in the function body with the value that the user supplies for the argument. If the user does not supply a value, R will replace the argument name with the argument’s default value (if you defined one).\nTo summarize, function helps you construct your own R functions. You create a body of code for your function to run by writing code between the braces that follow function. You create arguments for your function to use by supplying their names in the parentheses that follow function. Finally, you give your function a name by saving its output to an R object, as shown in Figure 6.\nOnce you’ve created your function, R will treat it like every other function in R. Think about how useful this is. Have you ever tried to create a new Excel option and add it to Microsoft’s menu bar? Or a new slide animation and add it to Powerpoint’s options? When you work with a programming language, you can do these types of things. As you learn to program in R, you will be able to create new, customized, reproducible tools for yourself whenever you like.\n\n\n\n\n\n\nFigure 6: “Every function in R has the same parts, and you can use function to create these parts. Assign the result to a name, so you can call the function later.”\n\n\n\n\n\n\nScripts are code that are saved for later reuse or editing. An R script is just a plain text file that you save R code in. You can open an R script in RStudio by going to File &gt; New File &gt; R script in the menu bar. RStudio will then open a fresh script above your console pane, as shown in Figure 7.\nI strongly encourage you to write and edit all of your R code in a script before you run it in the console. Why? This habit creates a reproducible record of your work. When you’re finished for the day, you can save your script and then use it to rerun your entire analysis the next day. Scripts are also very handy for editing and proofreading your code, and they make a nice copy of your work to share with others. To save a script, click the scripts pane, and then go to File &gt; Save As in the menu bar.\n\n\n\n\n\n\nFigure 7: “When you open an R Script (File &gt; New File &gt; R Script in the menu bar), RStudio creates a fourth pane (or puts a new tab in the existing pane) above the console where you can write and edit your code.”\n\n\n\nRStudio comes with many built-in features that make it easy to work with scripts. First, you can automatically execute a line of code in a script by clicking the Run button at the top of the editor panel.\nR will run whichever line of code your cursor is on. If you have a whole section highlighted, R will run the highlighted code. Alternatively, you can run the entire script by clicking the Source button. Don’t like clicking buttons? You can use Control + Return as a shortcut for the Run button. On Macs, that would be Command + Return.\nIf you’re not convinced about scripts, you soon will be. It becomes a pain to write multi-line code in the console’s single-line command line. Let’s avoid that headache and open your first script now before we move to the next chapter.\n\n\n\n\n\n\nTip\n\n\n\nExtract function\nRStudio comes with a tool that can help you build functions. To use it, highlight the lines of code in your R script that you want to turn into a function. Then click Code &gt; Extract Function in the menu bar. RStudio will ask you for a function name to use and then wrap your code in a function call. It will scan the code for undefined variables and use these as arguments.\nYou may want to double-check RStudio’s work. It assumes that your code is correct, so if it does something surprising, you may have a problem in your code.\n\n\n\n\n\nWe’ve covered a lot of ground already. You now have a virtual die stored in your computer’s memory, as well as your own R function that rolls a pair of dice. You’ve also begun speaking the R language.\nThe two most important components of the R language are objects, which store data, and functions, which manipulate data. R also uses a host of operators like +, -, *, /, and &lt;- to do basic tasks. As a data scientist, you will use R objects to store data in your computer’s memory, and you will use functions to automate tasks and do complicated calculations."
  },
  {
    "objectID": "r_basics.html#the-r-user-interface",
    "href": "r_basics.html#the-r-user-interface",
    "title": "Up and Running with R",
    "section": "",
    "text": "The RStudio interface is simple. You type R code into the bottom line of the RStudio console pane and then click Enter to run it. The code you type is called a command, because it will command your computer to do something for you. The line you type it into is called the command line.\n\n\n\n\n\n\nFigure 1: Your computer does your bidding when you type R commands at the prompt in the bottom line of the console pane. Don’t forget to hit the Enter key. When you first open RStudio, the console appears in the pane on your left, but you can change this with File &gt; Tools &gt; Global Options in the menu bar.\n\n\n\nWhen you type a command at the prompt and hit Enter, your computer executes the command and shows you the results. Then RStudio displays a fresh prompt for your next command. For example, if you type 1 + 1 and hit Enter, RStudio will display:\n&gt; 1 + 1\n[1] 2\n&gt;\nYou’ll notice that a [1] appears next to your result. R is just letting you know that this line begins with the first value in your result. Some commands return more than one value, and their results may fill up multiple lines. For example, the command 100:130 returns 31 values; it creates a sequence of integers from 100 to 130. Notice that new bracketed numbers appear at the start of the second and third lines of output. These numbers just mean that the second line begins with the 14th value in the result, and the third line begins with the 25th value. You can mostly ignore the numbers that appear in brackets:\n&gt; 100:130\n [1] 100 101 102 103 104 105 106 107 108 109 110 111 112\n[14] 113 114 115 116 117 118 119 120 121 122 123 124 125\n[25] 126 127 128 129 130\n\n\n\n\n\n\nTip\n\n\n\nThe colon operator (:) returns every integer between two integers. It is an easy way to create a sequence of numbers.\n\n\n\n\n\n\n\n\nWhen do we compile?\n\n\n\nIn some languages, like C, Java, and FORTRAN, you have to compile your human-readable code into machine-readable code (often 1s and 0s) before you can run it. If you’ve programmed in such a language before, you may wonder whether you have to compile your R code before you can use it. The answer is no. R is a dynamic programming language, which means R automatically interprets your code as you run it.\n\n\nIf you type an incomplete command and press Enter, R will display a + prompt, which means R is waiting for you to type the rest of your command. Either finish the command or hit Escape to start over:\n&gt; 5 -\n+\n+ 1\n[1] 4\nIf you type a command that R doesn’t recognize, R will return an error message. If you ever see an error message, don’t panic. R is just telling you that your computer couldn’t understand or do what you asked it to do. You can then try a different command at the next prompt:\n&gt; 3 % 5\nError: unexpected input in \"3 % 5\"\n&gt;\n\n\n\n\n\n\nTip\n\n\n\nWhenever you get an error message in R, consider googling the error message. You’ll often find that someone else has had the same problem and has posted a solution online. Simply cutting-and-pasting the error message into a search engine will often work\n\n\nOnce you get the hang of the command line, you can easily do anything in R that you would do with a calculator. For example, you could do some basic arithmetic:\n\n2 * 3   \n\n[1] 6\n\n4 - 1   \n\n[1] 3\n\n# this obeys order-of-operations\n6 / (4 - 1)   \n\n[1] 2\n\n\n\n\n\n\n\n\nTip\n\n\n\nR treats the hashtag character, #, in a special way; R will not run anything that follows a hashtag on a line. This makes hashtags very useful for adding comments and annotations to your code. Humans will be able to read the comments, but your computer will pass over them. The hashtag is known as the commenting symbol in R.\n\n\n\n\n\n\n\n\nCancelling commands\n\n\n\nSome R commands may take a long time to run. You can cancel a command once it has begun by pressing ctrl + c or by clicking the “stop sign” if it is available in Rstudio. Note that it may also take R a long time to cancel the command.\n\n\n\n\nThat’s the basic interface for executing R code in RStudio. Think you have it? If so, try doing these simple tasks. If you execute everything correctly, you should end up with the same number that you started with:\n\nChoose any number and add 2 to it.\nMultiply the result by 3.\nSubtract 6 from the answer.\nDivide what you get by 3.\n\n\n10 + 2\n\n[1] 12\n\n12 * 3\n\n[1] 36\n\n36 - 6\n\n[1] 30\n\n30 / 3\n\n[1] 10"
  },
  {
    "objectID": "r_basics.html#objects",
    "href": "r_basics.html#objects",
    "title": "Up and Running with R",
    "section": "",
    "text": "Now that you know how to use R, let’s use it to make a virtual die. The : operator from a couple of pages ago gives you a nice way to create a group of numbers from one to six. The : operator returns its results as a vector (we are going to work with vectors in more detail), a one-dimensional set of numbers:\n1:6\n## 1 2 3 4 5 6\nThat’s all there is to how a virtual die looks! But you are not done yet. Running 1:6 generated a vector of numbers for you to see, but it didn’t save that vector anywhere for later use. If we want to use those numbers again, we’ll have to ask your computer to save them somewhere. You can do that by creating an R object.\nR lets you save data by storing it inside an R object. What is an object? Just a name that you can use to call up stored data. For example, you can save data into an object like a or b. Wherever R encounters the object, it will replace it with the data saved inside, like so:\n\na &lt;- 1\na\n\n[1] 1\n\n\n\na + 2\n\n[1] 3\n\n\n\n\n\n\n\n\nWhat just happened?\n\n\n\n\nTo create an R object, choose a name and then use the less-than symbol, &lt;, followed by a minus sign, -, to save data into it. This combination looks like an arrow, &lt;-. R will make an object, give it your name, and store in it whatever follows the arrow. So a &lt;- 1 stores 1 in an object named a.\nWhen you ask R what’s in a, R tells you on the next line.\nYou can use your object in new R commands, too. Since a previously stored the value of 1, you’re now adding 1 to 2.\n\n\n\n\n\n\n\n\n\nAssignment vs expressions\n\n\n\nEverything that you type into the R console can be assigned to one of two categories:\n\nAssignments\nExpressions\n\nAn expression is a command that tells R to do something. For example, 1 + 2 is an expression that tells R to add 1 and 2. When you type an expression into the R console, R will evaluate the expression and return the result. For example, if you type 1 + 2 into the R console, R will return 3. Expressions can have “side effects” but they don’t explicitly result in anything being added to R memory.\n\n5 + 2\n\n[1] 7\n\n28 %% 3\n\n[1] 1\n\n3^2\n\n[1] 9\n\n5 + 4 * 4 + 4 ^ 4 / 10\n\n[1] 46.6\n\n\nWhile using R as a calculator is interesting, to do useful and interesting things, we need to assign values to objects. To create objects, we need to give it a name followed by the assignment operator &lt;- (or, entirely equivalently, =) and the value we want to give it:\n\nweight_kg &lt;- 55\n\n\n\nSo, for another example, the following code would create an object named die that contains the numbers one through six. To see what is stored in an object, just type the object’s name by itself:\n\ndie &lt;- 1:6\ndie\n\n[1] 1 2 3 4 5 6\n\n\nWhen you create an object, the object will appear in the environment pane of RStudio, as shown in Figure 2. This pane will show you all of the objects you’ve created since opening RStudio.\n\n\n\n\n\n\nFigure 2: Assignment creates an object in the environment pane.\n\n\n\nYou can name an object in R almost anything you want, but there are a few rules. First, a name cannot start with a number. Second, a name cannot use some special symbols, like ^, !, $, @, +, -, /, or *:\n\n\n\nGood names\nNames that cause errors\n\n\n\n\na\n1trial\n\n\nb\n$\n\n\nFOO\n^mean\n\n\nmy_var\n2nd\n\n\n.day\n!bad\n\n\n\n\n\n\n\n\n\nCapitalization matters\n\n\n\nR is case-sensitive, so name and Name will refer to different objects:\n&gt; Name = 0\n&gt; Name + 1\n[1] 1\n&gt; name + 1\nError: object 'name' not found\nThe error above is a common one!\n\n\nFinally, R will overwrite any previous information stored in an object without asking you for permission. So, it is a good idea to not use names that are already taken:\n\nmy_number &lt;- 1\nmy_number \n\n[1] 1\n\n\n\nmy_number &lt;- 999\nmy_number\n\n[1] 999\n\n\nYou can see which object names you have already used with the function ls:\nls()\nYour environment will contain different names than mine, because you have probably created different objects.\nYou can also see which names you have used by examining RStudio’s environment pane.\nWe now have a virtual die that is stored in the computer’s memory and which has a name that we can use to refer to it. You can access it whenever you like by typing the word die.\nSo what can you do with this die? Quite a lot. R will replace an object with its contents whenever the object’s name appears in a command. So, for example, you can do all sorts of math with the die. Math isn’t so helpful for rolling dice, but manipulating sets of numbers will be your stock and trade as a data scientist. So let’s take a look at how to do that:\n\ndie - 1\n\n[1] 0 1 2 3 4 5\n\ndie / 2\n\n[1] 0.5 1.0 1.5 2.0 2.5 3.0\n\ndie * die\n\n[1]  1  4  9 16 25 36\n\n\nR uses element-wise execution when working with a vector like die. When you manipulate a set of numbers, R will apply the same operation to each element in the set. So for example, when you run die - 1, R subtracts one from each element of die.\nWhen you use two or more vectors in an operation, R will line up the vectors and perform a sequence of individual operations. For example, when you run die * die, R lines up the two die vectors and then multiplies the first element of vector 1 by the first element of vector 2. R then multiplies the second element of vector 1 by the second element of vector 2, and so on, until every element has been multiplied. The result will be a new vector the same length as the first two {Figure 3}.\n\n\n\n\n\n\nFigure 3: “When R performs element-wise execution, it matches up vectors and then manipulates each pair of elements independently.”\n\n\n\nIf you give R two vectors of unequal lengths, R will repeat the shorter vector until it is as long as the longer vector, and then do the math, as shown in Figure 4. This isn’t a permanent change–the shorter vector will be its original size after R does the math. If the length of the short vector does not divide evenly into the length of the long vector, R will return a warning message. This behavior is known as vector recycling, and it helps R do element-wise operations:\n\n1:2\n\n[1] 1 2\n\n1:4\n\n[1] 1 2 3 4\n\ndie\n\n[1] 1 2 3 4 5 6\n\ndie + 1:2\n\n[1] 2 4 4 6 6 8\n\ndie + 1:4\n\nWarning in die + 1:4: longer object length is not a multiple of shorter object\nlength\n\n\n[1] 2 4 6 8 6 8\n\n\n\n\n\n\n\n\nFigure 4: “R will repeat a short vector to do element-wise operations with two vectors of uneven lengths.”\n\n\n\nElement-wise operations are a very useful feature in R because they manipulate groups of values in an orderly way. When you start working with data sets, element-wise operations will ensure that values from one observation or case are only paired with values from the same observation or case. Element-wise operations also make it easier to write your own programs and functions in R.\n\n\n\n\n\n\nElement-wise operations are not matrix operations\n\n\n\nIt is important to know that operations with vectors are not the same that you might expect if you are expecting R to perform “matrix” operations. R can do inner multiplication with the %*% operator and outer multiplication with the %o% operator:\n# Inner product (1*1 + 2*2 + 3*3 + 4*4 + 5*5 + 6*6)\ndie %*% die\n# Outer product\ndie %o% die\n\n\nNow that you can do math with your die object, let’s look at how you could “roll” it. Rolling your die will require something more sophisticated than basic arithmetic; you’ll need to randomly select one of the die’s values. And for that, you will need a function."
  },
  {
    "objectID": "r_basics.html#functions",
    "href": "r_basics.html#functions",
    "title": "Up and Running with R",
    "section": "",
    "text": "R has many functions and puts them all at our disposal. We can use functions to do simple and sophisticated tasks. For example, we can round a number with the round function, or calculate its factorial with the factorial function. Using a function is pretty simple. Just write the name of the function and then the data you want the function to operate on in parentheses:\n\nround(3.1415)\n\n[1] 3\n\nfactorial(3)\n\n[1] 6\n\n\nThe data that you pass into the function is called the function’s argument. The argument can be raw data, an R object, or even the results of another R function. In this last case, R will work from the innermost function to the outermost Figure 5.\n\nmean(1:6)\n\n[1] 3.5\n\nmean(die)\n\n[1] 3.5\n\nround(mean(die))\n\n[1] 4\n\n\n\n\n\n\n\n\nFigure 5: “When you link functions together, R will resolve them from the innermost operation to the outermost. Here R first looks up die, then calculates the mean of one through six, then rounds the mean.”\n\n\n\nReturning to our die, we can use the sample function to randomly select one of the die’s values; in other words, the sample function can simulate rolling the die.\nThe sample function takes two arguments: a vector named x and a number named size. sample will return size elements from the vector:\n\nsample(x = 1:4, size = 2)\n\n[1] 1 2\n\n\nTo roll your die and get a number back, set x to die and sample one element from it. You’ll get a new (maybe different) number each time you roll it:\n\nsample(x = die, size = 1)\n\n[1] 5\n\nsample(x = die, size = 1)\n\n[1] 1\n\nsample(x = die, size = 1)\n\n[1] 4\n\n\nMany R functions take multiple arguments that help them do their job. You can give a function as many arguments as you like as long as you separate each argument with a comma.\nYou may have noticed that I set die and 1 equal to the names of the arguments in sample, x and size. Every argument in every R function has a name. You can specify which data should be assigned to which argument by setting a name equal to data, as in the preceding code. This becomes important as you begin to pass multiple arguments to the same function; names help you avoid passing the wrong data to the wrong argument. However, using names is optional. You will notice that R users do not often use the name of the first argument in a function. So you might see the previous code written as:\n\nsample(die, size = 1)\n\n[1] 1\n\n\nOften, the name of the first argument is not very descriptive, and it is usually obvious what the first piece of data refers to anyways.\nBut how do you know which argument names to use? If you try to use a name that a function does not expect, you will likely get an error:\nround(3.1415, corners = 2)\n## Error in round(3.1415, corners = 2) : unused argument(s) (corners = 2)\nIf you’re not sure which names to use with a function, you can look up the function’s arguments with args. To do this, place the name of the function in the parentheses behind args. For example, you can see that the round function takes two arguments, one named x and one named digits:\n\nargs(round)\n\nfunction (x, digits = 0, ...) \nNULL\n\n\nDid you notice that args shows that the digits argument of round is already set to 0? Frequently, an R function will take optional arguments like digits. These arguments are considered optional because they come with a default value. You can pass a new value to an optional argument if you want, and R will use the default value if you do not. For example, round will round your number to 0 digits past the decimal point by default. To override the default, supply your own value for digits:\n\nround(3.1415)\n\n[1] 3\n\nround(3.1415, digits = 2)\n\n[1] 3.14\n\n# pi happens to be a built-in value in R\npi\n\n[1] 3.141593\n\nround(pi)\n\n[1] 3\n\n\nYou should write out the names of each argument after the first one or two when you call a function with multiple arguments. Why? First, this will help you and others understand your code. It is usually obvious which argument your first input refers to (and sometimes the second input as well). However, you’d need a large memory to remember the third and fourth arguments of every R function. Second, and more importantly, writing out argument names prevents errors.\nIf you do not write out the names of your arguments, R will match your values to the arguments in your function by order. For example, in the following code, the first value, die, will be matched to the first argument of sample, which is named x. The next value, 1, will be matched to the next argument, size:\n\nsample(die, 1)\n\n[1] 3\n\n\nAs you provide more arguments, it becomes more likely that your order and R’s order may not align. As a result, values may get passed to the wrong argument. Argument names prevent this. R will always match a value to its argument name, no matter where it appears in the order of arguments:\n\nsample(size = 1, x = die)\n\n[1] 6\n\n\n\n\nIf you set size = 2, you can almost simulate a pair of dice. Before we run that code, think for a minute why that might be the case. sample will return two numbers, one for each die:\n\nsample(die, size = 2)\n\n[1] 5 4\n\n\nI said this “almost” works because this method does something funny. If you use it many times, you’ll notice that the second die never has the same value as the first die, which means you’ll never roll something like a pair of threes or snake eyes. What is going on?\nBy default, sample builds a sample without replacement. To see what this means, imagine that sample places all of the values of die in a jar or urn. Then imagine that sample reaches into the jar and pulls out values one by one to build its sample. Once a value has been drawn from the jar, sample sets it aside. The value doesn’t go back into the jar, so it cannot be drawn again. So if sample selects a six on its first draw, it will not be able to select a six on the second draw; six is no longer in the jar to be selected. Although sample creates its sample electronically, it follows this seemingly physical behavior.\nOne side effect of this behavior is that each draw depends on the draws that come before it. In the real world, however, when you roll a pair of dice, each die is independent of the other. If the first die comes up six, it does not prevent the second die from coming up six. In fact, it doesn’t influence the second die in any way whatsoever. You can recreate this behavior in sample by adding the argument replace = TRUE:\n\nsample(die, size = 2, replace = TRUE)\n\n[1] 5 3\n\n\nThe argument replace = TRUE causes sample to sample with replacement. Our jar example provides a good way to understand the difference between sampling with replacement and without. When sample uses replacement, it draws a value from the jar and records the value. Then it puts the value back into the jar. In other words, sample replaces each value after each draw. As a result, sample may select the same value on the second draw. Each value has a chance of being selected each time. It is as if every draw were the first draw.\nSampling with replacement is an easy way to create independent random samples. Each value in your sample will be a sample of size one that is independent of the other values. This is the correct way to simulate a pair of dice:\n\nsample(die, size = 2, replace = TRUE)\n\n[1] 2 4\n\n\nCongratulate yourself; you’ve just run your first simulation in R! You now have a method for simulating the result of rolling a pair of dice. If you want to add up the dice, you can feed your result straight into the sum function:\n\ndice &lt;- sample(die, size = 2, replace = TRUE)\ndice\n\n[1] 2 5\n\nsum(dice)\n\n[1] 7\n\n\nWhat would happen if you call dice multiple times? Would R generate a new pair of dice values each time? Let’s give it a try:\n\ndice\n\n[1] 2 5\n\ndice\n\n[1] 2 5\n\ndice\n\n[1] 2 5\n\n\nThe name dice refers to a vector of two numbers. Calling more than once does not change the favlue. Each time you call dice, R will show you the result of that one time you called sample and saved the output to dice. R won’t rerun sample(die, 2, replace = TRUE) to create a new roll of the dice. Once you save a set of results to an R object, those results do not change.\nHowever, it would be convenient to have an object that can re-roll the dice whenever you call it. You can make such an object by writing your own R function."
  },
  {
    "objectID": "r_basics.html#write-functions",
    "href": "r_basics.html#write-functions",
    "title": "Up and Running with R",
    "section": "",
    "text": "To recap, you already have working R code that simulates rolling a pair of dice:\n\ndie &lt;- 1:6\ndice &lt;- sample(die, size = 2, replace = TRUE)\nsum(dice)\n\n[1] 4\n\n\nYou can retype this code into the console anytime you want to re-roll your dice. However, this is an awkward way to work with the code. It would be easier to use your code if you wrapped it into its own function, which is exactly what we’ll do now. We’re going to write a function named roll that you can use to roll your virtual dice. When you’re finished, the function will work like this: each time you call roll(), R will return the sum of rolling two dice:\nroll()\n## 8 \n\nroll()\n## 3\n\nroll()\n## 7\nFunctions may seem mysterious or fancy, but they are just another type of R object. Instead of containing data, they contain code. This code is stored in a special format that makes it easy to reuse the code in new situations. You can write your own functions by recreating this format.\n\n\nEvery function in R has three basic parts: a name, a body of code, and a set of arguments. To make your own function, you need to replicate these parts and store them in an R object, which you can do with the function function. To do this, call function() and follow it with a pair of braces, {}:\n\nmy_function &lt;- function() {}\n\nThis function, as written, doesn’t do anything (yet). However, it is a valid function. You can call it by typing its name followed by an open and closed parenthesis:\n\nmy_function()\n\nNULL\n\n\nfunction will build a function out of whatever R code you place between the braces. For example, you can turn your dice code into a function by calling:\n\nroll &lt;- function() {\n  die &lt;- 1:6\n  dice &lt;- sample(die, size = 2, replace = TRUE)\n  sum(dice)\n}\n\n\n\n\n\n\n\nIndentation and readability\n\n\n\nNotice each line of code between the braces is indented. This makes the code easier to read but has no impact on how the code runs. R ignores spaces and line breaks and executes one complete expression at a time. Note that in other languages like python, spacing is extremely important and part of the language.\n\n\nJust hit the Enter key between each line after the first brace, {. R will wait for you to type the last brace, }, before it responds.\nDon’t forget to save the output of function to an R object. This object will become your new function. To use it, write the object’s name followed by an open and closed parenthesis:\n\nroll()\n\n[1] 8\n\n\nYou can think of the parentheses as the “trigger” that causes R to run the function. If you type in a function’s name without the parentheses, R will show you the code that is stored inside the function. If you type in the name with the parentheses, R will run that code:\n\nroll\n\nfunction() {\n  die &lt;- 1:6\n  dice &lt;- sample(die, size = 2, replace = TRUE)\n  sum(dice)\n}\n\nroll()\n\n[1] 12\n\n\nThe code that you place inside your function is known as the body of the function. When you run a function in R, R will execute all of the code in the body and then return the result of the last line of code. If the last line of code doesn’t return a value, neither will your function, so you want to ensure that your final line of code returns a value. One way to check this is to think about what would happen if you ran the body of code line by line in the command line. Would R display a result after the last line, or would it not?\nHere’s some code that would display a result:\ndice\n1 + 1\nsqrt(2)\nAnd here’s some code that would not:\ndice &lt;- sample(die, size = 2, replace = TRUE)\ntwo &lt;- 1 + 1\na &lt;- sqrt(2)\nAgain, this is just showing the distinction between expressions and assignments."
  },
  {
    "objectID": "r_basics.html#arguments",
    "href": "r_basics.html#arguments",
    "title": "Up and Running with R",
    "section": "",
    "text": "What if we removed one line of code from our function and changed the name die to bones (just a name–don’t think of it as important), like this?\n\nroll2 &lt;- function() {\n  dice &lt;- sample(bones, size = 2, replace = TRUE)\n  sum(dice)\n}\n\nNow I’ll get an error when I run the function. The function needs the object bones to do its job, but there is no object named bones to be found (you can check by typing ls() which will show you the names in the environment, or memory).\nroll2()\n## Error in sample(bones, size = 2, replace = TRUE) : \n##   object 'bones' not found\nYou can supply bones when you call roll2 if you make bones an argument of the function. To do this, put the name bones in the parentheses that follow function when you define roll2:\n\nroll2 &lt;- function(bones) {\n  dice &lt;- sample(bones, size = 2, replace = TRUE)\n  sum(dice)\n}\n\nNow roll2 will work as long as you supply bones when you call the function. You can take advantage of this to roll different types of dice each time you call roll2.\nRemember, we’re rolling pairs of dice:\n\nroll2(bones = 1:4)\n\n[1] 3\n\nroll2(bones = 1:6)\n\n[1] 7\n\nroll2(1:20)\n\n[1] 34\n\n\nNotice that roll2 will still give an error if you do not supply a value for the bones argument when you call roll2:\nroll2()\n## Error in sample(bones, size = 2, replace = TRUE) : \n##   argument \"bones\" is missing, with no default\nYou can prevent this error by giving the bones argument a default value. To do this, set bones equal to a value when you define roll2:\n\nroll2 &lt;- function(bones = 1:6) {\n  dice &lt;- sample(bones, size = 2, replace = TRUE)\n  sum(dice)\n}\n\nNow you can supply a new value for bones if you like, and roll2 will use the default if you do not:\n\nroll2()\n\n[1] 7\n\n\nYou can give your functions as many arguments as you like. Just list their names, separated by commas, in the parentheses that follow function. When the function is run, R will replace each argument name in the function body with the value that the user supplies for the argument. If the user does not supply a value, R will replace the argument name with the argument’s default value (if you defined one).\nTo summarize, function helps you construct your own R functions. You create a body of code for your function to run by writing code between the braces that follow function. You create arguments for your function to use by supplying their names in the parentheses that follow function. Finally, you give your function a name by saving its output to an R object, as shown in Figure 6.\nOnce you’ve created your function, R will treat it like every other function in R. Think about how useful this is. Have you ever tried to create a new Excel option and add it to Microsoft’s menu bar? Or a new slide animation and add it to Powerpoint’s options? When you work with a programming language, you can do these types of things. As you learn to program in R, you will be able to create new, customized, reproducible tools for yourself whenever you like.\n\n\n\n\n\n\nFigure 6: “Every function in R has the same parts, and you can use function to create these parts. Assign the result to a name, so you can call the function later.”"
  },
  {
    "objectID": "r_basics.html#scripts",
    "href": "r_basics.html#scripts",
    "title": "Up and Running with R",
    "section": "",
    "text": "Scripts are code that are saved for later reuse or editing. An R script is just a plain text file that you save R code in. You can open an R script in RStudio by going to File &gt; New File &gt; R script in the menu bar. RStudio will then open a fresh script above your console pane, as shown in Figure 7.\nI strongly encourage you to write and edit all of your R code in a script before you run it in the console. Why? This habit creates a reproducible record of your work. When you’re finished for the day, you can save your script and then use it to rerun your entire analysis the next day. Scripts are also very handy for editing and proofreading your code, and they make a nice copy of your work to share with others. To save a script, click the scripts pane, and then go to File &gt; Save As in the menu bar.\n\n\n\n\n\n\nFigure 7: “When you open an R Script (File &gt; New File &gt; R Script in the menu bar), RStudio creates a fourth pane (or puts a new tab in the existing pane) above the console where you can write and edit your code.”\n\n\n\nRStudio comes with many built-in features that make it easy to work with scripts. First, you can automatically execute a line of code in a script by clicking the Run button at the top of the editor panel.\nR will run whichever line of code your cursor is on. If you have a whole section highlighted, R will run the highlighted code. Alternatively, you can run the entire script by clicking the Source button. Don’t like clicking buttons? You can use Control + Return as a shortcut for the Run button. On Macs, that would be Command + Return.\nIf you’re not convinced about scripts, you soon will be. It becomes a pain to write multi-line code in the console’s single-line command line. Let’s avoid that headache and open your first script now before we move to the next chapter.\n\n\n\n\n\n\nTip\n\n\n\nExtract function\nRStudio comes with a tool that can help you build functions. To use it, highlight the lines of code in your R script that you want to turn into a function. Then click Code &gt; Extract Function in the menu bar. RStudio will ask you for a function name to use and then wrap your code in a function call. It will scan the code for undefined variables and use these as arguments.\nYou may want to double-check RStudio’s work. It assumes that your code is correct, so if it does something surprising, you may have a problem in your code."
  },
  {
    "objectID": "r_basics.html#summary",
    "href": "r_basics.html#summary",
    "title": "Up and Running with R",
    "section": "",
    "text": "We’ve covered a lot of ground already. You now have a virtual die stored in your computer’s memory, as well as your own R function that rolls a pair of dice. You’ve also begun speaking the R language.\nThe two most important components of the R language are objects, which store data, and functions, which manipulate data. R also uses a host of operators like +, -, *, /, and &lt;- to do basic tasks. As a data scientist, you will use R objects to store data in your computer’s memory, and you will use functions to automate tasks and do complicated calculations."
  },
  {
    "objectID": "book/references.html",
    "href": "book/references.html",
    "title": "References",
    "section": "",
    "text": "References\n\n\n\n\n\n\n\nCitationBibTeX citation:@online{davis,\n  author = {Davis, Sean},\n  url = {https://seandavi.github.io/IDPT-8079/book/references.html},\n  langid = {en}\n}\nFor attribution, please cite this work as:\nDavis, Sean. n.d. https://seandavi.github.io/IDPT-8079/book/references.html."
  },
  {
    "objectID": "book/summary.html",
    "href": "book/summary.html",
    "title": "Summary",
    "section": "",
    "text": "Summary\nIn summary, this book has no content whatsoever.\n\n\n\n\nCitationBibTeX citation:@online{davis,\n  author = {Davis, Sean},\n  url = {https://seandavi.github.io/IDPT-8079/book/summary.html},\n  langid = {en}\n}\nFor attribution, please cite this work as:\nDavis, Sean. n.d. https://seandavi.github.io/IDPT-8079/book/summary.html."
  },
  {
    "objectID": "book/attic-learning-objectives-by-chapter.html",
    "href": "book/attic-learning-objectives-by-chapter.html",
    "title": "IDPT-8079: Frontier of AI in Medicine",
    "section": "",
    "text": "Certainly! Below is a set of learning objectives for each of the proposed chapters, designed to ensure distinct material while reinforcing key concepts across chapters. These objectives build on each other, with earlier chapters laying the groundwork for more complex material in later chapters.\n\n\nChapter 1: Introduction to Machine Learning in Medicine\nThis chapter serves as an introduction to the fundamental concepts of machine learning, focusing on its relevance and application in healthcare.\nLearning Objectives:\n\nDefine machine learning and its main types (supervised, unsupervised, and reinforcement learning).\nUnderstand the importance of machine learning in healthcare, including its role in diagnostics, prognosis, and patient management.\nExplain key machine learning tasks such as classification, regression, and clustering.\nRecognize real-world applications of machine learning in medical imaging, patient segmentation, and predictive analytics.\nIdentify challenges associated with using machine learning in medicine, such as data quality, bias, and interpretability.\n\n\n\n\nChapter 2: Supervised Learning\nThis chapter covers the most common type of machine learning, where the model learns from labeled data, focusing on its medical applications.\nLearning Objectives:\n\nExplain the concept of supervised learning and the distinction between classification and regression tasks.\nIdentify key supervised learning algorithms such as decision trees, support vector machines, and k-nearest neighbors, and their relevance to medicine.\nUnderstand how supervised learning is used for disease diagnosis, risk prediction, and clinical decision-making.\nExplore practical examples of supervised learning, such as classifying medical images or predicting disease onset from patient records.\nEvaluate supervised learning models based on performance metrics like accuracy, sensitivity, specificity, and AUC (area under the curve).\n\n\n\n\nChapter 3: Unsupervised Learning\nThis chapter explores unsupervised learning, which finds hidden patterns in unlabeled data, and its applications in healthcare research.\nLearning Objectives:\n\nDefine unsupervised learning and differentiate it from supervised learning.\nUnderstand the principles behind clustering algorithms (e.g., k-means, hierarchical clustering) and dimensionality reduction techniques (e.g., PCA).\nExplain how unsupervised learning is used in patient stratification, disease subtype discovery, and exploratory data analysis.\nIllustrate how unsupervised learning can reduce the complexity of medical datasets, such as in genomics or imaging.\nRecognize the challenges and limitations of unsupervised learning, including interpretability and the potential for spurious patterns.\n\n\n\n\nChapter 4: Model Evaluation and Validation\nThis chapter delves into how to assess the performance of machine learning models, a critical step before clinical deployment.\nLearning Objectives:\n\nExplain the importance of model evaluation and the concept of generalizability in machine learning.\nUnderstand performance metrics such as accuracy, precision, recall, F1-score, sensitivity, and specificity, and how they apply to medical models.\nExplore the importance of cross-validation and test-train splits in preventing overfitting and ensuring model robustness.\nDefine bias-variance tradeoff and its impact on model performance.\nDiscuss how model evaluation must align with clinical goals, such as prioritizing sensitivity for life-threatening conditions and specificity for screening.\n\n\n\n\nChapter 5: Deep Learning in Medicine\nThis chapter introduces deep learning, a subfield of machine learning that excels in handling complex, high-dimensional data such as medical images.\nLearning Objectives:\n\nDefine deep learning and understand the basic architecture of neural networks, including the role of layers and activation functions.\nExplain how convolutional neural networks (CNNs) are used in image-based tasks such as radiology and pathology.\nUnderstand how recurrent neural networks (RNNs) are applied to sequential medical data, such as time-series data from wearables or electronic health records.\nExplore practical applications of deep learning, including medical image analysis, genomics, and personalized treatment plans.\nRecognize the challenges of using deep learning in medicine, such as the need for large labeled datasets and the interpretability of model predictions.\n\n\n\n\nChapter 6: Challenges in Medical Machine Learning\nThis chapter focuses on the challenges and ethical considerations when deploying machine learning in clinical practice.\nLearning Objectives:\n\nIdentify the limitations of machine learning models, including issues related to bias in datasets and the risk of perpetuating health disparities.\nUnderstand the ethical concerns associated with patient privacy, data sharing, and the use of black-box models in clinical decision-making.\nDiscuss the challenge of model interpretability and the need for explainable AI in high-stakes medical environments.\nExplore the risks of over-reliance on machine learning in medicine, emphasizing the role of human oversight in clinical practice.\nUnderstand the regulatory and legal aspects of using machine learning in healthcare, including FDA guidelines for AI-based tools.\n\n\n\n\nLearning Objectives Reinforcement\n\nCore Concepts (Chapters 1 & 2): Foundational principles are introduced in Chapter 1 and reinforced with concrete examples in Chapter 2, particularly supervised learning algorithms and their relevance to tasks like disease diagnosis.\nExploration & Discovery (Chapters 3 & 5): While Chapter 3 focuses on unsupervised learning and its role in exploratory data analysis, Chapter 5 extends this with deep learning, particularly in unstructured data like images.\nModel Performance (Chapters 4 & 6): The importance of evaluating models thoroughly is emphasized in Chapter 4, and revisited in Chapter 6, where the ethical and practical implications of deploying ML in the clinic are considered.\n\n\nThese learning objectives aim to ensure that students progressively build their understanding of machine learning while reinforcing key concepts in each chapter. Let me know if you’d like to adjust any of these objectives!\n\n\n\n\nCitationBibTeX citation:@online{davis,\n  author = {Davis, Sean},\n  url = {https://seandavi.github.io/IDPT-8079/book/attic-learning-objectives-by-chapter.html},\n  langid = {en}\n}\nFor attribution, please cite this work as:\nDavis, Sean. n.d. https://seandavi.github.io/IDPT-8079/book/attic-learning-objectives-by-chapter.html."
  },
  {
    "objectID": "book/nlp-section/word-embeddings.html",
    "href": "book/nlp-section/word-embeddings.html",
    "title": "Word Embeddings and Representation in Text",
    "section": "",
    "text": "Tip\n\n\n\nWhat is the name?"
  },
  {
    "objectID": "book/nlp-section/word-embeddings.html#embedding-people-analogies-in-personality-dimensions",
    "href": "book/nlp-section/word-embeddings.html#embedding-people-analogies-in-personality-dimensions",
    "title": "Word Embeddings and Representation in Text",
    "section": "Embedding People: Analogies in Personality Dimensions",
    "text": "Embedding People: Analogies in Personality Dimensions\nThe HEXACO model of personality structure is a six-dimensional model of human personality that was created by Ashton and Lee and explained in their book, The H Factor of Personality,[1] based on findings from a series of lexical studies involving several European and Asian languages. The six factors, or dimensions, include honesty-humility (H), emotionality (E), extraversion (X), agreeableness (A), conscientiousness (C), and openness to experience (O). Each factor is composed of traits with characteristics indicating high and low levels of the factor. If you’ve ever taken a personality test, you might have encountered these dimensions.\nWe have three hypothetical colleagues, Jay, Kay, and May. Each has taken a personality test and received scores for two personality dimensions which we’ll call “Dimension 1” and “Dimension 2.” The scores are as shown Figure 1 depicted graphically in the top left. We can take these scores and represent them as vectors in a two-dimensional space, where each dimension corresponds to one of the personality dimensions as shown in the bottom of Figure 1. Using these vectors, we can visualize the relationships between Jay, Kay, and May in this two-dimensional space as shown on the right plot of Figure 1.\n\n\n\n\n\n\nFigure 1: Schematic of three hypothetical embeddings of people. Our embeddings are based on personality “dimensions” represented by two different scores (colored orange and blue).\n\n\n\nThe idea of “embedding people” allows us to take abstract concepts like personality traits and represent them in a numerical space. This concept is extended to words in natural language processing, where we represent words as vectors in a high-dimensional space. These word embeddings capture the meaning and relationships between words, allowing us to perform various tasks like sentiment analysis, machine translation, and named entity recognition. Just like with Jay, Kay, and May, words that are similar in meaning are close together in this space.\nIn the case of personality traits the dimensions are derived from a psychological model, but in the case of word embeddings, the dimensions are learned from large text corpora using models like Word2Vec, GloVe, or fastText. These models learn to represent words in a way that captures their semantic and syntactic relationships based on the context they appear in."
  },
  {
    "objectID": "book/nlp-section/word-embeddings.html#word-embeddings-capturing-semantic-relationships",
    "href": "book/nlp-section/word-embeddings.html#word-embeddings-capturing-semantic-relationships",
    "title": "Word Embeddings and Representation in Text",
    "section": "Word Embeddings: Capturing Semantic Relationships",
    "text": "Word Embeddings: Capturing Semantic Relationships\nText is one of the most abundant forms of data in healthcare, with sources ranging from electronic health records (EHRs) to published research articles, clinical notes, and even patient-reported outcomes. However, computers don’t understand words as humans do—they require numerical representations of text to analyze, model, and make predictions. The challenge is: how do we represent the meaning of words in a way that captures their context and relationships in a way that machines can understand?\nThis is where word embeddings come into play. Word embeddings provide a way to represent words as vectors (numerical arrays), capturing semantic relationships and making it possible to apply machine learning models to text. By converting text into embeddings, we open the door to a range of applications, from clinical text mining to predicting patient outcomes based on unstructured medical notes.\nThis chapter introduces word embeddings and explains how they allow us to map words into a vectors that encode semantic and syntactic meaning. We’ll cover why this is an improvement over older methods, how these embeddings are learned, and how they are used in medical applications."
  },
  {
    "objectID": "book/nlp-section/word-embeddings.html#limitations-of-traditional-text-representations",
    "href": "book/nlp-section/word-embeddings.html#limitations-of-traditional-text-representations",
    "title": "Word Embeddings and Representation in Text",
    "section": "Limitations of Traditional Text Representations",
    "text": "Limitations of Traditional Text Representations\nBefore diving into embeddings, let’s briefly review older techniques for representing text. The simplest representations were based on bag-of-words (BoW) models and term frequency-inverse document frequency (TF-IDF) scores.\n\nBag-of-Words and TF-IDF\n\nBag-of-words ignores the order of words and represents text based on word occurrences. For example, a clinical note with the text: “Patient experiences chest pain” would be represented simply as [\"patient\", \"experiences\", \"chest\", \"pain\"]. The model doesn’t understand that “chest” and “pain” are related, or that their combination is meaningful.\nTF-IDF refines this by weighing how frequently words appear in a document relative to how common they are across all documents. This addresses the fact that some words are very frequent and not informative, like “the” or “patient.”\n\n\n\nLimitations\n\nLack of Context: These methods do not capture word order or semantics. For example, in BoW, the words “chest pain” and “pain in the chest” would be represented the same.\nHigh Dimensionality: BoW and TF-IDF result in large sparse matrices, making it difficult to work with longer documents.\nNo Concept of Similarity: In these models, words like “doctor” and “physician” are treated as completely independent, despite their similar meanings.\n\nThis leads us to modern word embeddings, which solve many of these issues."
  },
  {
    "objectID": "book/nlp-section/word-embeddings.html#what-are-word-embeddings",
    "href": "book/nlp-section/word-embeddings.html#what-are-word-embeddings",
    "title": "Word Embeddings and Representation in Text",
    "section": "What Are Word Embeddings?",
    "text": "What Are Word Embeddings?\nWord embeddings are dense, low-dimensional vector representations of words, where words with similar meanings have similar vector representations. The key idea is that these embeddings capture both the syntactic and semantic properties of words. The most popular models for learning embeddings include Word2Vec [@mikolovEfficientEstimationWord2013], GloVe [@penningtonGloVeGlobalVectors2014], and fastText [@bojanowskiEnrichingWordVectors2017].\n\n\n\n\n\n\nFigure 2: Linear combinations of dimensions in vector space correlate with the semantic and syntactic roles of the words in the corpus[^1]. For illustration purposes, dimension d1 in the figure has a high positive correlation with living beings. A properly tuned word embedding model will map words with similar semantic or syntactic roles to adjacent regions in vector space. This property can be visualized through dimensionality reduction techniques such as t-SNE or PCA. Cultural concepts are also apparent in vector space as consistent offsets between vector representations of words sharing a particular relationship. For instance, in the bottom right of the figure, the dotted vector represents a gender regularity that goes from masculinity to femininity.\n\n\n\nFigure 2 effectively demonstrates how word embeddings capture the meaning and relationships between words in a numerical space, and how this can be visualized after reducing the dimensionality. Let’s break down each part of the figure to build intuition.\nIn the left section of the figure, you see word embeddings for seven different words: “dog,” “puppy,” “cat,” “houses,” “man,” “woman,” “king,” and “queen.” Each word is represented as a vector in a seven-dimensional space (d1 to d7), where each number in the row corresponds to a particular dimension in this space.\nFor example: - “dog” is represented as the vector [0.6, 0.9, 0.1, 0.4, -0.7, -0.3, -0.2] - “cat” is represented as [0.7, -0.1, 0.4, 0.3, -0.4, -0.1, -0.3]\nThese vectors encode the meaning of the words, capturing their relationships to other words in the vocabulary based on the corpus they were trained on.\n\nWord embeddings are numerical representations of words\nEach word is represented as a dense vector of real numbers. The dimensions (d1 to d7) don’t have a simple interpretable meaning like “animal” or “emotion,” but the relationships between the vectors capture such nuances. 1. Similarity and Relationship: Words that are semantically similar or related (like “dog” and “puppy”) tend to have similar vectors, meaning that in seven-dimensional space, they are near each other. We’ll see how this manifests in the visualization on the right.\nThe right side of Figure 2 shows what happens when we reduce the dimensionality of these word embeddings from 7D to 2D (for visualization). Dimensionality reduction techniques like Principal Component Analysis (PCA) or t-SNE are often used to reduce the complexity of the data while retaining its most important features. Here, reducing from 7 dimensions to 2 allows us to visualize the relationships between the words in 2D space. Note that the actual embeddings are learned in much higher dimensions (e.g., 100 to 300) and that the 2D projection is for visualization purposes only.\nIn the top-right plot of Figure 2, we see the 2D embeddings for “dog,” “puppy,” “cat,” and “houses.”\n“Dog” and “puppy” are close together in the embedding space, reflecting their semantic similarity. Both refer to canines, with “puppy” being a younger dog. This proximity in vector space is a hallmark of how embeddings capture semantic similarity. - “Cat” is a bit further away, as it represents a different animal, but it is still in proximity, highlighting some shared characteristics between cats and dogs (both are pets/animals). - “Houses” is far from all the animal-related words. This makes sense because “houses” is a completely different concept (object vs. animal). The fact that it’s distant in the embedding space highlights that the embeddings successfully differentiate unrelated terms.\nFigure 2 is a simplified example, but it captures the essence of how word embeddings work and how they can be visualized in lower dimensions to reveal relationships between words.\n\n\nReal world example: King-Queen Analogy\nIn Figure 3, we see a classic example of how word embeddings capture relationships between words. The figure shows the embeddings a number of words, including “king,” “queen,” “man,” and “woman” in 2D space. The axes have been adjusted to highlight the relationships between these words so that the y-axis represents the woman–queen axis representing a sense of royalty. The x-axis, aligned with the he–she axis represents a gender dimension.\n\n\n\n\n\n\nFigure 3: GloVE embeddings are the inputs to this 2D plot. The words/points are placed based on their location along the queen–woman or royalty axis and the he–she or gender axis in the GloVE space.\n\n\n\nAn amazing property of word embeddings is that they can capture analogies like “King is to Queen” as “Man is to woman.” This is known as the king-queen analogy and is a classic example of how embeddings can encode relationships between words. To use embeddings to solve this analogy, we can perform vector arithmetic. In this case, the vector operation we could use is given in Equation 1.\n\\[\\text{vector(\"king\")} - \\text{vector(\"man\")} + \\text{vector(\"woman\")} \\approx \\text{vector(\"queen\")} \\tag{1}\\]\nHere are a few ways of thinking about Equation 1.\nThis figure illustrates word embeddings in a 2D space, where the x-axis represents the spectrum from “he” to “she” and the y-axis represents the spectrum from “woman” to “queen”. The famous analogy “king - man + woman = queen” can be intuitively explained using this geometric representation:\nVector representation:\n\nIn this space, each word is represented as a 2D vector. The position of each word encodes semantic information about gender and royalty/status.\n“king - man”: This subtraction shifts the vector from “king” in the direction opposite to “man”. Geometrically, it moves the point left and slightly down, removing the “maleness” from “king”.\n“+ woman”: Adding “woman” shifts the resulting vector right and down, adding “femaleness”.\nResult ≈ queen: The final position after these operations ends up very close to “queen”.\n\nGeometric interpretation:\n\nSubtraction (king - man): Imagine drawing a vector from “man” to “king”. This represents the concept of “royalty” independent of gender.\nAddition (+ woman): Now apply this “royalty” vector starting from “woman”. It brings you to a point very close to “queen”.\n\nSemantic relationships:\n\n“king” is to “man” as “queen” is to “woman”\nThe difference between “king” and “man” (royalty) is similar to the difference between “queen” and “woman”\n“king” and “queen” are at similar heights (y-values), representing similar levels of royalty/status.\n“man” and “woman” are at similar heights, but lower than king/queen.\nThe gender axis (x-axis) separates male and female terms consistently while the royalty axis (y-axis) separates royal titles from less “regal” terms."
  },
  {
    "objectID": "book/nlp-section/word-embeddings.html#where-do-word-embeddings-come-from",
    "href": "book/nlp-section/word-embeddings.html#where-do-word-embeddings-come-from",
    "title": "Word Embeddings and Representation in Text",
    "section": "Where do Word Embeddings Come From?",
    "text": "Where do Word Embeddings Come From?\nWord embeddings are learned from large text corpora using models like Word2Vec, GloVe, or fastText. These models are trained to predict words based on their context in the text, capturing the relationships between words in the process.\nThe word2vec model, developed by Mikolov et al., is one of the most popular methods for learning word embeddings. It comes in two flavors: Continuous Bag of Words (CBOW) and Skip-gram. The skip-gram model is particularly effective at capturing semantic relationships between words. It learns to predict the context words given a target word, effectively learning the embeddings that encode these relationships. Figure 4 illustrates how the skip-gram approach applies to a sentence. The model learns to predict the surrounding words given the current word, capturing the context in which words appear.\n\n\n\n\n\n\n\n\nFigure 4: Learning word embeddings using the skip-gram model. Figure from 1\n\n\n\nThe word2vec architecture consists of a single hidden layer neural network with a softmax output layer. The input to the model is a one-hot encoded vector representing the target word, and the output is a probability distribution over the vocabulary. The model is trained using backpropagation to minimize the loss between the predicted and actual context words. This process results in word embeddings that capture the semantic relationships between words. Figure 5 illustrates how the skip-gram model is trained using backpropagation.\n\n\n\n\n\n\nNote\n\n\n\nOne-hot encoding is a way of representing words as binary vectors, where each word is represented by a vector with a 1 in the position corresponding to the word’s index in the vocabulary and 0s elsewhere. For example, in a “vocabulary” of the six words [“cat”, “hat”, “the”, “in”, “green”, “eggs”], the word “cat” might be represented as [0, 0, 1, 0, 0, 0] and “green” as [0, 0, 0, 1, 0, 0]. Thus, when we want to provide input to our word embedder for training, we supply the first vector for “cat” and for “green” we use the second, and so on. In reality, our “vocabulary” would be much larger, but this is the basic idea.\nWhen a vector consists of mostly zeros, like our one-hot encoding vectors, they are referred to as “sparse.” Word embeddings provide a “dense” representation word embedding vectors do not generally contain zeros. The dense vector for each word is in a lower-dimensional space (typically 100-500 dimensions), capturing semantic relationships more effectively. Another way of thinking of word embeddings is as a “lookup table” that maps the words in the one-hot encoding to continuous vectors.\n\n\n\n\n\n\n\n\n\n\n\n\n\n(a) Model incorrectly predicts neighboring words.\n\n\n\n\n\n\n\n\n\n\n\n\n\n(b) Model has “learned” new weights and now correctly predicts neighboring words.\n\n\n\n\n\n\n\nFigure 5: The skip-gram model is trained using backpropagation to minimize the loss between the predicted and actual context words. The diagram illustrates the training process. The goal is to learn weights such that the model can predict correctly that the word “the” comes before “wide” and is followed by the word “road.” Figure 5 (a) demonstrates that the model has made a mistake; we can see that because the \\(y_{pred}\\) vector representing the prediction does not match the \\(y\\) vector which is the “correct” value. Figure 5 (b) shows the correct prediction after adjusting the weights and the \\(y_{pred}\\) vector now matches the \\(y\\) vector.\n\n\n\n\nApplications in Healthcare\nIn medical contexts, word embeddings can capture similar nuances. For example:\n\nMedical Conditions: Words like “diabetes” and “insulin” might cluster closely together because they frequently co-occur in medical texts.\nDrug-Condition Relationships: Embeddings might place medications and their corresponding conditions near each other, such as “metformin” and “diabetes.”\nSemantic Analogies: Embeddings could capture analogies such as “insulin is to diabetes as chemotherapy is to cancer.”\n\nVisualizing embeddings in medical text could help identify clinically relevant clusters, group patients with similar conditions, or even highlight previously unknown associations between treatments and conditions.\nIn an embedding space, similar words are closer together. For example, in a model trained on medical notes, the words “diabetes” and “insulin” might be closer to each other than “diabetes” and “antibiotic.”"
  },
  {
    "objectID": "book/nlp-section/word-embeddings.html#why-word-embeddings-are-powerful-for-medical-text",
    "href": "book/nlp-section/word-embeddings.html#why-word-embeddings-are-powerful-for-medical-text",
    "title": "Word Embeddings and Representation in Text",
    "section": "Why Word Embeddings Are Powerful for Medical Text",
    "text": "Why Word Embeddings Are Powerful for Medical Text\nThe power of word embeddings lies in their ability to capture both semantic similarity and relationships between terms. Some key benefits include:\n\nContextual Relationships: Embeddings capture the relationships between words based on the context they appear in. For instance, embeddings might learn that “heart attack” is more related to “chest pain” than to “headache.”\nTransfer Learning: Once embeddings are trained on a large dataset, they can be transferred to other tasks. This is particularly useful in medicine, where labeled datasets are often scarce.\nReduced Dimensionality: Instead of having thousands of word features (as in BoW or TF-IDF), word embeddings map words into a continuous vector space of, say, 300 dimensions, significantly reducing computational complexity."
  },
  {
    "objectID": "book/nlp-section/word-embeddings.html#applications-of-word-embeddings-in-healthcare",
    "href": "book/nlp-section/word-embeddings.html#applications-of-word-embeddings-in-healthcare",
    "title": "Word Embeddings and Representation in Text",
    "section": "Applications of Word Embeddings in Healthcare",
    "text": "Applications of Word Embeddings in Healthcare\nWord embeddings have broad applications in healthcare, ranging from clinical note processing to biomedical literature mining."
  },
  {
    "objectID": "book/nlp-section/word-embeddings.html#challenges-and-considerations",
    "href": "book/nlp-section/word-embeddings.html#challenges-and-considerations",
    "title": "Word Embeddings and Representation in Text",
    "section": "Challenges and Considerations",
    "text": "Challenges and Considerations\nWhile word embeddings are powerful, they are not without limitations, particularly in the medical context.\n\nData Quality: Embeddings reflect the biases of the text they are trained on. Incomplete or biased data (e.g., underrepresentation of minority groups in medical datasets) may lead to biased embeddings.\nOut-of-Vocabulary Words: Traditional embeddings struggle with out-of-vocabulary (OOV) words, such as rare medical terms or abbreviations not present in the training data. This is addressed by newer models like fastText, which breaks words into subword units.\nInterpretability: The embedding space is often not human-interpretable. We can visualize relationships between terms, but it is difficult to explain why certain words cluster together beyond their proximity in the vector space."
  },
  {
    "objectID": "book/nlp-section/word-embeddings.html#conclusion",
    "href": "book/nlp-section/word-embeddings.html#conclusion",
    "title": "Word Embeddings and Representation in Text",
    "section": "Conclusion",
    "text": "Conclusion\nWord embeddings revolutionized how text is represented in machine learning models, particularly in complex domains like healthcare. By capturing both syntactic and semantic relationships between words, embeddings allow for more effective processing of clinical texts, patient records, and biomedical literature.\nIn the next chapter, we will delve into how more advanced architectures, like recurrent neural networks, build on the foundation of word embeddings to handle sequential data, setting the stage for even more powerful models like transformers and large language models."
  },
  {
    "objectID": "book/nlp-section/word-embeddings.html#exercises",
    "href": "book/nlp-section/word-embeddings.html#exercises",
    "title": "Word Embeddings and Representation in Text",
    "section": "Exercises",
    "text": "Exercises\n\nTensorFlow Embedding Projector\nThe TensorFlow Embedding Projector is a web-based tool that allows you to visualize word embeddings in a 3D space. You can use it to explore the relationships between words and see how they are clustered together. Navigate to the TensorFlow Embedding Projector and experiment a bit.\n\nBy mousing over the points in the 3D space, you can see the words that are closest to a given word. You can also search for a specific word and see how it is related to other words in the space. If you click on a word, you can see a list of the words that are closest to it (based on cosine similarity in the embedding space, not necessarily in the 2D projection).\n\n\nWord Embedding Visualization\nIn this exercise, you can play with a really cool interactive word embedding visualization tool. The tool allows you to explore word embeddings in a 2D space and see how words are related to each other.\nFirst, watch the video below to see how the tool works:\n\n\nNavigate to the word2viz website.\nExplore the controls and inputs on the right.\nPLAY!\n\n\n\n[Optional] Playing with Word Embeddings in Python\nIn this exercise, you will use the gensim library to load pre-trained word embeddings and explore the relationships between words. Gensim is a popular library for working with word embeddings and provides an easy way to load pre-trained models or to train your own embeddings!\nFirst, you need to install the gensim library if you haven’t already. You can do this using pip:\npip install gensim\nNext, you can use the following code to load a pre-trained word embedding model and explore the relationships between words.\n\nimport gensim.downloader as api\n\n# Download a pre-trained word embedding model (if not already downloaded)\nmodel = api.load(\"glove-wiki-gigaword-50\")\n\nThe model object is now a word embedding model that you can use to get word vectors and find similar words. Someone else has trained the model already. Here are a few things you can do with the model:\n\n# Get the word embedding vector for a word\nword = \"king\"\nvector = model[word]\nprint(f\"Word embedding for '{word}': {vector}\")\n\nWord embedding for 'king': [ 0.50451   0.68607  -0.59517  -0.022801  0.60046  -0.13498  -0.08813\n  0.47377  -0.61798  -0.31012  -0.076666  1.493    -0.034189 -0.98173\n  0.68229   0.81722  -0.51874  -0.31503  -0.55809   0.66421   0.1961\n -0.13495  -0.11476  -0.30344   0.41177  -2.223    -1.0756   -1.0783\n -0.34354   0.33505   1.9927   -0.04234  -0.64319   0.71125   0.49159\n  0.16754   0.34344  -0.25663  -0.8523    0.1661    0.40102   1.1685\n -1.0137   -0.21585  -0.15155   0.78321  -0.91241  -1.6106   -0.64426\n -0.51042 ]\n\n\nThe vector variable now contains the word embedding for the word “king.” You can use this to find similar words or perform vector arithmetic. Here’s an example:\n\n# Find similar words\nsimilar_words = model.most_similar(word, topn=5)\n\n# Display similar words and their similarity scores\nprint(f\"Words similar to '{word}':\")\nfor similar_word, score in similar_words:\n    print(f\"    {similar_word}: {score}\")\n\nWords similar to 'king':\n    prince: 0.8236179351806641\n    queen: 0.7839044332504272\n    ii: 0.7746230363845825\n    emperor: 0.7736247777938843\n    son: 0.766719400882721\n\n\nYou can also perform vector arithmetic to find relationships between words. Coming back to our earlier example of the king-queen analogy, you can use the word embeddings to find the word that completes the analogy “Man is to king as woman is to ___.”\n\n# Perform vector arithmetic\nresult = model.most_similar(positive=[\"king\", \"woman\"], negative=[\"man\"], topn=1)\nprint(f\"King + Woman - Man = {result}\")\n\nKing + Woman - Man = [('queen', 0.8523604273796082)]\n\n\nFor those who want to try this themselves, I’ve created a Google Colab notebook that you can use to experiment with word embeddings in Python.\nYou can watch this short video to see how to use the notebook:"
  },
  {
    "objectID": "book/nlp-section/word-embeddings.html#references",
    "href": "book/nlp-section/word-embeddings.html#references",
    "title": "Word Embeddings and Representation in Text",
    "section": "References",
    "text": "References"
  },
  {
    "objectID": "book/nlp-section/word-embeddings.html#footnotes",
    "href": "book/nlp-section/word-embeddings.html#footnotes",
    "title": "Word Embeddings and Representation in Text",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nhttps://www.tensorflow.org/tutorials/text/word2vec↩︎"
  },
  {
    "objectID": "Exercises/aom-expert-system/play-with-prolog.html",
    "href": "Exercises/aom-expert-system/play-with-prolog.html",
    "title": "Build an Expert System using Prolog",
    "section": "",
    "text": "Understand Expert Systems: Know what an expert system is, particularly as a narrow AI system.\nExplore Logic Programming: Learn the basic principles of logic programming and how Prolog is used to model complex decision-making processes.\nLearn to Implement an Expert System: Gain hands-on experience using programming to solve problems using logical rules and knowledge representation.\nDevelop Problem-Solving Skills: Implement a simple expert system in Prolog, mimicking the decision-making capabilities of a human expert.\nUnderstand limitations of Expert Systems: Explore the concept of narrow AI and its practical applications in specific domains through the use of expert systems."
  },
  {
    "objectID": "Exercises/aom-expert-system/play-with-prolog.html#components-of-an-expert-system",
    "href": "Exercises/aom-expert-system/play-with-prolog.html#components-of-an-expert-system",
    "title": "Build an Expert System using Prolog",
    "section": "Components of an Expert System",
    "text": "Components of an Expert System\nAn ES is built around a knowledge base that contains a vast amount of information, rules, and relationships specific to the domain it’s designed for. This knowledge is typically acquired from human experts, research papers, or other sources. The knowledge base is organized and structured to facilitate efficient reasoning and problem-solving. Think of this as the “rules” or “facts” that the system uses to make decisions. In a medical setting, gathering the knowledge base might involve reviewing textbooks, guidelines, and expert opinions to extract the key information needed to make diagnoses and treatment recommendations.\nThe inference engine is the “brain” of the ES. It uses the knowledge base to draw conclusions, make decisions, and solve problems. The engine applies logical rules and reasoning techniques to arrive at a solution. Note that the inference engine doesn’t “learn” in the traditional sense, but rather applies predefined rules to the input data. New rules can be added to the system to expand its capabilities, but the system doesn’t learn from experience like a neural network would.\nAn ES typically has a user-friendly interface that allows users to input queries, ask questions, or provide data. The system then uses this input to generate a response, provide recommendations, or solve a problem. The user interface can be text-based, graphical, or voice-activated, depending on the application.\nESs use various reasoning techniques, such as forward and backward chaining, to solve problems and make decisions. The reasoning and problem solving capabilities of an ES are what set it apart from traditional software systems. Languages like Prolog are commonly used to implement the logic and reasoning components of an ES."
  },
  {
    "objectID": "Exercises/aom-expert-system/play-with-prolog.html#applications-of-expert-systems",
    "href": "Exercises/aom-expert-system/play-with-prolog.html#applications-of-expert-systems",
    "title": "Build an Expert System using Prolog",
    "section": "Applications of Expert Systems",
    "text": "Applications of Expert Systems\nExpert Systems have been applied in various domains and industries, including healthcare, finance, manufacturing, and customer service. ESs can help diagnose diseases, recommend treatments, and guide patient care. ESs can monitor production processes, detect defects, and recommend quality improvements. ESs can provide customer support, answer frequently asked questions, and route complex issues to human representatives."
  },
  {
    "objectID": "Exercises/aom-expert-system/play-with-prolog.html#limitations-of-expert-systems",
    "href": "Exercises/aom-expert-system/play-with-prolog.html#limitations-of-expert-systems",
    "title": "Build an Expert System using Prolog",
    "section": "Limitations of Expert Systems",
    "text": "Limitations of Expert Systems\nWhile Expert Systems have shown significant promise, they also have some limitations. Building an ES requires a significant amount of knowledge acquisition, which can be time-consuming and costly. The knowledge base must be accurately represented and organized to ensure effective reasoning and problem-solving. ESs require ongoing maintenance to keep their knowledge base up-to-date and ensure they remain effective. ESs may struggle with complex, ambiguous, or uncertain problems that require human intuition or creativity. Because ESs rely on predefined rules and logic, they may not adapt well to new or unexpected situations such as additional symptoms, tests, or rare conditions not accounted for when the system was built."
  },
  {
    "objectID": "Exercises/aom-expert-system/play-with-prolog.html#using-chatgpt-or-claude-to-understand-expert-systems",
    "href": "Exercises/aom-expert-system/play-with-prolog.html#using-chatgpt-or-claude-to-understand-expert-systems",
    "title": "Build an Expert System using Prolog",
    "section": "Using ChatGPT (or Claude) to understand Expert Systems",
    "text": "Using ChatGPT (or Claude) to understand Expert Systems\nBefore we dive into the actual exercise, ask ChatGPT (or Claude) a few questions to understand the concept of Expert Systems better. Some examples might include:\n\nWhat is an Expert System?\nHow do Expert Systems work?\nWhat are the components of an Expert System?\nWhat are some applications of Expert Systems?\nWhat are the limitations of Expert Systems?\nHow are Expert Systems different from traditional software systems?\nHow do expert systems compare to machine learning systems?\nWhat are some examples of Expert Systems in healthcare?"
  },
  {
    "objectID": "Exercises/aom-expert-system/play-with-prolog.html#key-features-of-prolog",
    "href": "Exercises/aom-expert-system/play-with-prolog.html#key-features-of-prolog",
    "title": "Build an Expert System using Prolog",
    "section": "Key features of Prolog",
    "text": "Key features of Prolog\n\nDeclarative Approach: Prolog focuses on what needs to be solved rather than how to solve it. Think of it like giving a set of rules and facts, and then letting the computer figure out the solution on its own, rather than telling it step-by-step how to get there.\nLogical Reasoning: Prolog is built on logic. It uses logical thinking to figure things out, much like how we reason through problems in everyday life. For example, if you tell it certain facts like “All humans are mortal” and “Socrates is a human,” Prolog can figure out that “Socrates is mortal.”\nFacts, Rules, and Questions: Prolog programs are made up of facts (like “Socrates is a human”), rules (like “all humans are mortal”), and questions (like “is Socrates mortal?”). You give Prolog the facts and rules, and then you can ask it questions. It works to find the answers using the information you’ve provided.\n\nIn short, Prolog is like a puzzle solver that uses logic and rules to find solutions, and you don’t have to tell it every step—it figures that part out by itself!"
  },
  {
    "objectID": "Exercises/aom-expert-system/play-with-prolog.html#role-in-ai",
    "href": "Exercises/aom-expert-system/play-with-prolog.html#role-in-ai",
    "title": "Build an Expert System using Prolog",
    "section": "Role in AI",
    "text": "Role in AI\nProlog has played a significant role in the history of AI and has been used in various AI applications. Some of the key areas where Prolog has been applied include:\n\nExpert Systems: In the 1980s, Prolog was widely used to develop expert systems, which rely on predefined knowledge and logical rules to provide decision-making capabilities.\nNatural Language Processing (NLP): Prolog’s strengths in pattern matching and symbolic reasoning made it a good choice for early NLP research and applications, as it could model syntactic and semantic relationships in language.\nAutomated Theorem Proving: Due to its foundation in formal logic, Prolog was used in AI systems aimed at proving theorems and solving puzzles."
  },
  {
    "objectID": "Exercises/aom-expert-system/play-with-prolog.html#historical-significance",
    "href": "Exercises/aom-expert-system/play-with-prolog.html#historical-significance",
    "title": "Build an Expert System using Prolog",
    "section": "Historical Significance",
    "text": "Historical Significance\nProlog played a crucial role in early AI research. It was one of the key languages, alongside LISP, that shaped the development of AI methodologies, particularly in areas such as knowledge representation, reasoning, and machine learning. In the 1980s, Prolog gained popularity when it was adopted by the Japanese Fifth Generation Computer Systems (FGCS) project, which aimed to develop intelligent computers. Although the project did not meet all of its goals, it contributed to Prolog’s international prominence."
  },
  {
    "objectID": "Exercises/aom-expert-system/play-with-prolog.html#current-usage",
    "href": "Exercises/aom-expert-system/play-with-prolog.html#current-usage",
    "title": "Build an Expert System using Prolog",
    "section": "Current Usage",
    "text": "Current Usage\nProlog is not as widely used today as mainstream languages like Python or Java, particularly in AI development. However, it still has a niche role in certain areas of AI, particularly in research and specialized fields like automated reasoning, logic programming, and computational linguistics. Prolog continues to be taught in some academic settings as a tool for understanding logic programming and the fundamentals of AI.\nProlog remains an important historical pillar in AI, particularly for its contributions to logical reasoning, knowledge representation, and expert systems."
  },
  {
    "objectID": "Exercises/aom-expert-system/play-with-prolog.html#an-example-prolog-program",
    "href": "Exercises/aom-expert-system/play-with-prolog.html#an-example-prolog-program",
    "title": "Build an Expert System using Prolog",
    "section": "An example Prolog program",
    "text": "An example Prolog program\nThis example illustrates a simple Prolog program that defines facts, rules, and queries. The program is designed to answer the question of whether Socrates is mortal based on the fact that he is human. In practice, Prolog programs can be much more complex, with many facts, rules, and queries that define a domain of interest.\nIn the code below, everything in a line after a ‘%’ is a comment that explains what the code is doing. Comments are not part of the program itself but are there to help you understand the code.\n% Facts\nhuman(socrates).\n\n% Rules\nmortal(X) :- human(X). \n\n% Queries\n?- mortal(socrates).\n\nExplanation:\n\nFacts:\nIn Prolog, facts are basic statements about things we know to be true. In this case, the fact human(socrates). means that Socrates is a human. This is a piece of information we’re giving to the program. In a medical context, we might have facts like symptom(fever). or history_of(cancer). that represent information about patients.\nRules:\nRules in Prolog define relationships between facts. Here, we have the rule mortal(X) :- human(X)., which means “X is mortal if X is human.” “Variables” in prolog begin with capital letters, so X is a variable. In Prolog, the :- symbol can be read as “if.” So, this rule is saying, “if X is human, then X is mortal.” This is a simple logical relationship that Prolog can use to make inferences.\nQueries:\nWhen we want to ask Prolog a question (or query), we do so by providing a query. For example, the query ?- mortal(socrates). is asking, “Is Socrates mortal?” Prolog will use the facts and rules we’ve provided to answer this question.\nIn this case, it looks at the rule mortal(X) :- human(X). and sees that since Socrates is a human (from the fact human(socrates).), he must also be mortal. So, Prolog will respond with “Yes” or true.\n\n\n\nHow It Works:\n\nhuman(socrates).: This is a fact we already know—Socrates is human.\nmortal(X) :- human(X).: This is a rule that says any human is mortal.\n?- mortal(socrates).: This is the query we ask, and Prolog checks the facts and rules to conclude that Socrates is mortal because he is human.\n\nIn summary, this small Prolog program uses logic to infer that Socrates is mortal based on the information that he’s human. It reflects how Prolog works by defining facts, applying rules, and answering queries logically."
  },
  {
    "objectID": "Exercises/aom-expert-system/play-with-prolog.html#knowledge-base",
    "href": "Exercises/aom-expert-system/play-with-prolog.html#knowledge-base",
    "title": "Build an Expert System using Prolog",
    "section": "Knowledge Base",
    "text": "Knowledge Base\nThe first step in building an expert system is to define the knowledge base. This knowledge base will contain the facts and rules that the system will use to reason and make decisions. In our case, we are going to build an expert system that can diagnose common conditions like colds, flu, and allergies based on a set of symptoms.\nWe are going to limit our facts to the following symptoms:\n\nrunny nose\nsneezing\nfever\nfatigue\n\nThese are common symptoms that can help differentiate between colds, flu, and allergies. For this exercise, lets assume that the following rules apply:\n\nIf a patient has a runny nose and sneezing with or without a fever, they likely have a common cold.\nIf a patient has a fever, sore throat, and runny nose, they likely have the flu.\nIf a patient has sneezing and a runny nose but no fever, they likely have allergies.\n\nWe can define these symptoms as facts in Prolog, like this:\n\n\n\nSymptom\nProlog Fact Representation\n\n\n\n\nRunny Nose\nsymptom(runny_nose).\n\n\nSneezing\nsymptom(sneezing).\n\n\nFever\nsymptom(fever).\n\n\nFatigue\nsymptom(fatigue).\n\n\nItchy Eyes\nsymptom(itchy_eyes).\n\n\n\nWe are going to simplify the rules for the sake of this exercise, but in a real-world scenario, the rules would be more complex and based on a larger set of symptoms and diagnostic criteria. In this case, we’ll assume that the presence or absence of these symptoms is enough to differentiate between the conditions.\nFor the common cold, we’ll use the following rule:\n\nIf a patient has a runny nose and sneezing but no fever, they likely have a common cold.\nTreatment: Rest, drink fluids, consider over-the-counter cold medicine.\n\nFor the flu, we’ll use the following rule:\n\nIf a patient has a fever, fatigue, and runny nose, they likely have the flu.\nTreatment: Rest, stay hydrated, take anti-fever medication, see a doctor if symptoms worsen.\n\nFor allergies, we’ll use the following rule:\n\nIf a patient has sneezing, a runny nose, and itchy eyes, they likely have allergies.\nTreatment: Avoid allergens, use antihistamines, consult an allergist if needed."
  },
  {
    "objectID": "Exercises/aom-expert-system/play-with-prolog.html#visualizing-the-expert-system",
    "href": "Exercises/aom-expert-system/play-with-prolog.html#visualizing-the-expert-system",
    "title": "Build an Expert System using Prolog",
    "section": "Visualizing the Expert System",
    "text": "Visualizing the Expert System\nBefore we dive into the Prolog code, let’s visualize the expert system using a flowchart. This will help us understand the logic and decision-making process that the system will follow. The flowchart will show how the system will diagnose patients based on their symptoms and recommend appropriate treatments.\n\n\n\n\n\ngraph TD\n    A[Start] --&gt; B{Runny nose?}\n    B --&gt;|No| Z[No diagnosis]\n\n    subgraph Symptom_Check\n        B --&gt;|Yes| C{Sneezing?}\n        C --&gt;|No| Z\n        C --&gt;|Yes| D{Fever?}\n        D --&gt;|Yes| E[Flu]\n        D --&gt;|No| F{Itchy eyes?}\n        F --&gt;|Yes| G[Allergies]\n        F --&gt;|No| H[Common Cold]\n    end\n\n    subgraph Diagnosis\n        E --&gt; I[Diagnosis: Flu]\n        G --&gt; J[Diagnosis: Allergies]\n        H --&gt; K[Diagnosis: Common Cold]\n    end\n\n    subgraph Treatment\n        I --&gt; L[Treatment: Rest, stay hydrated, take anti-fever medication, see doctor if symptoms worsen]\n        J --&gt; M[Treatment: Avoid allergens, use antihistamines, consult allergist if needed]\n        K --&gt; N[Treatment: Rest, drink fluids, consider over-the-counter cold medicine]\n    end"
  },
  {
    "objectID": "Exercises/aom-expert-system/play-with-prolog.html#reasoning-engine",
    "href": "Exercises/aom-expert-system/play-with-prolog.html#reasoning-engine",
    "title": "Build an Expert System using Prolog",
    "section": "Reasoning engine",
    "text": "Reasoning engine\nOnce we have defined our knowledge base, we need some kind of “reaoning” or “inference” engine to process the information and draw conclusions. This is where the Prolog programming language comes in. Prolog is a logic programming language that is well-suited for representing and reasoning with complex knowledge and rules. It uses a declarative syntax that allows you to define relationships, rules, and facts in a concise and intuitive way.\nProlog programs consist of a set of facts and rules that define the relationships between different entities in the system. The Prolog interpreter uses these facts and rules to answer queries and make inferences based on the input data.\nHere are some facts that we might include in our Prolog program based on some symptoms that a patient might present with:\n% Facts\nsymptom(fever).\nsymptom(fatigue).\nsymptom(runny_nose).\nsymptom(sneezing).\nsymptom(itchy_eyes).\nWhen we want to use Prolog, we tell the system what we know (facts) and what we want to know (queries). The system then uses the rules and facts to answer our queries.\nAnd here are some rules that we might include in our Prolog program based on the diagnostic criteria for different conditions:\n% Rules for diagnossis\n% Diagnosis rules\ndiagnose(common_cold) :-\n    symptom(runny_nose),\n    symptom(sneezing),\n    \\+ symptom(fever),\n    write('Diagnosis: Common Cold'), nl.\n\ndiagnose(flu) :-\n    symptom(fever),\n    symptom(fatigue),\n    symptom(runny_nose),\n    write('Diagnosis: Flu'), nl.\n\ndiagnose(allergies) :-\n    symptom(sneezing),\n    symptom(runny_nose),\n    symptom(itchy_eyes),\n    write('Diagnosis: Allergies'), nl.\nAnd we can do the same for the treatment recommendations:\n% Rules for treatment\ntreatment(common_cold) :-\n    write('Treatment: Rest, drink plenty of fluids, and consider over-the-counter cold medicine.'), nl.\n\ntreatment(flu) :-\n    write('Treatment: Rest, stay hydrated, take anti-fever medication, and see a doctor if symptoms worsen.'), nl.\n\ntreatment(allergies) :-\n    write('Treatment: Avoid allergens, use antihistamines, and consult an allergist if needed.'), nl.\nFinally, we can put it all together in a Prolog program that checks the symptoms, makes a diagnosis, and provides treatment recommendations:\n% Rule to check diagnosis and apply treatment\ncheck_diagnosis_and_treatment :-\n    diagnose(Disease),\n    treatment(Disease)."
  },
  {
    "objectID": "Exercises/aom-expert-system/play-with-prolog.html#footnotes",
    "href": "Exercises/aom-expert-system/play-with-prolog.html#footnotes",
    "title": "Build an Expert System using Prolog",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nSee https://www.datacamp.com/blog/what-is-narrow-ai for more information on narrow AI.↩︎"
  },
  {
    "objectID": "Exercises/retrieval-augmented-generation/rag.html",
    "href": "Exercises/retrieval-augmented-generation/rag.html",
    "title": "Large Language Models and Retrieval-Augmented Generation: A Technical Overview",
    "section": "",
    "text": "Large Language Models (LLMs) have revolutionized natural language processing by generating human-like text and enabling a wide range of applications, from chatbots to language translation. However, LLMs have limitations that impact how valuable they are in a medical context.\nHere are a few scenarios where LLMs may fall short:\nHere, we’ll explore how Retrieval-Augmented Generation (RAG) can address these limitations by combining the strengths of LLMs with external knowledge retrieval. We will discuss the technical aspects of RAG, including embeddings, chunking, and the retrieval process, and how these components work together to enhance the capabilities of LLMs in medical applications."
  },
  {
    "objectID": "Exercises/retrieval-augmented-generation/rag.html#large-language-models",
    "href": "Exercises/retrieval-augmented-generation/rag.html#large-language-models",
    "title": "Large Language Models and Retrieval-Augmented Generation: A Technical Overview",
    "section": "Large Language Models",
    "text": "Large Language Models\nLarge language models are machine learning models trained on vast amounts of text data to understand and generate human language (but are not necessarily intelligent (“ChatGPT Is Not \"True AI.\" A Computer Scientist Explains Why - Big Think” n.d.)). These models are based on neural networks, particularly transformer architectures, which excel at learning long-range dependencies between words and concepts. By training on extensive text corpora, including medical literature, clinical notes, and general knowledge sources, LLMs can model the complex relationships between terms, diagnoses, and treatments in medical data. They are in essence very complex pattern recognition systems that can generate text that is contextually relevant and coherent. Another way of thinking of them is as incredibly powerful autocomplete systems that can generate text based on a given prompt. A third was is to think of them as “language calculators” that can perform tasks like translation, summarization, and question-answering.\n\nTraining GPT-4\nIt is thought that GPT-4 was trained on about 575 GB of data representing a diverse range of text sources, including books, articles, and websites. The training process involved optimizing the model’s parameters to predict the next word in a sentence, a task known as autoregressive language modeling. By learning the statistical patterns in the training data, GPT-4 can generate coherent and contextually relevant text in response to user prompts. The underlying model has about 1.8 trillion parameters. The training process is thought to have involved \\(2.5 \\cdot 10^{25}\\) floating-point operations, which is equivalent to running a single CPU core for about 1.5 million years. Your laptop would take a mere 100,000 years to complete the same task.\nDespite being trained on vast amounts of data, data types or sources that are not included in the training data are not accessible to the model. This limitation can be particularly problematic in dynamic domains like healthcare, where new research, guidelines, and patient data are constantly emerging. This is where there is a need for optimization strategies like retrieval-augmented generation and fine-tuning to enhance the model’s performance in specific contexts."
  },
  {
    "objectID": "Exercises/retrieval-augmented-generation/rag.html#addressing-limitations-of-llm-data",
    "href": "Exercises/retrieval-augmented-generation/rag.html#addressing-limitations-of-llm-data",
    "title": "Large Language Models and Retrieval-Augmented Generation: A Technical Overview",
    "section": "Addressing Limitations of LLM data",
    "text": "Addressing Limitations of LLM data\nIt is worth noting that RAG is not the only approach for integrating external knowledge into LLMs (See Figure 2). Another method is fine-tuning, which can be acomplished by training the existing model on new data. However, fine-tuning requires access to a large amount of labeled data, which may not always be available or feasible in practice. RAG, on the other hand, leverages external knowledge sources without modifying the model’s internal parameters, making it a more flexible and scalable solution for incorporating real-world information into LLMs.\n\n\n\n\n\n\nFigure 2: RAG compared with other model optimization methods in the aspects of “External Knowledge Required” and “Model Adaption Required”. Prompt Engineering requires low modifications to the model and external knowledge, focusing on harnessing the capabilities of LLMs themselves. Fine-tuning, on the other hand, involves further training the model. In the early stages of RAG (Naive RAG), there is a low demand for model modifications. As research progresses, Modular RAG has become more integrated with fine-tuning techniques.\n\n\n\nFine-tuning involves modifying the model’s internal parameters to specialize in specific tasks or domains. This process requires high-quality labeled training data pairs and significant computational resources. In contrast, RAG augments the model’s responses with external knowledge without modifying the base model. It mainly requires reference documents or a knowledge base and is computationally less expensive than fine-tuning. RAG is particularly useful for applications that require up-to-date information, compliance with regulations, or domain-specific expertise. Table Table 1 provides a comparison of the features and characteristics of RAG and fine-tuning for model optimization and adaptation.\n\n\n\nTable 1: A comparison of the features and characteristics of RAG vs fine-tuning for model optimization and adaptation.\n\n\n\n\n\n\n\n\n\n\nAspect\nFine-tuning\nRAG\n\n\n\n\nPurpose\nModifies base model weights to specialize in specific tasks/domains\nAugments model responses with external knowledge without modifying the base model\n\n\nTraining Data Requirements\nRequires high-quality labeled training data pairs\nRequires only reference documents/knowledge base\n\n\nComputational Cost\nHigh - requires significant compute resources for training\nLower - mainly needs storage and embedding computation\n\n\nUpdates & Maintenance\nRequires complete retraining to update knowledge\nEasy to update by simply modifying the knowledge base\n\n\nConsistency\nGenerally more consistent in specialized domain\nMay vary based on retrieval quality\n\n\nResponse Speed\nFast inference once trained\nSlightly slower due to retrieval step\n\n\nMemory Requirements\nFixed model size\nScales with knowledge base size\n\n\nHallucination Risk\nLower for domain-specific knowledge\nCan be lower when retrievals are accurate\n\n\nCost\nHigh upfront cost for training\nLower upfront cost, ongoing storage/compute costs\n\n\nUse Cases\n- Domain-specific applications- Style transfer- Consistent brand voice\n- Question answering- Up-to-date information- Compliance requirements\n\n\nFlexibility\nLess flexible - tied to training data\nMore flexible - easy to modify knowledge\n\n\nDevelopment Time\nLonger - requires careful training and validation\nShorter - focus on knowledge engineering\n\n\n\n\n\n\nWe won’t go into the details of fine-tuning here since it is both costly and inconvenient for everyday use. Instead, we will focus on RAG, which is more flexible and cost-effective for augmenting LLMs with external knowledge.\n\nRAG Drivers and Benefits\nRAG addresses several limitations of LLMs by integrating external knowledge retrieval into the generation process. Table Table 2 outlines the key areas where LLMs fall short and how RAG can mitigate these limitations.\n\n\n\nTable 2: Areas where LLMs fall short and how RAG can address these limitations.\n\n\n\n\n\n\n\n\n\nDriver\nDescription\n\n\n\n\nKnowledge Freshness\n• LLMs have a knowledge cutoff date from their training• RAG allows access to current information by retrieving up-to-date documents• Particularly important for rapidly changing domains like tech, news, and business\n\n\nAccuracy & Hallucination Reduction\n• LLMs can sometimes fabricate or “hallucinate” information• RAG grounds responses in specific source documents• Provides citations and references to validate information• Reduces false or inaccurate statements\n\n\nDomain-Specific Knowledge\n• LLMs have broad but sometimes shallow knowledge• RAG enables deep expertise in specific domains by accessing:  - Internal company documents  - Industry-specific materials  - Technical documentation  - Specialized research papers\n\n\nData Privacy & Security\n• Base LLMs don’t have access to private/proprietary information• RAG allows secure access to private documents while maintaining:  - Data sovereignty  - Compliance requirements  - Confidentiality\n\n\nCost Efficiency\n• Fine-tuning LLMs is expensive and resource-intensive• RAG provides a more cost-effective way to augment LLM capabilities• Allows dynamic updates without retraining\n\n\nVerifiability\n• RAG enables tracing responses back to source documents• Important for:  - Compliance requirements  - Audit trails  - Quality assurance  - Building trust in AI systems\n\n\nCustomization\n• Organizations can tailor responses based on their specific knowledge base• Enables consistent messaging and brand voice• Allows for context-aware responses\n\n\nReal-time Information Access\n• RAG can connect to live databases or document stores• Enables responses based on current data states• Useful for dynamic information like inventory or pricing\n\n\n\n\n\n\nOne of the most fundamental limitations and dangers of LLMs is their propensity to generate incorrect or fabricated information, known as hallucination (Zhang et al. 2023). This occurs because LLMs, when faced with incomplete or ambiguous inputs, will still generate outputs that may appear coherent but are not grounded in factual data. In a medical context, this could manifest as the AI confidently suggesting a treatment that is not supported by clinical evidence or misinterpreting symptoms due to the limitations of its training data. For example, if the AI is asked about a rare disease that was underrepresented in its training set, it may generate plausible but inaccurate diagnostic recommendations. Understanding this limitation is critical in fields where the cost of misinformation is high, such as healthcare. RAG can help mitigate this risk by providing the model with accurate, up-to-date information from external sources, reducing the likelihood of hallucination and improving the quality of generated responses.\n\n\nThe Role of Prompts in LLM Interaction\nA prompt is the input provided to the model, serving as the basis for generating a response. In our example, the medical professional’s description of symptoms, medical history, and any specific questions about diagnoses or treatments form the user prompt. There are several types of prompts:\n\nSystem prompts: These set the stage for how the model should behave. For example, a system prompt may instruct the model to maintain a formal, professional tone or limit responses to a concise format appropriate for medical decision-making.\nUser prompts: These are the direct inputs from the user, such as “What are the likely causes of chest pain in a 50-year-old patient with a history of smoking?”\nAdditional context: This refers to background information or structured data that may inform the model’s response, such as the patient’s prior diagnoses, lab results, or family history.\n\nWith commercially available LLMs, we can supply quite a bit of context to the model. For example, we can often drop a PDF into the model to provide additional context. This works well when the context is relatively small and can be easily processed by the model.\nHowever, when the context is large (e.g., multiple books or all patient records for patients in a health system) or would require accessing external systems such as a database, we can utilize retrieval-augmented generation (RAG) to provide the model with the necessary information to generate a response. The RAG approach combines the strengths of LLMs with external knowledge retrieval to enhance the model’s performance in complex, information-rich domains like healthcare.\n\n\nRetrieval-Augmented Generation (RAG)\n\n\n\n\n\n\nFigure 3: Comparison between the three paradigms of RAG. (Left) Naive RAG mainly consists of three parts: indexing, retrieval and generation. (Middle) Advanced RAG proposes multiple optimization strategies around pre-retrieval and post-retrieval, with a process similar to the Naive RAG, still following a chain-like structure. (Right) Modular RAG inherits and develops from the previous paradigm, showcasing greater flexibility overall. This is evident in the introduction of multiple specific functional modules and the replacement of existing modules. The overall process is not limited to sequential retrieval and generation; it includes methods such as iterative and adaptive retrieval.\n\n\n\nTo address the limitations of a model’s built-in knowledge and context window, retrieval-augmented generation (RAG) integrates external knowledge retrieval into the generation process (See Figure 3). In our motivating example, if the medical professional inputs symptoms related to a rare disease, a RAG-enabled system would not rely solely on the LLM’s internal parameters but would retrieve relevant documents—such as the latest clinical guidelines or research papers on the disease—from an external knowledge base.\nRAG systems typically work in two phases:\n\nRetrieval: The model searches a database or corpus of external documents (such as medical research papers or guidelines) for relevant information based on the input.\nGeneration: The retrieved documents are used to inform the model’s response, augmenting the language generation process with precise and up-to-date information.\n\nThis approach significantly reduces the risk of hallucination by grounding responses in verified data. In our use case, RAG would enable the AI to search clinical databases for information about rare diseases, ensuring that its diagnostic suggestions are based on real-world evidence, not just patterns in its training data.\n\n\nEmbeddings and Chunking in RAG\nWhile the most common implementation of RAG involves a two-step process of retrieval followed by generation, the technical details can vary based on the specific use case and system architecture. Table 3 provides an overview of different retrieval approaches for RAG systems, highlighting their best use cases and considerations.\n\n\n\nTable 3: A comparison of different retrieval approaches for RAG systems, including their best use cases and considerations.\n\n\n\n\n\n\n\n\n\n\n\nRetrieval Approach\nDescription\nBest Used For\nConsiderations\n\n\n\n\nVector Databases\n• Store document embeddings for semantic search• Examples: Pinecone, Weaviate, Milvus• Efficient similarity search\n• Unstructured documents• Long-form content• Knowledge bases• Documentation\n• Embedding quality matters• Chunking strategy important• Storage costs for large collections\n\n\nSQL Databases\n• Direct querying of structured data• Can generate SQL from natural language• Precise, structured retrieval\n• Transactional data• Product catalogs• Customer records• Financial data\n• Schema design crucial• Query generation accuracy• Performance with complex joins\n\n\nWeb Search APIs\n• Real-time internet search• APIs like Google Custom Search• Bing Web Search API\n• Current events• Public information• Market research• Competitor analysis\n• Cost per query• Rate limits• Quality of results• Data freshness\n\n\nDomain-Specific APIs\n• Weather APIs• Stock market data• Sports scores• Geographic data\n• Real-time data needs• Specialized information• Dynamic content\n• API reliability• Integration complexity• Costs and rate limits\n\n\nCode Repositories\n• GitHub API• Source code indexing• Documentation sites\n• Technical support• Code examples• API usage• Debugging\n• Code parsing complexity• Version management• Context understanding\n\n\nGraph Databases\n• Neo4j, Amazon Neptune• Relationship-based retrieval• Knowledge graphs\n• Complex relationships• Network analysis• Dependencies\n• Graph query complexity• Maintenance overhead• Schema design\n\n\nHybrid Search\n• Combines multiple approaches• Example: keyword + semantic search• Multi-index retrieval\n• Complex queries• Diverse content types• High accuracy needs\n• Orchestration complexity• Result ranking• Performance overhead\n\n\nFile Systems\n• Local document storage• Network drives• Document management systems\n• Internal documents• Legacy systems• Offline access\n• File format handling• Access permissions• Indexing overhead\n\n\nCache Layers\n• Redis, Memcached• Frequently accessed data• Results caching\n• High-performance needs• Repeated queries• Cost optimization\n• Cache invalidation• Storage limits• Consistency management\n\n\n\n\n\n\nWhen thinking about applying RAG to a specific use case, it is essential to consider the retrieval approach that best suits the data sources and information needs. For example, a healthcare AI system may benefit from using vector databases to store document embeddings for semantic search, enabling efficient retrieval of relevant medical literature based on input symptoms. On the other hand, a financial advisory chatbot could leverage SQL databases to query structured data on stock prices and market trends in real time. A private practice clinic might use domain-specific APIs to access patient appointment schedules and medical records securely.\n\n\nEmbeddings and Chunking in RAG\nTwo critical components of RAG are embeddings and chunking.\n\nEmbeddings: Embeddings are vector representations of text that capture the semantic meaning of words and phrases. In the retrieval step, the input (e.g., symptoms or a diagnostic question) is transformed into an embedding, which is then used to search the knowledge base for relevant information. Embeddings ensure that even if the input uses different terminology, the retrieval process can still match it with relevant documents that use similar meanings.\nIn our example, the AI system would convert the input symptoms into an embedding and use it to search for medical documents that discuss those symptoms, even if the wording differs slightly (e.g., “myocardial infarction” versus “heart attack”).\nChunking: Large documents, such as clinical guidelines or research papers, are often too extensive to process in their entirety. Chunking breaks these documents into smaller, manageable sections, allowing the model to retrieve specific parts relevant to the input. When a document on cardiovascular health is divided into chunks, the model can retrieve only the sections related to smoking and chest pain, rather than processing the entire document.\n\nThese techniques allow the AI system to quickly access relevant information without being overwhelmed by the volume of text."
  },
  {
    "objectID": "Exercises/retrieval-augmented-generation/rag.html#exercises",
    "href": "Exercises/retrieval-augmented-generation/rag.html#exercises",
    "title": "Large Language Models and Retrieval-Augmented Generation: A Technical Overview",
    "section": "Exercises",
    "text": "Exercises\n\nGive google notebookLM a try.\nUse notebookLM to create and interact with a notebook about retrieval augmented generation. Include resources such as papers, blog posts, chatgpt responses (text), videos."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "IDPT-8079: Frontier of AI in Medicine",
    "section": "",
    "text": "This is a collection of talks on various topics in machine learning and artificial intelligence. It also includes some exercises and interactive demos."
  },
  {
    "objectID": "index.html#talks",
    "href": "index.html#talks",
    "title": "IDPT-8079: Frontier of AI in Medicine",
    "section": "Talks",
    "text": "Talks\n\n\n   \n     \n     \n       Order By\n       Default\n         \n          Title\n        \n         \n          Date - Oldest\n        \n         \n          Date - Newest\n        \n         \n          Author\n        \n     \n  \n    \n      \n      \n    \n\n\n\n\n\n\n\n\n\n\nAI Agents\n\n\nLearn how large language models can be used as agents to solve complex tasks by interacting with external tools.\n\n\n\nSean Davis, Sean Davis, MD, PhD\n\n\nOct 17, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAI in Medical Education\n\n\n\n\n\n\nSean Davis, Sean Davis, MD, PhD\n\n\nOct 23, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nIntroduction to Machine Learning\n\n\n\n\n\n\nSean Davis, Sean Davis, MD, PhD\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPrompt Engineering\n\n\n\nteaching\n\n\n\nLearn design principles for effective prompts for language models to improve accuracy, usability, and relevance of model outputs.\n\n\n\nSean Davis, Sean Davis, MD, PhD\n\n\nOct 17, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nThe History of Artificial Intelligence and Machine Learning\n\n\n\n\n\n\nSean Davis, Sean Davis, MD, PhD\n\n\nSep 19, 2024\n\n\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "index.html#exercises",
    "href": "index.html#exercises",
    "title": "IDPT-8079: Frontier of AI in Medicine",
    "section": "Exercises",
    "text": "Exercises\n\n\n\n\n\n\n\n\n\n\nBuild an Expert System using Prolog\n\n\n\n\n\nLearn how to build a simple expert system using Prolog, a logic programming language, to diagnose common conditions like colds, flu, and allergies based on a set of symptoms.\n\n\n\n\n\nOct 2, 2024\n\n\nSean Davis\n\n\n\n\n\n\n\n\n\n\n\n\nLarge Language Models and Retrieval-Augmented Generation: A Technical Overview\n\n\n\n\n\n\n\n\n\n\n\nSean Davis\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "talks/word-embedding-exercises.html",
    "href": "talks/word-embedding-exercises.html",
    "title": "Experiments in Word Embeddings",
    "section": "",
    "text": "Recall that word embeddings are a way of representing words as vectors in a high-dimensional space. The idea is that words that are similar in meaning should be close together in this space. Word embeddings are often used as a way of representing words in natural language processing tasks, such as sentiment analysis, machine translation, and named entity recognition. Figure 1 schematically illustrates how words are represented in a vector space.\n\n\n\n\n\n\nFigure 1: Linear combinations of dimensions in vector space correlate with the semantic and syntactic roles of the words in the corpus1. For illustration purposes, dimension d1 in the figure has a high positive correlation with living beings. A properly tuned word embedding model will map words with similar semantic or syntactic roles to adjacent regions in vector space. This property can be visualized through dimensionality reduction techniques such as t-SNE or PCA. Cultural concepts are also apparent in vector space as consistent offsets between vector representations of words sharing a particular relationship. For instance, in the bottom right of the figure, the dotted vector represents a gender regularity that goes from masculinity to femininity.\n\n\n\nIn this set of experiments, we’ll be using some online tools that allow us to explore word embeddings. We’ll be using the TensorFlow Embedding Projector and the Word2Vec tool from Google.\n\n\nThe TensorFlow Embedding Projector is a web-based tool that allows you to visualize word embeddings in a 3D space. You can use it to explore the relationships between words and see how they are clustered together. Navigate to the TensorFlow Embedding Projector and experiment a bit.\n\nBy mousing over the points in the 3D space, you can see the words that are closest to a given word. You can also search for a specific word and see how it is related to other words in the space. If you click on a word, you can see a list of the words that are closest to it (based on cosine similarity in the embedding space, not necessarily in the 2D projection).\n\n\n\n\n\nIn this page, you can supply a word and the tool will find words that are similar in meaning. The “model” choice is based on the text that was used to train the embeddings (eg. Wikipedia, Google News, etc.). The numbers next to the words are the cosine similarity between the input word and the word in the list.\nExercise: Navigate to http://vectors.nlpl.eu/explore/embeddings/en/associates/ and experiment a bit.\n\n\n\nThis little tool allows you to visualize word embeddings in 2D. You can see how words are related to each other based on their embeddings. You’ll supply a list of words and the tool will show you how they are related to each other using TSNE or PCA (these are dimensionality reduction techniques that allow you to visualize high-dimensional data in 2D). The “model” choice is based on the text that was used to train the embeddings (eg. Wikipedia, Google News, etc.).\nExercise: Navigate to http://vectors.nlpl.eu/explore/embeddings/en/visual/ and experiment a bit.\n\n\n\n\nCalculate ratios, such as «find a word D related to the word C in the same way as the word A is related to the word B». An example is given in the placeholder: which word is in the same relation to the word «father» as «daughter» is to «mother»? The answer is «son». The model calculates the difference between the vectors of «mother» and «daughter» and adds it to the vector of «father». After doing so, the word with the closest vector to the result is output, which in this case is «son».\nSo, what does the difference between the vectors of «mother» and «daughter» represent? It represents the concept of a parent-child relationship. By adding this difference to the vector of «father», the model is looking for a word that is related to «father» in the same way that «daughter» is related to «mother». In this case, the answer is «son».\nExercise: Navigate to http://vectors.nlpl.eu/explore/embeddings/en/calculator/ and experiment a bit, perhaps trying some of the examples from Table 1.\nA few examples to try:\n\n\n\nTable 1: Some examples to try in the semantic calculator. What will be the result for word 4?\n\n\n\n\n\nWord 1\nWord 2\nWord 3\nWord 4\n\n\n\n\ndog\npuppy\ncat\n?\n\n\nking\nman\nqueen\n?\n\n\ncat\nkitten\nhorse\n?\n\n\nking\nboyfriend\nqueen\n?\n\n\nheart\nlungs\nstomach\n?"
  },
  {
    "objectID": "talks/word-embedding-exercises.html#tensorflow-embedding-projector",
    "href": "talks/word-embedding-exercises.html#tensorflow-embedding-projector",
    "title": "Experiments in Word Embeddings",
    "section": "",
    "text": "The TensorFlow Embedding Projector is a web-based tool that allows you to visualize word embeddings in a 3D space. You can use it to explore the relationships between words and see how they are clustered together. Navigate to the TensorFlow Embedding Projector and experiment a bit.\n\nBy mousing over the points in the 3D space, you can see the words that are closest to a given word. You can also search for a specific word and see how it is related to other words in the space. If you click on a word, you can see a list of the words that are closest to it (based on cosine similarity in the embedding space, not necessarily in the 2D projection)."
  },
  {
    "objectID": "talks/word-embedding-exercises.html#webvectors",
    "href": "talks/word-embedding-exercises.html#webvectors",
    "title": "Experiments in Word Embeddings",
    "section": "",
    "text": "In this page, you can supply a word and the tool will find words that are similar in meaning. The “model” choice is based on the text that was used to train the embeddings (eg. Wikipedia, Google News, etc.). The numbers next to the words are the cosine similarity between the input word and the word in the list.\nExercise: Navigate to http://vectors.nlpl.eu/explore/embeddings/en/associates/ and experiment a bit.\n\n\n\nThis little tool allows you to visualize word embeddings in 2D. You can see how words are related to each other based on their embeddings. You’ll supply a list of words and the tool will show you how they are related to each other using TSNE or PCA (these are dimensionality reduction techniques that allow you to visualize high-dimensional data in 2D). The “model” choice is based on the text that was used to train the embeddings (eg. Wikipedia, Google News, etc.).\nExercise: Navigate to http://vectors.nlpl.eu/explore/embeddings/en/visual/ and experiment a bit.\n\n\n\n\nCalculate ratios, such as «find a word D related to the word C in the same way as the word A is related to the word B». An example is given in the placeholder: which word is in the same relation to the word «father» as «daughter» is to «mother»? The answer is «son». The model calculates the difference between the vectors of «mother» and «daughter» and adds it to the vector of «father». After doing so, the word with the closest vector to the result is output, which in this case is «son».\nSo, what does the difference between the vectors of «mother» and «daughter» represent? It represents the concept of a parent-child relationship. By adding this difference to the vector of «father», the model is looking for a word that is related to «father» in the same way that «daughter» is related to «mother». In this case, the answer is «son».\nExercise: Navigate to http://vectors.nlpl.eu/explore/embeddings/en/calculator/ and experiment a bit, perhaps trying some of the examples from Table 1.\nA few examples to try:\n\n\n\nTable 1: Some examples to try in the semantic calculator. What will be the result for word 4?\n\n\n\n\n\nWord 1\nWord 2\nWord 3\nWord 4\n\n\n\n\ndog\npuppy\ncat\n?\n\n\nking\nman\nqueen\n?\n\n\ncat\nkitten\nhorse\n?\n\n\nking\nboyfriend\nqueen\n?\n\n\nheart\nlungs\nstomach\n?"
  },
  {
    "objectID": "talks/word-embedding-exercises.html#footnotes",
    "href": "talks/word-embedding-exercises.html#footnotes",
    "title": "Experiments in Word Embeddings",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nhttps://doi.org/10.1371/journal.pone.0231189↩︎"
  },
  {
    "objectID": "talks/ai-in-medical-education/index.html#section",
    "href": "talks/ai-in-medical-education/index.html#section",
    "title": "AI in Medical Education",
    "section": "",
    "text": "“Maybe once every few decades a true revolution occurs in the way we teach medical students and what we expect them to be able to do when they become doctors. This is one of those times.”\n\n\n– Bernard Chang, MMSc ’05, HMS dean for medical education, Speaking about ChatGPT and Generative AI in Medical Education"
  },
  {
    "objectID": "talks/ai-in-medical-education/index.html#what-we-will-not-cover-today",
    "href": "talks/ai-in-medical-education/index.html#what-we-will-not-cover-today",
    "title": "AI in Medical Education",
    "section": "What we will not cover today",
    "text": "What we will not cover today\n\nPersonal use of AI in medical education\nMany, many examples of AI in medical education"
  },
  {
    "objectID": "talks/ai-in-medical-education/index.html#the-academic-medical-center-view",
    "href": "talks/ai-in-medical-education/index.html#the-academic-medical-center-view",
    "title": "AI in Medical Education",
    "section": "The academic medical center view",
    "text": "The academic medical center view\n\n\nhttps://seandavi.github.io/campus-llm-kb/framework.html"
  },
  {
    "objectID": "talks/ai-in-medical-education/index.html#hypothetical-application-of-ai-in-education",
    "href": "talks/ai-in-medical-education/index.html#hypothetical-application-of-ai-in-education",
    "title": "AI in Medical Education",
    "section": "Hypothetical application of AI in education",
    "text": "Hypothetical application of AI in education\nYou are on the faculty of a medical school that has proposed to use ChatGPT to help draft letters of recommendation for medical school residency programs for its students.\n\nWhat are your thoughts?\nWhat are some specific concerns and recommendations that you would recommend to faculty leaders?"
  },
  {
    "objectID": "talks/ai-in-medical-education/index.html#what-do-llms-know-about-medicine",
    "href": "talks/ai-in-medical-education/index.html#what-do-llms-know-about-medicine",
    "title": "AI in Medical Education",
    "section": "What do LLMs know about medicine?",
    "text": "What do LLMs know about medicine?\n\n\nhttps://arxiv.org/abs/2305.09617"
  },
  {
    "objectID": "talks/ai-in-medical-education/index.html#what-do-llms-know-about-medicine-1",
    "href": "talks/ai-in-medical-education/index.html#what-do-llms-know-about-medicine-1",
    "title": "AI in Medical Education",
    "section": "What do LLMs know about medicine?",
    "text": "What do LLMs know about medicine?\n\n\nhttps://arxiv.org/abs/2305.09617"
  },
  {
    "objectID": "talks/ai-in-medical-education/index.html#androgogy",
    "href": "talks/ai-in-medical-education/index.html#androgogy",
    "title": "AI in Medical Education",
    "section": "Androgogy",
    "text": "Androgogy\nIn addition to mutual respect, collaboration, support, mutual trust, and fun, additional key drivers of adult learning include\n\nBuilding on experience: Adults learn by relating new information to their own experiences and the experiences of others.\nLearning by doing: Adults need time for application exercises to practice new skills and knowledge. Different learning styles and rates: Adults learn in different ways and at different rates, so use a variety of instructional methods.\nKnowing why they need to learn: Adults need to know why they need to learn something.\nFeeling responsible for learning: Adults need to feel responsible for their learning.\nProblem focused: Adults want their training to be problem focused.\nIntrinsic motivation: Adults learn best when motivation comes intrinsically.\nFeedback and interaction: builds confidence which is a large component of learning success."
  },
  {
    "objectID": "talks/ai-in-medical-education/index.html#scoping-review-of-ai-in-medical-education",
    "href": "talks/ai-in-medical-education/index.html#scoping-review-of-ai-in-medical-education",
    "title": "AI in Medical Education",
    "section": "Scoping review of AI in medical education",
    "text": "Scoping review of AI in medical education\n\n\nhttps://doi.org/10.1080/0142159X.2024.2314198"
  },
  {
    "objectID": "talks/ai-in-medical-education/index.html#ai-for-admissions-and-selection",
    "href": "talks/ai-in-medical-education/index.html#ai-for-admissions-and-selection",
    "title": "AI in Medical Education",
    "section": "AI for Admissions and Selection",
    "text": "AI for Admissions and Selection\n\nAI can improve the admissions process by:\n\nPredicting student success (AUC of 0.925 in one study).\nAnalyzing application materials using sentiment analysis.\nAugmenting traditional holistic reviews.\n\nExample: ML models accurately ranked medical applicants based on retrospective data.\n\n\nhttps://doi.org/10.1080/0142159X.2024.2314198"
  },
  {
    "objectID": "talks/ai-in-medical-education/index.html#ai-augmented-instruction",
    "href": "talks/ai-in-medical-education/index.html#ai-augmented-instruction",
    "title": "AI in Medical Education",
    "section": "AI-Augmented Instruction",
    "text": "AI-Augmented Instruction\n\nAI for Personalized Education:\n\nAdaptive learning systems for tailoring content to individual student needs.\nExample: AI-driven tutoring systems providing real-time feedback during ultrasound training.\n\nAI-Enhanced Simulations:\n\nVirtual reality and AI-powered simulators used for surgery and clinical skills training.\nExample: Robotic surgery simulators to assess surgical competency.\n\n\n\nhttps://doi.org/10.1080/0142159X.2024.2314198"
  },
  {
    "objectID": "talks/ai-in-medical-education/index.html#ai-in-teaching-clinical-reasoning",
    "href": "talks/ai-in-medical-education/index.html#ai-in-teaching-clinical-reasoning",
    "title": "AI in Medical Education",
    "section": "AI in Teaching Clinical Reasoning",
    "text": "AI in Teaching Clinical Reasoning\n\nVirtual Patient Simulators (VPS):\n\nAI-driven platforms simulate real patient encounters.\nStudents interact with avatars or text interfaces, practicing hypothesis generation and clinical reasoning.\n\nIntelligent Tutoring Systems (ITS):\n\nProvides personalized feedback based on student inputs and performance.\nExample: NLP algorithms creating virtual patient case libraries.\n\n\n\nhttps://doi.org/10.1080/0142159X.2024.2314198"
  },
  {
    "objectID": "talks/ai-in-medical-education/index.html#ai-in-assessments",
    "href": "talks/ai-in-medical-education/index.html#ai-in-assessments",
    "title": "AI in Medical Education",
    "section": "AI in Assessments",
    "text": "AI in Assessments\n\nAI for Objective Structured Clinical Examinations (OSCE):\n\nAI enhances clinical skills assessments, reducing bias and logistical demands.\nAI can automate grading and real-time feedback during simulations.\n\nAI in Narrative Analysis:\n\nNLP for analyzing student reflections, faculty evaluations, and identifying bias in feedback.\nExample: AI assessed medical narratives for professionalism and clinical competency.\n\n\n\nhttps://doi.org/10.1080/0142159X.2024.2314198"
  },
  {
    "objectID": "talks/ai-in-medical-education/index.html#ai-generated-multiple-choice-questions",
    "href": "talks/ai-in-medical-education/index.html#ai-generated-multiple-choice-questions",
    "title": "AI in Medical Education",
    "section": "AI-Generated Multiple Choice Questions",
    "text": "AI-Generated Multiple Choice Questions\n\nAI can create and assess multiple-choice questions for exams.\nChatGPT has been widely tested, with mixed results in MCQ creation.\nExample: LLMs (Large Language Models) were tested on national licensure exams and performed comparably to humans in many cases.\n\n\nhttps://doi.org/10.1080/0142159X.2024.2314198"
  },
  {
    "objectID": "talks/ai-in-medical-education/index.html#ai-for-procedural-skills-and-automation",
    "href": "talks/ai-in-medical-education/index.html#ai-for-procedural-skills-and-automation",
    "title": "AI in Medical Education",
    "section": "AI for Procedural Skills and Automation",
    "text": "AI for Procedural Skills and Automation\n\nAI aids in documenting procedural and clinical experiences.\n\nNLP algorithms track clinical logs and case experiences, boosting accuracy and efficiency.\nExample: AI systems tracking neurology resident experiences, tripling the logged cases.\n\n\n\nhttps://doi.org/10.1080/0142159X.2024.2314198"
  },
  {
    "objectID": "talks/ai-in-medical-education/index.html#attitudes-toward-ai-in-medical-education",
    "href": "talks/ai-in-medical-education/index.html#attitudes-toward-ai-in-medical-education",
    "title": "AI in Medical Education",
    "section": "Attitudes Toward AI in Medical Education",
    "text": "Attitudes Toward AI in Medical Education\n\nMixed perceptions on AI’s role:\n\nMany students recognize AI’s benefits, such as enhanced clinical decision-making.\nConcerns about AI’s impact on doctor-patient relationships and potential over-reliance on technology.\n\nCalls for comprehensive AI curricula to prepare future physicians for AI integration.\n\n\nhttps://doi.org/10.1080/0142159X.2024.2314198"
  },
  {
    "objectID": "talks/ai-in-medical-education/index.html#ethical-considerations",
    "href": "talks/ai-in-medical-education/index.html#ethical-considerations",
    "title": "AI in Medical Education",
    "section": "Ethical Considerations",
    "text": "Ethical Considerations\n\nBias and equity: AI models trained on non-representative data may exacerbate healthcare disparities.\nTransparency: Students must understand the ethical implications of AI’s involvement in clinical decisions.\nAutomation Bias: Students must maintain critical thinking skills and not overly rely on AI outputs.\n\nExample: AI in admissions can help reduce bias in holistic reviews but also risks introducing new biases.\n\n\n\nhttps://doi.org/10.1080/0142159X.2024.2314198"
  },
  {
    "objectID": "talks/ai-in-medical-education/index.html#a-sampling-of-policies-from-various-institutions",
    "href": "talks/ai-in-medical-education/index.html#a-sampling-of-policies-from-various-institutions",
    "title": "AI in Medical Education",
    "section": "A sampling of policies from various institutions",
    "text": "A sampling of policies from various institutions\n\n\n\nCarnegie Mellon University Examples of AI use policies for educators\nUniversity of Iowa, Office of Teaching, Learning, and Technology\nSFCC Library Faculty Help\nCleveland State University Center for Faculty Excellence\nClassroom Policies Related to ChatGPT and Other AI Tools\n\n\n\nMontclair State University AI Course Policies and Assignment Guidelines\nInside HigherEd Opinion Piece on Generative AI Policy Making\nStanford\nUpdate Your Syllabus for ChatGPT\nRules for Tools (from Padagogische Hochschule Heidelberg)\n\n\n\nhttps://seandavi.github.io/campus-llm-kb/resources_education.html#educational-policy-statements-and-guidelines"
  },
  {
    "objectID": "talks/ai-in-medical-education/index.html#thinking-about-academic-integrity",
    "href": "talks/ai-in-medical-education/index.html#thinking-about-academic-integrity",
    "title": "AI in Medical Education",
    "section": "Thinking about academic integrity",
    "text": "Thinking about academic integrity\n\nIs there such a thing as “ChatGPT-proofing” your assignments?\nThe better question to ask is, “why do students plagiarize?”\n\nThe student may feel like they don’t know what a successful submission is, fear failing, or simply think something that wasn’t written specifically for the class can pass muster.\n\nHow do we approach building our assignments so there is trust between the instructor and student?\n\nThe instructor trusts that students will approach the assignment with motivation and a desire to put their own voice into the work.\nThe student trusts that the work they’re doing is meaningful and worth any struggle or challenges they come across."
  },
  {
    "objectID": "talks/ai-in-medical-education/index.html#appeals-for-academic-integrity",
    "href": "talks/ai-in-medical-education/index.html#appeals-for-academic-integrity",
    "title": "AI in Medical Education",
    "section": "Appeals for academic integrity",
    "text": "Appeals for academic integrity\nMost institutions include a formal academic code of conduct. However, it is often helpful to remind students of the importance of academic integrity and the consequences of cheating. Here are some appeals that can be used to encourage students to maintain academic integrity."
  },
  {
    "objectID": "talks/ai-in-medical-education/index.html#academic-integrity-logical-appeal",
    "href": "talks/ai-in-medical-education/index.html#academic-integrity-logical-appeal",
    "title": "AI in Medical Education",
    "section": "Academic integrity: Logical appeal",
    "text": "Academic integrity: Logical appeal\nCheating diminishes the value of this credential/course/degree. There will very soon come a time when you will need the skills and knowledge being assessed in this course, and you don’t want to find yourself in a position in which your pre-requisite/credentialed knowledge is fraudulent.\n\nhttps://teaching.cornell.edu/teaching-resources/assessment-evaluation/promoting-academic-integrity-your-course"
  },
  {
    "objectID": "talks/ai-in-medical-education/index.html#academic-integrity-emotional-moral-appeal",
    "href": "talks/ai-in-medical-education/index.html#academic-integrity-emotional-moral-appeal",
    "title": "AI in Medical Education",
    "section": "Academic integrity: Emotional (moral) appeal",
    "text": "Academic integrity: Emotional (moral) appeal\nCheating is a temptation, of course, but it’s your personal integrity on the line. We are [NAME OF INSTITUTION] (YOU are [NAME OF INSTUTION]), and we are called to do the right thing.\n\nhttps://teaching.cornell.edu/teaching-resources/assessment-evaluation/promoting-academic-integrity-your-course"
  },
  {
    "objectID": "talks/ai-in-medical-education/index.html#academic-integrity-personal-appeal",
    "href": "talks/ai-in-medical-education/index.html#academic-integrity-personal-appeal",
    "title": "AI in Medical Education",
    "section": "Academic integrity: Personal appeal",
    "text": "Academic integrity: Personal appeal\nAs I have made every effort to continue our class’s sense of community and purpose, I’m asking you to make every effort to be honest and honorable in the demonstration of what you have learned in our class.\n\nhttps://teaching.cornell.edu/teaching-resources/assessment-evaluation/promoting-academic-integrity-your-course"
  },
  {
    "objectID": "talks/ai-in-medical-education/index.html#policies-on-ai-use-in-the-classroom",
    "href": "talks/ai-in-medical-education/index.html#policies-on-ai-use-in-the-classroom",
    "title": "AI in Medical Education",
    "section": "Policies on AI use in the classroom",
    "text": "Policies on AI use in the classroom\nContent-generating AI is NOT Allowed:\n\nUnder this category, the use of AI tools is strictly prohibited. These syllabi are clear that work produced by students must be entirely original, and the use of AI-generated content will be considered academic misconduct.\nStatements falling into this category emphasize the core value of academic originality and stress the importance of mastering subjects without undue reliance on technological shortcuts.\n\n\nhttps://academic.wlu.edu/2023/08/17/thinking-about-updating-your-syllabus-for-chatgpt/"
  },
  {
    "objectID": "talks/ai-in-medical-education/index.html#policies-on-ai-use-in-the-classroom-1",
    "href": "talks/ai-in-medical-education/index.html#policies-on-ai-use-in-the-classroom-1",
    "title": "AI in Medical Education",
    "section": "Policies on AI use in the classroom",
    "text": "Policies on AI use in the classroom\nContent-generating AI is Allowed with Appropriate Attribution:\n\nPolicies in this grouping permit the use of AI for certain tasks or specific assignments, provided it is properly attributed. Students must clearly identify any writing, text, or media generated by AI when submitting work. They are also responsible for the accuracy of any generated content.\nSyllabi in this group might specify, for instance, that if a student employs AI tools like ChatGPT to generate content, this fact must be clearly indicated in their submission. The emphasis is on transparency and understanding the origin of academic materials.\n\n\nhttps://academic.wlu.edu/2023/08/17/thinking-about-updating-your-syllabus-for-chatgpt/"
  },
  {
    "objectID": "talks/ai-in-medical-education/index.html#policies-on-ai-use-in-the-classroom-2",
    "href": "talks/ai-in-medical-education/index.html#policies-on-ai-use-in-the-classroom-2",
    "title": "AI in Medical Education",
    "section": "Policies on AI use in the classroom",
    "text": "Policies on AI use in the classroom\nContent-generating AI Use is Allowed in LIMITED Instances\n\nThis grouping offers a middle ground. While AI is not entirely banned, its use is curtailed to very specific instances or types of assignments.\nSyllabi in this category might allow AI tools for preliminary stages of research, brainstorming, or concept development, but not for final submissions. Here, AI is viewed as an assistant rather than a creator, helping students in the preparation and formulation, but not execution of their academic tasks.\n\n\nhttps://academic.wlu.edu/2023/08/17/thinking-about-updating-your-syllabus-for-chatgpt/"
  },
  {
    "objectID": "talks/ai-in-medical-education/index.html#policies-on-ai-use-in-the-classroom-3",
    "href": "talks/ai-in-medical-education/index.html#policies-on-ai-use-in-the-classroom-3",
    "title": "AI in Medical Education",
    "section": "Policies on AI use in the classroom",
    "text": "Policies on AI use in the classroom\nContent-generating AI Use is Encouraged Broadly\n\nThe most progressive of the groupings, these policies embrace AI as a significant component of a rapidly evolving tech landscape.\nThese syllabi might encourage students to explore AI’s capabilities, suggesting that they employ these tools in various assignments to understand their potential and limitations. However, they still emphasize the importance of integrity, ensuring students do not misuse AI, but rather incorporate it as part of a holistic learning experience.\n\n\nhttps://academic.wlu.edu/2023/08/17/thinking-about-updating-your-syllabus-for-chatgpt/"
  },
  {
    "objectID": "talks/ai-in-medical-education/index.html#recognize-that-ai-in-medical-education-is-still-about-education",
    "href": "talks/ai-in-medical-education/index.html#recognize-that-ai-in-medical-education-is-still-about-education",
    "title": "AI in Medical Education",
    "section": "Recognize that AI in medical education is STILL about education",
    "text": "Recognize that AI in medical education is STILL about education\n\n\nhttps://www.chronicle.com/article/how-chatgpt-could-help-or-hurt-students-with-disabilities"
  },
  {
    "objectID": "talks/ai-in-medical-education/index.html#tips-for-addressing-ethical-concerns-of-ai-in-medical-education",
    "href": "talks/ai-in-medical-education/index.html#tips-for-addressing-ethical-concerns-of-ai-in-medical-education",
    "title": "AI in Medical Education",
    "section": "Tips for addressing ethical concerns of AI in medical education",
    "text": "Tips for addressing ethical concerns of AI in medical education\n\nThis article discusses the ethical challenges that arise with the integration of artificial intelligence (AI) in medical education. The authors present twelve practical tips to guide medical educators in addressing these ethical issues and ensuring the responsible use of AI in educational settings.\n\nhttps://pmc.ncbi.nlm.nih.gov/articles/PMC10993743/"
  },
  {
    "objectID": "talks/ai-in-medical-education/index.html#ethical-framework-for-ai-in-medical-education",
    "href": "talks/ai-in-medical-education/index.html#ethical-framework-for-ai-in-medical-education",
    "title": "AI in Medical Education",
    "section": "Ethical framework for AI in medical education",
    "text": "Ethical framework for AI in medical education\n\n\nhttps://doi.org/10.1080/0142159X.2024.2314198"
  },
  {
    "objectID": "talks/ai-in-medical-education/index.html#tips-for-addressing-ethical-concerns-of-ai-in-medical-education-1",
    "href": "talks/ai-in-medical-education/index.html#tips-for-addressing-ethical-concerns-of-ai-in-medical-education-1",
    "title": "AI in Medical Education",
    "section": "Tips for addressing ethical concerns of AI in medical education",
    "text": "Tips for addressing ethical concerns of AI in medical education\n\nEnsure transparency in AI development and deployment.\nAddress biases in AI algorithms to ensure fair educational representation.\nValidate AI-generated educational content for accuracy and credibility.\nPrioritize privacy with robust measures for protecting student and patient data.\n\n\nhttps://pmc.ncbi.nlm.nih.gov/articles/PMC10993743/"
  },
  {
    "objectID": "talks/ai-in-medical-education/index.html#tips-for-addressing-ethical-concerns-of-ai-in-medical-education-2",
    "href": "talks/ai-in-medical-education/index.html#tips-for-addressing-ethical-concerns-of-ai-in-medical-education-2",
    "title": "AI in Medical Education",
    "section": "Tips for addressing ethical concerns of AI in medical education",
    "text": "Tips for addressing ethical concerns of AI in medical education\n\nObtain informed consent from students and stakeholders for AI usage.\nFoster collaboration between AI experts, educators, and students.\nConduct faculty development programs on AI ethics.\nProvide student education on AI’s implications in medical education.\n\n\nhttps://pmc.ncbi.nlm.nih.gov/articles/PMC10993743/"
  },
  {
    "objectID": "talks/ai-in-medical-education/index.html#tips-for-addressing-ethical-concerns-of-ai-in-medical-education-3",
    "href": "talks/ai-in-medical-education/index.html#tips-for-addressing-ethical-concerns-of-ai-in-medical-education-3",
    "title": "AI in Medical Education",
    "section": "Tips for addressing ethical concerns of AI in medical education",
    "text": "Tips for addressing ethical concerns of AI in medical education\n\nEnsure ongoing maintenance of AI algorithms for performance and reliability.\nEstablish clear lines of accountability for AI systems.\nEnhance regulatory awareness of AI standards in healthcare and education.\nForm ethics committees or engage institutional review boards for ethical oversight of AI.\n\n\nhttps://pmc.ncbi.nlm.nih.gov/articles/PMC10993743/"
  },
  {
    "objectID": "talks/ai-in-medical-education/index.html#contributed-resources",
    "href": "talks/ai-in-medical-education/index.html#contributed-resources",
    "title": "AI in Medical Education",
    "section": "Contributed resources",
    "text": "Contributed resources\n\nLarge Language Models for Education: A Survey and Outlook\nAI and the future of medical education\nAI and Medical Student Learninghttps://pmc.ncbi.nlm.nih.gov/articles/PMC10755136/\nResidency Applications in the Era of Generative Artificial Intelligence"
  },
  {
    "objectID": "talks/ai-in-medical-education/index.html#understanding-the-ai-ecosystem-at-your-institution",
    "href": "talks/ai-in-medical-education/index.html#understanding-the-ai-ecosystem-at-your-institution",
    "title": "AI in Medical Education",
    "section": "Understanding the AI ecosystem at your institution",
    "text": "Understanding the AI ecosystem at your institution\n\nFACETS framework to report future AI innovations in medical education."
  },
  {
    "objectID": "talks/ai-in-medical-education/index.html#go-forth-and-educate",
    "href": "talks/ai-in-medical-education/index.html#go-forth-and-educate",
    "title": "AI in Medical Education",
    "section": "Go forth and educate!",
    "text": "Go forth and educate!"
  },
  {
    "objectID": "talks/ai-agents/llm-2.html#beyond-text-llms-as-agents",
    "href": "talks/ai-agents/llm-2.html#beyond-text-llms-as-agents",
    "title": "AI Agents",
    "section": "Beyond Text: LLMs as Agents",
    "text": "Beyond Text: LLMs as Agents\n\nTraditional LLMs excel at text generation, but their knowledge is limited to their training data.\nTool use allows LLMs to become active agents, interacting with the real world.\nExamples: retrieving up-to-date information, performing calculations, running code, controlling software."
  },
  {
    "objectID": "talks/ai-agents/llm-2.html#when-rag-is-not-enough",
    "href": "talks/ai-agents/llm-2.html#when-rag-is-not-enough",
    "title": "AI Agents",
    "section": "When RAG is not enough",
    "text": "When RAG is not enough"
  },
  {
    "objectID": "talks/ai-agents/llm-2.html#the-rationale-for-tool-use",
    "href": "talks/ai-agents/llm-2.html#the-rationale-for-tool-use",
    "title": "AI Agents",
    "section": "The Rationale for Tool Use",
    "text": "The Rationale for Tool Use\n\nOvercoming Knowledge Limitations: Accessing external data sources like the internet or specific databases keeps the LLM’s knowledge current and relevant.\nEnhancing Capabilities: Tools allow LLMs to perform tasks they cannot do independently, like booking a flight or controlling a smart home device.\nImproving Accuracy: Using tools for tasks like calculations or fact-checking ensures more reliable outputs."
  },
  {
    "objectID": "talks/ai-agents/llm-2.html#components-of-llm-tools",
    "href": "talks/ai-agents/llm-2.html#components-of-llm-tools",
    "title": "AI Agents",
    "section": "Components of LLM Tools",
    "text": "Components of LLM Tools\n\nAPI: The interface that allows the LLM to communicate with the tool.\nDescription: A clear definition of the tool’s function, inputs, and outputs. This allows the LLM to understand how to use the tool correctly.\nInvoker: A mechanism that triggers the tool based on the LLM’s instructions."
  },
  {
    "objectID": "talks/ai-agents/llm-2.html#what-is-an-api",
    "href": "talks/ai-agents/llm-2.html#what-is-an-api",
    "title": "AI Agents",
    "section": "What is an API?",
    "text": "What is an API?\n\nAPI stands for Application Programming Interface.\nIt’s a set of rules and specifications that allow one application to access the features or data of another application.\nThis enables different applications to communicate and interact with each other."
  },
  {
    "objectID": "talks/ai-agents/llm-2.html#apis-and-llm-tools",
    "href": "talks/ai-agents/llm-2.html#apis-and-llm-tools",
    "title": "AI Agents",
    "section": "APIs and LLM Tools",
    "text": "APIs and LLM Tools\n\nAPIs are the foundation of LLM tool use.\nThey provide the communication channel between the LLM and the external tool.\nThe LLM uses the API to send requests to the tool and receive responses."
  },
  {
    "objectID": "talks/ai-agents/llm-2.html#how-llms-use-tools",
    "href": "talks/ai-agents/llm-2.html#how-llms-use-tools",
    "title": "AI Agents",
    "section": "How LLMs Use Tools",
    "text": "How LLMs Use Tools\n\nTask Identification: The LLM analyzes the user’s request and determines if a tool is needed.\nTool Selection: The LLM selects the appropriate tool based on the task and the available tools.\nAPI Call Formulation: The LLM generates the correct API call to the selected tool, including any necessary parameters.\nResponse Integration: The LLM receives the tool’s output and integrates it into its response to the user."
  },
  {
    "objectID": "talks/ai-agents/llm-2.html#structured-output-json",
    "href": "talks/ai-agents/llm-2.html#structured-output-json",
    "title": "AI Agents",
    "section": "Structured Output (JSON)",
    "text": "Structured Output (JSON)\n\nJSON stands for JavaScript Object Notation.\nIt’s a lightweight data format that is easy for humans to read and write and easy for machines to parse.\nJSON is commonly used for transmitting data between web applications and servers."
  },
  {
    "objectID": "talks/ai-agents/llm-2.html#json-and-llm-tools",
    "href": "talks/ai-agents/llm-2.html#json-and-llm-tools",
    "title": "AI Agents",
    "section": "JSON and LLM Tools",
    "text": "JSON and LLM Tools\n\nMany LLM tools use JSON for input and output.\nThe LLM sends requests to the tool in JSON format.\nThe tool responds with results in JSON format, which the LLM can then process."
  },
  {
    "objectID": "talks/ai-agents/llm-2.html#benefits-of-using-json",
    "href": "talks/ai-agents/llm-2.html#benefits-of-using-json",
    "title": "AI Agents",
    "section": "Benefits of Using JSON",
    "text": "Benefits of Using JSON\n\nStandardized Format: Ensures consistency and compatibility between different tools.\nEasy to Parse: Allows the LLM to quickly extract the information it needs from the tool’s response.\nFlexible: Can represent a wide range of data structures."
  },
  {
    "objectID": "talks/ai-agents/llm-2.html#llms-as-components-of-larger-systems",
    "href": "talks/ai-agents/llm-2.html#llms-as-components-of-larger-systems",
    "title": "AI Agents",
    "section": "LLMs as components of larger systems",
    "text": "LLMs as components of larger systems"
  },
  {
    "objectID": "talks/ai-agents/llm-2.html#planning",
    "href": "talks/ai-agents/llm-2.html#planning",
    "title": "AI Agents",
    "section": "Planning",
    "text": "Planning"
  },
  {
    "objectID": "talks/ai-agents/llm-2.html#memory",
    "href": "talks/ai-agents/llm-2.html#memory",
    "title": "AI Agents",
    "section": "Memory",
    "text": "Memory"
  },
  {
    "objectID": "talks/ai-agents/llm-2.html#tools",
    "href": "talks/ai-agents/llm-2.html#tools",
    "title": "AI Agents",
    "section": "Tools",
    "text": "Tools"
  },
  {
    "objectID": "talks/ai-agents/llm-2.html#future-of-llm-tool-use",
    "href": "talks/ai-agents/llm-2.html#future-of-llm-tool-use",
    "title": "AI Agents",
    "section": "Future of LLM Tool Use",
    "text": "Future of LLM Tool Use\n\nMore Sophisticated Tools: LLMs will be able to use a wider range of tools, including those that can perform more complex tasks.\nImproved Integration: LLMs will be able to seamlessly integrate tool outputs into their responses.\nIncreased Autonomy: LLMs will be able to make more decisions about when and how to use tools."
  },
  {
    "objectID": "talks/ai-agents/llm-2.html#llm-tool-use-in-healthcare",
    "href": "talks/ai-agents/llm-2.html#llm-tool-use-in-healthcare",
    "title": "AI Agents",
    "section": "LLM Tool Use in Healthcare",
    "text": "LLM Tool Use in Healthcare\n\nPotential Applications: Accessing patient records, retrieving medical research, generating reports, scheduling appointments.\nBenefits: Improved efficiency, accuracy, and decision-making.\nChallenges: Ensuring patient privacy and data security."
  },
  {
    "objectID": "talks/prompt-engineering/prompt-engineering.html#what-is-a-prompt-anyway",
    "href": "talks/prompt-engineering/prompt-engineering.html#what-is-a-prompt-anyway",
    "title": "Prompt Engineering",
    "section": "What is a Prompt, anyway?",
    "text": "What is a Prompt, anyway?\n\nA prompt is a set of instructions or guidelines given to a language model to generate a specific output.\nIt can be a question, a task, or a description of the desired output.\nPrompts help guide the model’s response and ensure it provides relevant and accurate information.\nEffective prompt design is crucial for obtaining useful and reliable results from language models."
  },
  {
    "objectID": "talks/prompt-engineering/prompt-engineering.html#and-prompt-engineering",
    "href": "talks/prompt-engineering/prompt-engineering.html#and-prompt-engineering",
    "title": "Prompt Engineering",
    "section": "And Prompt Engineering?",
    "text": "And Prompt Engineering?\n\nPrompt engineering is the process of designing prompts to elicit the desired responses from language models.\nIt involves crafting clear, specific, and structured instructions that guide the model’s behavior.\nWell-designed prompts can improve the accuracy, relevance, and usability of the model’s outputs.\nPrompt engineering is essential for leveraging the full potential of language models in various applications."
  },
  {
    "objectID": "talks/prompt-engineering/prompt-engineering.html#rule-1-start-with-a-clear-objective",
    "href": "talks/prompt-engineering/prompt-engineering.html#rule-1-start-with-a-clear-objective",
    "title": "Prompt Engineering",
    "section": "Rule 1: Start with a Clear Objective",
    "text": "Rule 1: Start with a Clear Objective\nWhy? A well-defined goal guides the prompting process.\nHow? Begin with a specific question, task, or instruction.\nExample:\n❌ \"Tell me about diabetes.\" \n\n✅ \"Summarize the key risk factors for developing Type 2 diabetes.\""
  },
  {
    "objectID": "talks/prompt-engineering/prompt-engineering.html#rule-2-provide-context",
    "href": "talks/prompt-engineering/prompt-engineering.html#rule-2-provide-context",
    "title": "Prompt Engineering",
    "section": "Rule 2: Provide Context",
    "text": "Rule 2: Provide Context\nWhy? Context helps the model understand the background and purpose.\nHow? Include relevant details such as patient demographics, medical history, or specific symptoms.\nExample:\n✅ “A 55-year-old male with a history of hypertension presents with chest pain…”"
  },
  {
    "objectID": "talks/prompt-engineering/prompt-engineering.html#rule-3-use-precise-language",
    "href": "talks/prompt-engineering/prompt-engineering.html#rule-3-use-precise-language",
    "title": "Prompt Engineering",
    "section": "Rule 3: Use Precise Language",
    "text": "Rule 3: Use Precise Language\nWhy? Ambiguity can lead to inaccurate or irrelevant results.\nHow? Choose specific medical terms and avoid vague descriptions.\nExample:\n❌ “stomach pain”\n✅ “epigastric pain radiating to the back”"
  },
  {
    "objectID": "talks/prompt-engineering/prompt-engineering.html#rule-4-specify-the-desired-output-format",
    "href": "talks/prompt-engineering/prompt-engineering.html#rule-4-specify-the-desired-output-format",
    "title": "Prompt Engineering",
    "section": "Rule 4: Specify the Desired Output Format",
    "text": "Rule 4: Specify the Desired Output Format\nWhy? This ensures the information is delivered in a usable format.\nHow? Request specific formats like lists, tables, summaries, or code.\nExample:\n✅ “Generate a differential diagnosis list for these symptoms…”\n✅ “Summarize the patient’s history in bullet points.”"
  },
  {
    "objectID": "talks/prompt-engineering/prompt-engineering.html#rule-5-iterate-and-refine",
    "href": "talks/prompt-engineering/prompt-engineering.html#rule-5-iterate-and-refine",
    "title": "Prompt Engineering",
    "section": "Rule 5: Iterate and Refine",
    "text": "Rule 5: Iterate and Refine\nWhy? Prompt engineering is an iterative process.\nHow? Experiment with different phrasing, keywords, and levels of detail. Analyze the outputs and refine the prompts to improve accuracy.\nExample:\n\nInitial Prompt: “What are the treatment options for this patient?”\nRefined Prompt: “Given the patient’s age, medical history, and contraindications, provide a prioritized list of evidence-based treatment options for their condition.”"
  },
  {
    "objectID": "talks/prompt-engineering/prompt-engineering.html#rule-6-employ-few-shot-prompting",
    "href": "talks/prompt-engineering/prompt-engineering.html#rule-6-employ-few-shot-prompting",
    "title": "Prompt Engineering",
    "section": "Rule 6: Employ “Few-Shot” Prompting",
    "text": "Rule 6: Employ “Few-Shot” Prompting\nWhy? Providing examples helps the model understand the desired pattern.\nHow? Include a few examples of the desired input-output pairs in the prompt.\nExample:\nPrompt: “Translate these medical abbreviations:\n\nCHF: Congestive Heart Failure\nMI: Myocardial Infarction\n\nNow translate:\n\nCOPD: ”"
  },
  {
    "objectID": "talks/prompt-engineering/prompt-engineering.html#rule-7-break-down-complex-tasks",
    "href": "talks/prompt-engineering/prompt-engineering.html#rule-7-break-down-complex-tasks",
    "title": "Prompt Engineering",
    "section": "Rule 7: Break Down Complex Tasks",
    "text": "Rule 7: Break Down Complex Tasks\nWhy? Large language models perform better with focused, step-by-step instructions.\nHow? Decompose complex tasks into smaller, more manageable subtasks.\nExample:\nInstead of asking for a complete treatment plan, first ask for:\n\nPossible diagnoses\nTreatment options for each diagnosis\nFactors influencing treatment selection"
  },
  {
    "objectID": "talks/prompt-engineering/prompt-engineering.html#rule-8-utilize-delimiters",
    "href": "talks/prompt-engineering/prompt-engineering.html#rule-8-utilize-delimiters",
    "title": "Prompt Engineering",
    "section": "Rule 8: Utilize Delimiters",
    "text": "Rule 8: Utilize Delimiters\nWhy? Delimiters help the model distinguish between different parts of the prompt.\nHow? Use clear separators like “```”, “###”, or “**” to mark different sections.\nExample:\nPrompt:\nYour goal is to generate a differential diagnosis for this patient. \n\n### Start of patient information\nPatient History:\n60-year-old female\nHistory of type 2 diabetes\n\nCurrent Symptoms:\nFatigue\nIncreased thirst\n### End of patient information"
  },
  {
    "objectID": "talks/prompt-engineering/prompt-engineering.html#rule-9-be-mindful-of-biases",
    "href": "talks/prompt-engineering/prompt-engineering.html#rule-9-be-mindful-of-biases",
    "title": "Prompt Engineering",
    "section": "Rule 9: Be Mindful of Biases",
    "text": "Rule 9: Be Mindful of Biases\nWhy? Language models can reflect biases present in the training data.\nHow? Use neutral language and avoid stereotypes.\nExample:\n❌ “This is a typical case of…”\n✅ “Based on the presented information, consider…”"
  },
  {
    "objectID": "talks/prompt-engineering/prompt-engineering.html#rule-10-stay-updated-on-best-practices",
    "href": "talks/prompt-engineering/prompt-engineering.html#rule-10-stay-updated-on-best-practices",
    "title": "Prompt Engineering",
    "section": "Rule 10: Stay Updated on Best Practices",
    "text": "Rule 10: Stay Updated on Best Practices\n\nOpenAI’s prompt engineering guide\nGoogle’s prompt design strategies\nPublicly available prompt repositories\n\nhttps://github.com/abilzerian/LLM-Prompt-Library\n\nhttps://www.promptingguide.ai/\nhttps://promptengineering.org/\nResearch papers: Meskó (2023)"
  },
  {
    "objectID": "talks/prompt-engineering/prompt-engineering.html#references",
    "href": "talks/prompt-engineering/prompt-engineering.html#references",
    "title": "Prompt Engineering",
    "section": "References",
    "text": "References\n\n\n\n\nMeskó, Bertalan. 2023. “Prompt Engineering as an Important Emerging Skill for Medical Professionals: Tutorial.” Journal of Medical Internet Research 25 (1): e50638. https://doi.org/10.2196/50638."
  },
  {
    "objectID": "talks/ai-history/index.html#introduction",
    "href": "talks/ai-history/index.html#introduction",
    "title": "The History of Artificial Intelligence and Machine Learning",
    "section": "Introduction",
    "text": "Introduction\n\nArtificial Intelligence (AI) and Machine Learning (ML) have a rich history\nFrom early concepts to modern applications\nThis presentation covers key milestones and breakthroughs"
  },
  {
    "objectID": "talks/ai-history/index.html#early-beginnings-1940s-1950s",
    "href": "talks/ai-history/index.html#early-beginnings-1940s-1950s",
    "title": "The History of Artificial Intelligence and Machine Learning",
    "section": "Early Beginnings (1940s-1950s)",
    "text": "Early Beginnings (1940s-1950s)\n\n\n\n1936: Turing and the Computable Numbers (Turing 1936)\n1943: McCulloch and Pitts create a computational model for neural networks\n1950: Alan Turing proposes the Turing Test (Turing 1950) and Paper\n1956: Dartmouth Conference coins the term “Artificial Intelligence”"
  },
  {
    "objectID": "talks/ai-history/index.html#i-robot-by-isaac-asimov",
    "href": "talks/ai-history/index.html#i-robot-by-isaac-asimov",
    "title": "The History of Artificial Intelligence and Machine Learning",
    "section": "“I, Robot” by Isaac Asimov",
    "text": "“I, Robot” by Isaac Asimov\n\n\n\nPublished in 1950 by Gnome Press\nCollection of nine science fiction short stories\nOriginally appeared in super-science fiction magazines (1940-1950)\nIntroduced the concept of positronic robots and the Three Laws of Robotics\n\n\n\n\nAsimov (1950)\n\nAsimov’s work laid the foundation for ethical considerations in AI development."
  },
  {
    "objectID": "talks/ai-history/index.html#the-three-laws-of-robotics",
    "href": "talks/ai-history/index.html#the-three-laws-of-robotics",
    "title": "The History of Artificial Intelligence and Machine Learning",
    "section": "The Three Laws of Robotics",
    "text": "The Three Laws of Robotics\n\nA robot may not injure a human being or, through inaction, allow a human being to come to harm.\nA robot must obey the orders given it by human beings except where such orders would conflict with the First Law.\nA robot must protect its own existence as long as such protection does not conflict with the First or Second Laws.\n\n\nAsimov later added the Zeroth Law that superseded the others:\n\nA robot may not harm humanity, or, by inaction, allow humanity to come to harm.\n\n\n\nThese laws have become a cornerstone in discussions about AI ethics and safety."
  },
  {
    "objectID": "talks/ai-history/index.html#i-robots-influence-on-modern-ai",
    "href": "talks/ai-history/index.html#i-robots-influence-on-modern-ai",
    "title": "The History of Artificial Intelligence and Machine Learning",
    "section": "“I, Robot”’s Influence on Modern AI",
    "text": "“I, Robot”’s Influence on Modern AI\n\nSparked discussions on machine ethics and AI safety\nInfluenced researchers to consider ethical implications of AI development\nConcept of “friendly AI” draws parallels to Asimov’s laws\nChallenges presented in stories mirror real-world AI alignment problems\n\n\nWhile not directly implementable, Asimov’s laws have shaped thinking about AI governance and ethics in the field."
  },
  {
    "objectID": "talks/ai-history/index.html#the-turing-test",
    "href": "talks/ai-history/index.html#the-turing-test",
    "title": "The History of Artificial Intelligence and Machine Learning",
    "section": "1950: The Turing Test",
    "text": "1950: The Turing Test\n\nWho’s the real human?"
  },
  {
    "objectID": "talks/ai-history/index.html#the-golden-years-1956-1974",
    "href": "talks/ai-history/index.html#the-golden-years-1956-1974",
    "title": "The History of Artificial Intelligence and Machine Learning",
    "section": "The Golden Years (1956-1974)",
    "text": "The Golden Years (1956-1974)\n\nDevelopment of early AI programs\n1957: Frank Rosenblatt develops the Perceptron\n1964: ELIZA, one of the first chatbots, is created by Joseph Weizenbaum"
  },
  {
    "objectID": "talks/ai-history/index.html#eliza-one-of-the-first-chatbots",
    "href": "talks/ai-history/index.html#eliza-one-of-the-first-chatbots",
    "title": "The History of Artificial Intelligence and Machine Learning",
    "section": "1964: ELIZA, one of the first chatbots",
    "text": "1964: ELIZA, one of the first chatbots\n\n\n\n\n\n\n\n\nAlthough ELIZA was limited in terms of actual understanding, it marked an important milestone in the development of AI and human-computer interaction, showing how conversation-based interfaces could influence the perception of intelligence.\n\n\nELIZA was one of the earliest chatbots, developed in the mid-1960s by Joseph Weizenbaum, a computer scientist at MIT. The program was designed to simulate a conversation between a human and a machine, and it did so by using pattern matching and substitution methodology, a simple but effective form of natural language processing.\nELIZA’s most famous script was called “DOCTOR,” which mimicked a Rogerian psychotherapist. In this role, ELIZA would take users’ input and reflect their statements back to them in a way that encouraged further conversation. For example, if a user said, “I’m feeling sad today,” ELIZA might respond with, “Why do you think you’re feeling sad today?”\nWhile ELIZA’s responses were largely superficial, many users were surprised at how human-like they seemed. Weizenbaum created ELIZA to demonstrate how easily people could attribute human-like understanding to a machine, even when its responses were formulaic. He was struck by how quickly people became emotionally attached to the program, despite knowing it was not genuinely intelligent.\nAlthough ELIZA was limited in terms of actual understanding, it marked an important milestone in the development of AI and human-computer interaction, showing how conversation-based interfaces could influence the perception of intelligence."
  },
  {
    "objectID": "talks/ai-history/index.html#what-is-an-expert-system",
    "href": "talks/ai-history/index.html#what-is-an-expert-system",
    "title": "The History of Artificial Intelligence and Machine Learning",
    "section": "What is an Expert System?",
    "text": "What is an Expert System?\n\nDefinition: Computer program that emulates decision-making ability of a human expert\nKey Components:\n\nKnowledge Base: Contains domain-specific information and rules\nInference Engine: Applies rules to the knowledge to derive new information\nUser Interface: Allows non-expert users to interact with the system\n\nCharacteristics:\n\nSolves complex problems by reasoning through bodies of knowledge\nSeparates domain knowledge from the reasoning mechanism\nCan explain its decisions and reasoning"
  },
  {
    "objectID": "talks/ai-history/index.html#what-is-an-expert-system-1",
    "href": "talks/ai-history/index.html#what-is-an-expert-system-1",
    "title": "The History of Artificial Intelligence and Machine Learning",
    "section": "What is an Expert System?",
    "text": "What is an Expert System?\n\nApplications:\n\nMedical diagnosis (e.g., MYCIN)\nFinancial planning\nManufacturing process control\nScientific analysis\n\nAdvantages:\n\nConsistent and accurate decisions\nPreservation of expert knowledge\nAbility to handle complex scenarios\n\nLimitations:\n\nLimited to specific domains (narrow AI)\nDifficulty in capturing tacit knowledge\nMay struggle with unusual or unprecedented situations"
  },
  {
    "objectID": "talks/ai-history/index.html#example-expert-system-mycin",
    "href": "talks/ai-history/index.html#example-expert-system-mycin",
    "title": "The History of Artificial Intelligence and Machine Learning",
    "section": "Example Expert system: MYCIN",
    "text": "Example Expert system: MYCIN\n\nDeveloped in the early 1970s at Stanford University\nOne of the first rule-based expert systems in medicine\nPurpose: Assist physicians in diagnosing and treating bacterial infections\nFocused on bloodstream infections (bacteremia and meningitis)\nNamed after antibiotics (many of which end in “-mycin”)"
  },
  {
    "objectID": "talks/ai-history/index.html#mycin-key-features-and-functionality",
    "href": "talks/ai-history/index.html#mycin-key-features-and-functionality",
    "title": "The History of Artificial Intelligence and Machine Learning",
    "section": "MYCIN: Key Features and Functionality",
    "text": "MYCIN: Key Features and Functionality\n\nRule-based system with approximately 600 rules\nUsed backward chaining inference engine\nIncorporated certainty factors to handle uncertainty\nAsked users a series of yes/no questions about symptoms and test results\nProvided diagnosis recommendations and suggested antibiotic treatments\nExplained its reasoning process to user"
  },
  {
    "objectID": "talks/ai-history/index.html#mycin-impact-and-legacy",
    "href": "talks/ai-history/index.html#mycin-impact-and-legacy",
    "title": "The History of Artificial Intelligence and Machine Learning",
    "section": "MYCIN: Impact and Legacy",
    "text": "MYCIN: Impact and Legacy\n\nNever used in clinical practice due to ethical and legal concerns\nAchieved performance comparable to human experts in its domain\nPioneered several important concepts in AI and expert systems:\n\nSeparation of knowledge base from inference engine\nExplanation of reasoning\nHandling of uncertainty\n\nInfluenced development of subsequent expert systems and clinical decision support tools\nDemonstrated potential of AI in healthcare, paving way for modern medical AI applications"
  },
  {
    "objectID": "talks/ai-history/index.html#increased-computational-power",
    "href": "talks/ai-history/index.html#increased-computational-power",
    "title": "The History of Artificial Intelligence and Machine Learning",
    "section": "Increased Computational Power",
    "text": "Increased Computational Power\n\nAdvancement:\n\nRapid growth of CPUs and the emergence of GPUs (Graphics Processing Units).\n\nImpact:\n\nEnabled the training of deeper neural networks essential for various AI tasks."
  },
  {
    "objectID": "talks/ai-history/index.html#big-data",
    "href": "talks/ai-history/index.html#big-data",
    "title": "The History of Artificial Intelligence and Machine Learning",
    "section": "Big Data",
    "text": "Big Data\n\nAdvancement:\n\nExplosion of digital data from the internet, social media, and sensors.\n\nImpact:\n\nFacilitated the development of accurate models as ML algorithms require substantial data to learn effectively."
  },
  {
    "objectID": "talks/ai-history/index.html#open-source-frameworks-and-libraries",
    "href": "talks/ai-history/index.html#open-source-frameworks-and-libraries",
    "title": "The History of Artificial Intelligence and Machine Learning",
    "section": "Open Source Frameworks and Libraries",
    "text": "Open Source Frameworks and Libraries\n\nAdvancement:\n\nEmergence of libraries like TensorFlow (2015), Keras (2015), and Scikit-learn (2007).\n\nImpact:\n\nLowered the barrier for AI development, allowing more practitioners to innovate in the field."
  },
  {
    "objectID": "talks/ai-history/index.html#advances-in-algorithms",
    "href": "talks/ai-history/index.html#advances-in-algorithms",
    "title": "The History of Artificial Intelligence and Machine Learning",
    "section": "Advances in Algorithms",
    "text": "Advances in Algorithms\n\nAdvancement:\n\nResearch in new algorithms, such as support vector machines and deep learning architectures.\n\nImpact:\n\nImproved AI performance across applications, particularly in image and speech recognition."
  },
  {
    "objectID": "talks/ai-history/index.html#cloud-computing",
    "href": "talks/ai-history/index.html#cloud-computing",
    "title": "The History of Artificial Intelligence and Machine Learning",
    "section": "Cloud Computing",
    "text": "Cloud Computing\n\nAdvancement:\n\nRise of cloud computing platforms (e.g., AWS, Google Cloud, Microsoft Azure).\n\nImpact:\n\nProvided scalable resources for storage and computation, enabling extensive ML experimentation."
  },
  {
    "objectID": "talks/ai-history/index.html#collaborative-research-and-knowledge-sharing",
    "href": "talks/ai-history/index.html#collaborative-research-and-knowledge-sharing",
    "title": "The History of Artificial Intelligence and Machine Learning",
    "section": "Collaborative Research and Knowledge Sharing",
    "text": "Collaborative Research and Knowledge Sharing\n\nAdvancement:\n\nIncreased collaboration and sharing of findings through conferences and online platforms.\n\nImpact:\n\nAccelerated innovation in AI and ML as researchers built upon each other’s work."
  },
  {
    "objectID": "talks/ai-history/index.html#investment-and-interest-from-industry",
    "href": "talks/ai-history/index.html#investment-and-interest-from-industry",
    "title": "The History of Artificial Intelligence and Machine Learning",
    "section": "Investment and Interest from Industry",
    "text": "Investment and Interest from Industry\n\nAdvancement:\n\nGrowing interest and investment from tech giants and startups in AI technologies.\n\nImpact:\n\nLed to the development of practical applications and commercial products, driving further research."
  },
  {
    "objectID": "talks/ai-history/index.html#deep-learning-resurgence-2006",
    "href": "talks/ai-history/index.html#deep-learning-resurgence-2006",
    "title": "The History of Artificial Intelligence and Machine Learning",
    "section": "Deep Learning Resurgence (2006)",
    "text": "Deep Learning Resurgence (2006)\n\nMilestone: Geoffrey Hinton and team introduced “deep belief networks.”\nImpact: Marked the resurgence of deep learning and laid the foundation for modern AI applications, especially in image and speech recognition."
  },
  {
    "objectID": "talks/ai-history/index.html#alexnet-wins-imagenet-competition-2012",
    "href": "talks/ai-history/index.html#alexnet-wins-imagenet-competition-2012",
    "title": "The History of Artificial Intelligence and Machine Learning",
    "section": "AlexNet Wins ImageNet Competition (2012)",
    "text": "AlexNet Wins ImageNet Competition (2012)\n\nMilestone: Alex Krizhevsky, Ilya Sutskever, and Geoffrey Hinton’s deep neural network (AlexNet) won the ImageNet competition.\nImpact: Showcased the power of convolutional neural networks (CNNs) and triggered widespread adoption in computer vision tasks."
  },
  {
    "objectID": "talks/ai-history/index.html#ibm-watson-wins-jeopardy-2011",
    "href": "talks/ai-history/index.html#ibm-watson-wins-jeopardy-2011",
    "title": "The History of Artificial Intelligence and Machine Learning",
    "section": "IBM Watson Wins Jeopardy! (2011)",
    "text": "IBM Watson Wins Jeopardy! (2011)\n\nMilestone: IBM Watson defeated champions Ken Jennings and Brad Rutter on Jeopardy!.\nImpact: Demonstrated AI’s ability to process and understand natural language, leading to applications in healthcare, finance, and customer service."
  },
  {
    "objectID": "talks/ai-history/index.html#md-anderson-sets-watson-aside-2017-2018",
    "href": "talks/ai-history/index.html#md-anderson-sets-watson-aside-2017-2018",
    "title": "The History of Artificial Intelligence and Machine Learning",
    "section": "MD Anderson sets Watson aside (2017-2018)",
    "text": "MD Anderson sets Watson aside (2017-2018)\n\nSee Herper (n.d.)"
  },
  {
    "objectID": "talks/ai-history/index.html#generative-adversarial-networks-gans-2014",
    "href": "talks/ai-history/index.html#generative-adversarial-networks-gans-2014",
    "title": "The History of Artificial Intelligence and Machine Learning",
    "section": "Generative Adversarial Networks (GANs) (2014)",
    "text": "Generative Adversarial Networks (GANs) (2014)\n\nMilestone: Ian Goodfellow introduced GANs, a model where two neural networks compete to generate realistic data.\nImpact: Revolutionized image generation and unsupervised learning, powering innovations like deepfakes and AI-generated art."
  },
  {
    "objectID": "talks/ai-history/index.html#alphago-defeats-world-champion-2016",
    "href": "talks/ai-history/index.html#alphago-defeats-world-champion-2016",
    "title": "The History of Artificial Intelligence and Machine Learning",
    "section": "AlphaGo Defeats World Champion (2016)",
    "text": "AlphaGo Defeats World Champion (2016)\n\nMilestone: Google DeepMind’s AlphaGo defeated Go champion Lee Sedol.\nImpact: Showcased the capability of reinforcement learning and deep neural networks in mastering complex strategic games."
  },
  {
    "objectID": "talks/ai-history/index.html#transformer-architecture-2017",
    "href": "talks/ai-history/index.html#transformer-architecture-2017",
    "title": "The History of Artificial Intelligence and Machine Learning",
    "section": "Transformer Architecture (2017)",
    "text": "Transformer Architecture (2017)\n\nMilestone: Vaswani et al. introduced the Transformer model, revolutionizing natural language processing.\nImpact: Laid the groundwork for state-of-the-art NLP models like BERT and GPT, transforming language understanding and generation."
  },
  {
    "objectID": "talks/ai-history/index.html#ai-and-ml-in-social-media-2010s",
    "href": "talks/ai-history/index.html#ai-and-ml-in-social-media-2010s",
    "title": "The History of Artificial Intelligence and Machine Learning",
    "section": "AI and ML in Social Media (2010s)",
    "text": "AI and ML in Social Media (2010s)\n\nMilestone: Social media platforms adopted AI for content recommendation and moderation.\nImpact: Enhanced user engagement and experience, but also raised concerns about echo chambers, misinformation, and algorithmic bias."
  },
  {
    "objectID": "talks/ai-history/index.html#alphafold-solves-protein-folding-2020",
    "href": "talks/ai-history/index.html#alphafold-solves-protein-folding-2020",
    "title": "The History of Artificial Intelligence and Machine Learning",
    "section": "AlphaFold Solves Protein Folding (2020)",
    "text": "AlphaFold Solves Protein Folding (2020)\n\nMilestone: DeepMind’s AlphaFold achieved breakthrough accuracy in predicting protein structures.\nImpact: Solved a 50-year-old challenge in biology, opening new doors in drug discovery and molecular biology."
  },
  {
    "objectID": "talks/ai-history/index.html#gpt-4-and-large-language-models-2023",
    "href": "talks/ai-history/index.html#gpt-4-and-large-language-models-2023",
    "title": "The History of Artificial Intelligence and Machine Learning",
    "section": "GPT-4 and Large Language Models (2023)",
    "text": "GPT-4 and Large Language Models (2023)\n\nMilestone: OpenAI’s GPT-4 showcased the potential of large-scale language models for complex, nuanced language understanding.\nImpact: Accelerated the development of AI-driven content creation and enhanced human-computer interaction."
  },
  {
    "objectID": "talks/ai-history/index.html#future-directions",
    "href": "talks/ai-history/index.html#future-directions",
    "title": "The History of Artificial Intelligence and Machine Learning",
    "section": "Future Directions",
    "text": "Future Directions\n\nArtificial General Intelligence (AGI) research\nQuantum computing and AI\nNeuromorphic computing\nHuman-AI collaboration\n\nFor deeper dive into the history, see (Norman 2024)."
  },
  {
    "objectID": "talks/ai-history/index.html#challenges-and-opportunities",
    "href": "talks/ai-history/index.html#challenges-and-opportunities",
    "title": "The History of Artificial Intelligence and Machine Learning",
    "section": "Challenges and Opportunities",
    "text": "Challenges and Opportunities\n\nEthical AI development\nAI governance and regulation\nAddressing AI bias and fairness\nBalancing innovation with responsible development"
  },
  {
    "objectID": "talks/ai-history/index.html#references",
    "href": "talks/ai-history/index.html#references",
    "title": "The History of Artificial Intelligence and Machine Learning",
    "section": "References",
    "text": "References\n\n\n\n\nAsimov, Isaac. 1950. I, Robot. Bantam hardcover ed. (2). New York: Bantam Books.\n\n\nHerper, Matthew. n.d. “MD Anderson Benches IBM Watson In Setback For Artificial Intelligence In Medicine.” Forbes. Accessed October 2, 2024. https://www.forbes.com/sites/matthewherper/2017/02/19/md-anderson-benches-ibm-watson-in-setback-for-artificial-intelligence-in-medicine/.\n\n\nNorman, Jeremy. 2024. “History of Information.” https://www.historyofinformation.com/?cat=71.\n\n\nTuring, Alan. 1936. “On Computable Numbers, with an Application to the Entscheidungsproblem.” https://www.abelard.org/turpap2/tp2-ie.asp.\n\n\n———. 1950. “Computing Machinery and Intelligence.” Mind 59 (October): 433–60. https://doi.org/10.1093/mind/lix.236.433."
  },
  {
    "objectID": "talks/ml-intro/index.html#outline",
    "href": "talks/ml-intro/index.html#outline",
    "title": "Introduction to Machine Learning",
    "section": "Outline",
    "text": "Outline\n\nRelationship between AI and ML\nTypes of Machine Learning\nA little about data\nSupervised Learning\nUnsupervised Learning"
  },
  {
    "objectID": "talks/ml-intro/index.html#an-ontology-of-ai",
    "href": "talks/ml-intro/index.html#an-ontology-of-ai",
    "title": "Introduction to Machine Learning",
    "section": "An Ontology of AI",
    "text": "An Ontology of AI"
  },
  {
    "objectID": "talks/ml-intro/index.html#what-is-machine-learning",
    "href": "talks/ml-intro/index.html#what-is-machine-learning",
    "title": "Introduction to Machine Learning",
    "section": "What is Machine Learning?",
    "text": "What is Machine Learning?\nThe study of computer algorithms that improve automatically through experience. It is seen as a subset of artificial intelligence. Machine learning systems give the computer the ability to learn without being explicitly programmed rules."
  },
  {
    "objectID": "talks/ml-intro/index.html#what-is-deep-learning",
    "href": "talks/ml-intro/index.html#what-is-deep-learning",
    "title": "Introduction to Machine Learning",
    "section": "What is Deep Learning?",
    "text": "What is Deep Learning?\nMachine learning algorithms that are inspired by the structure and function of the brain. Deep learning is a subset of machine learning in artificial intelligence that has networks capable of learning unsupervised from data that is often unstructured (i.e., text or images)."
  },
  {
    "objectID": "talks/ml-intro/index.html#ai-vs.-ml-vs.-deep-learning",
    "href": "talks/ml-intro/index.html#ai-vs.-ml-vs.-deep-learning",
    "title": "Introduction to Machine Learning",
    "section": "AI vs. ML vs. Deep Learning",
    "text": "AI vs. ML vs. Deep Learning\n\n\nArtificialIntelligence\n\n\nMachineLearning\n\n\nDeepLearning"
  },
  {
    "objectID": "talks/ml-intro/index.html#ai-vs.-ml-vs.-deep-learning-1",
    "href": "talks/ml-intro/index.html#ai-vs.-ml-vs.-deep-learning-1",
    "title": "Introduction to Machine Learning",
    "section": "AI vs. ML vs. Deep Learning",
    "text": "AI vs. ML vs. Deep Learning\n\n\nArtificialIntelligence\n\n\nMachineLearning\n\n\nDeepLearning"
  },
  {
    "objectID": "talks/ml-intro/index.html#an-ontology-of-data",
    "href": "talks/ml-intro/index.html#an-ontology-of-data",
    "title": "Introduction to Machine Learning",
    "section": "An ontology of Data",
    "text": "An ontology of Data\n\n\n\n\nOne way to think about different classes of data."
  },
  {
    "objectID": "talks/ml-intro/index.html#structured-data-vs-unstructured-data",
    "href": "talks/ml-intro/index.html#structured-data-vs-unstructured-data",
    "title": "Introduction to Machine Learning",
    "section": "Structured Data vs Unstructured Data",
    "text": "Structured Data vs Unstructured Data\n\n\n\n\n\n\n\n\n\nStructured data\nUnstructured data\n\n\n\n\nWhat is it?\nData that fits in a predefined data model or schema.\nData without an underlying model to discern attributes.\n\n\nBasic example\nAn Excel table.\nA collection of video files.\n\n\nBest for\nA set of predefined observations or characteristics (columns) on a collection of things (rows)\nAn associated collection of data, objects, or files where the attributes change or are unknown.\n\n\nCommon formats\nCSV, TSV, Excel, SQL databases.\nImages, audio, video, text."
  },
  {
    "objectID": "talks/ml-intro/index.html#tabular-data",
    "href": "talks/ml-intro/index.html#tabular-data",
    "title": "Introduction to Machine Learning",
    "section": "Tabular Data",
    "text": "Tabular Data\n\nRows and columns\nEach column has a specific data type\nEach row represents an observation on a subject (e.g., patient, sample)\n\nTerminology:\n\nFeature: A column in the dataset\nTarget: The variable you are trying to predict\nObservation: A row in the dataset\nDimension: The number of features in the dataset (sometimes represented by \\(p\\))\nSample: A single row in the dataset (usually represented by \\(n\\))"
  },
  {
    "objectID": "talks/ml-intro/index.html#classes-of-machine-learning",
    "href": "talks/ml-intro/index.html#classes-of-machine-learning",
    "title": "Introduction to Machine Learning",
    "section": "Classes of Machine Learning",
    "text": "Classes of Machine Learning\n\nBroad classes of machine learning."
  },
  {
    "objectID": "talks/ml-intro/index.html#types-of-machine-learning",
    "href": "talks/ml-intro/index.html#types-of-machine-learning",
    "title": "Introduction to Machine Learning",
    "section": "Types of Machine Learning",
    "text": "Types of Machine Learning\n\nSupervised Learning\n\nClassification\nRegression\n\nUnsupervised Learning\n\nClustering\nDimensionality Reduction\n\nReinforcement Learning"
  },
  {
    "objectID": "talks/ml-intro/index.html#reinforecement-learning",
    "href": "talks/ml-intro/index.html#reinforecement-learning",
    "title": "Introduction to Machine Learning",
    "section": "Reinforecement Learning",
    "text": "Reinforecement Learning\n\nLearning through interaction: Unlike supervised learning where you have labeled data, RL agents learn by interacting with an environment.\nDelayed rewards: The agent doesn’t receive immediate feedback about the optimal action, but rather must learn which actions lead to better cumulative rewards over time.\nExploration vs. exploitation: The agent must balance exploring new actions versus exploiting known good actions.\nSequential decision making: RL deals with sequences of decisions rather than one-time predictions.\n\n\nExamples\n\n\n\nGame playing (e.g., AlphaGo, OpenAI Five)\nRobotics control\n\n\n\nAutonomous driving\nTrading strategies"
  },
  {
    "objectID": "talks/ml-intro/index.html#a-map-of-machine-learning-approaches",
    "href": "talks/ml-intro/index.html#a-map-of-machine-learning-approaches",
    "title": "Introduction to Machine Learning",
    "section": "A map of machine learning approaches",
    "text": "A map of machine learning approaches\n\n\nhttps://scikit-learn.org/stable/tutorial/machine_learning_map/index.html"
  },
  {
    "objectID": "talks/ml-intro/index.html#supervised-learning-1",
    "href": "talks/ml-intro/index.html#supervised-learning-1",
    "title": "Introduction to Machine Learning",
    "section": "Supervised Learning",
    "text": "Supervised Learning\n\nGiven a dataset of input-output pairs: \\(\\{(x_1, y_1), (x_2, y_2), \\ldots, (x_n, y_n)\\}\\)\nLearn a function \\(f\\) with parameters \\(\\theta\\) that maps inputs \\(x\\) to outputs \\(y\\) \\[y = f(x; \\theta) + \\epsilon\\]\nObjective: Choose parameters \\(\\theta\\) to minimize the prediction error \\(\\epsilon\\)"
  },
  {
    "objectID": "talks/ml-intro/index.html#supervised-learning-2",
    "href": "talks/ml-intro/index.html#supervised-learning-2",
    "title": "Introduction to Machine Learning",
    "section": "Supervised Learning",
    "text": "Supervised Learning\nWhen \\(y\\) is a continuous variable (e.g., house prices), it’s a regression problem.\nWhen \\(y\\) is a discrete variable (e.g., spam or not spam), it’s a classification problem.\n\nIt is not a concidence that the same terms are used in statistics! Many machine learning algorithms are based on statistical principles or are generalizations of statistical methods."
  },
  {
    "objectID": "talks/ml-intro/index.html#classification",
    "href": "talks/ml-intro/index.html#classification",
    "title": "Introduction to Machine Learning",
    "section": "Classification",
    "text": "Classification"
  },
  {
    "objectID": "talks/ml-intro/index.html#regression",
    "href": "talks/ml-intro/index.html#regression",
    "title": "Introduction to Machine Learning",
    "section": "Regression",
    "text": "Regression\n\nNot all regression is linear…."
  },
  {
    "objectID": "talks/ml-intro/index.html#classification-example",
    "href": "talks/ml-intro/index.html#classification-example",
    "title": "Introduction to Machine Learning",
    "section": "Classification Example",
    "text": "Classification Example\n\nThe classic iris"
  },
  {
    "objectID": "talks/ml-intro/index.html#classification-example-1",
    "href": "talks/ml-intro/index.html#classification-example-1",
    "title": "Introduction to Machine Learning",
    "section": "Classification Example",
    "text": "Classification Example\n\n\n\n\n\nSepal.Length\nSepal.Width\nPetal.Length\nPetal.Width\nSpecies\n\n\n\n\n6.2\n2.8\n4.8\n1.8\nvirginica\n\n\n4.8\n3.4\n1.6\n0.2\nsetosa\n\n\n5.0\n3.4\n1.5\n0.2\nsetosa\n\n\n5.9\n3.2\n4.8\n1.8\nversicolor\n\n\n5.8\n4.0\n1.2\n0.2\nsetosa\n\n\n5.8\n2.7\n3.9\n1.2\nversicolor\n\n\n6.7\n3.1\n4.7\n1.5\nversicolor\n\n\n5.6\n2.8\n4.9\n2.0\nvirginica\n\n\n6.3\n2.8\n5.1\n1.5\nvirginica\n\n\n6.3\n2.5\n5.0\n1.9\nvirginica\n\n\n4.6\n3.1\n1.5\n0.2\nsetosa\n\n\n5.5\n2.4\n3.8\n1.1\nversicolor\n\n\n6.5\n3.0\n5.2\n2.0\nvirginica\n\n\n5.6\n3.0\n4.5\n1.5\nversicolor\n\n\n7.3\n2.9\n6.3\n1.8\nvirginica\n\n\n6.1\n3.0\n4.9\n1.8\nvirginica\n\n\n4.3\n3.0\n1.1\n0.1\nsetosa\n\n\n6.4\n3.2\n5.3\n2.3\nvirginica\n\n\n4.8\n3.0\n1.4\n0.3\nsetosa\n\n\n6.1\n2.9\n4.7\n1.4\nversicolor"
  },
  {
    "objectID": "talks/ml-intro/index.html#classification-example-2",
    "href": "talks/ml-intro/index.html#classification-example-2",
    "title": "Introduction to Machine Learning",
    "section": "Classification Example",
    "text": "Classification Example"
  },
  {
    "objectID": "talks/ml-intro/index.html#training-and-testing",
    "href": "talks/ml-intro/index.html#training-and-testing",
    "title": "Introduction to Machine Learning",
    "section": "Training and Testing",
    "text": "Training and Testing\n\n\nTraining Data: Used to teach the model. It consists of input-output pairs for a supervised learning task.\nTesting Data: Used to evaluate the model’s performance. It should be separate from the training data, but come from the same distribution or population.\nValidation Data: Used for tuning hyperparameters. Hyperparameters are settings that control the learning process (e.g., k in k-NN, learning rate in neural networks)."
  },
  {
    "objectID": "talks/ml-intro/index.html#generalizability",
    "href": "talks/ml-intro/index.html#generalizability",
    "title": "Introduction to Machine Learning",
    "section": "Generalizability",
    "text": "Generalizability\n\nThe ability of a model to perform well on unseen data\n\nThis table shows the relationship between training error, testing error, and overfitting, good fit, and underfitting.\n\n\n\nTraining Error\nTesting Error\nModel Fit\n\n\n\n\nLow\nHigh\nOverfit\n\n\nLow\nLow\nGood Fit\n\n\nHigh\nHigh\nUnderfit (poor performance)"
  },
  {
    "objectID": "talks/ml-intro/index.html#bias-and-variance",
    "href": "talks/ml-intro/index.html#bias-and-variance",
    "title": "Introduction to Machine Learning",
    "section": "Bias and Variance",
    "text": "Bias and Variance\n\nBias: Error from incorrect assumptions in the learning algorithm\nVariance: Error from sensitivity to small fluctuations in the training set\nBias-Variance Tradeoff: The conflict in trying to simultaneously minimize these two sources of error"
  },
  {
    "objectID": "talks/ml-intro/index.html#classification-example-3",
    "href": "talks/ml-intro/index.html#classification-example-3",
    "title": "Introduction to Machine Learning",
    "section": "Classification Example",
    "text": "Classification Example"
  },
  {
    "objectID": "talks/ml-intro/index.html#classification-example-4",
    "href": "talks/ml-intro/index.html#classification-example-4",
    "title": "Introduction to Machine Learning",
    "section": "Classification Example",
    "text": "Classification Example"
  },
  {
    "objectID": "talks/ml-intro/index.html#classification-example-5",
    "href": "talks/ml-intro/index.html#classification-example-5",
    "title": "Introduction to Machine Learning",
    "section": "Classification Example",
    "text": "Classification Example"
  },
  {
    "objectID": "talks/ml-intro/index.html#regression-example",
    "href": "talks/ml-intro/index.html#regression-example",
    "title": "Introduction to Machine Learning",
    "section": "Regression Example",
    "text": "Regression Example\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCall:\nlm(formula = y ~ x)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-49.071 -11.047  -0.692  12.970  41.897 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept) -0.72808    3.68575  -0.198    0.844    \nx            2.05022    0.06336  32.356   &lt;2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 18.29 on 98 degrees of freedom\nMultiple R-squared:  0.9144,    Adjusted R-squared:  0.9135 \nF-statistic:  1047 on 1 and 98 DF,  p-value: &lt; 2.2e-16"
  },
  {
    "objectID": "talks/ml-intro/index.html#regression-example-1",
    "href": "talks/ml-intro/index.html#regression-example-1",
    "title": "Introduction to Machine Learning",
    "section": "Regression Example",
    "text": "Regression Example\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCall:\nlm(formula = y ~ x)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-98.143 -22.095  -1.385  25.940  83.795 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  -1.4562     7.3715  -0.198    0.844    \nx             2.1004     0.1267  16.574   &lt;2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 36.58 on 98 degrees of freedom\nMultiple R-squared:  0.7371,    Adjusted R-squared:  0.7344 \nF-statistic: 274.7 on 1 and 98 DF,  p-value: &lt; 2.2e-16"
  },
  {
    "objectID": "talks/ml-intro/index.html#regression-example-2",
    "href": "talks/ml-intro/index.html#regression-example-2",
    "title": "Introduction to Machine Learning",
    "section": "Regression Example",
    "text": "Regression Example\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCall:\nlm(formula = y ~ x)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-171.749  -38.665   -2.423   45.395  146.641 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  -2.5483    12.9001  -0.198    0.844    \nx             2.1758     0.2218   9.811 3.12e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 64.02 on 98 degrees of freedom\nMultiple R-squared:  0.4955,    Adjusted R-squared:  0.4904 \nF-statistic: 96.25 on 1 and 98 DF,  p-value: 3.116e-16"
  },
  {
    "objectID": "talks/ml-intro/index.html#more-complex-regression-example",
    "href": "talks/ml-intro/index.html#more-complex-regression-example",
    "title": "Introduction to Machine Learning",
    "section": "More Complex Regression Example",
    "text": "More Complex Regression Example\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nage\nsex\nbmi\nchildren\nsmoker\nregion\ncharges\nobese\n\n\n\n\n19\nfemale\n27.900\n0\nyes\nsouthwest\n16884.924\nnot obese\n\n\n18\nmale\n33.770\n1\nno\nsoutheast\n1725.552\nobese\n\n\n28\nmale\n33.000\n3\nno\nsoutheast\n4449.462\nobese\n\n\n33\nmale\n22.705\n0\nno\nnorthwest\n21984.471\nnot obese\n\n\n32\nmale\n28.880\n0\nno\nnorthwest\n3866.855\nnot obese\n\n\n31\nfemale\n25.740\n0\nno\nsoutheast\n3756.622\nnot obese\n\n\n46\nfemale\n33.440\n1\nno\nsoutheast\n8240.590\nobese\n\n\n37\nfemale\n27.740\n3\nno\nnorthwest\n7281.506\nnot obese\n\n\n37\nmale\n29.830\n2\nno\nnortheast\n6406.411\nnot obese\n\n\n60\nfemale\n25.840\n0\nno\nnorthwest\n28923.137\nnot obese"
  },
  {
    "objectID": "talks/ml-intro/index.html#more-complex-regression-example-1",
    "href": "talks/ml-intro/index.html#more-complex-regression-example-1",
    "title": "Introduction to Machine Learning",
    "section": "More Complex Regression Example",
    "text": "More Complex Regression Example\n\nWhat do you think about the relationship between age and insurance charges?"
  },
  {
    "objectID": "talks/ml-intro/index.html#more-complex-regression-example-2",
    "href": "talks/ml-intro/index.html#more-complex-regression-example-2",
    "title": "Introduction to Machine Learning",
    "section": "More Complex Regression Example",
    "text": "More Complex Regression Example"
  },
  {
    "objectID": "talks/ml-intro/index.html#more-complex-regression-example-3",
    "href": "talks/ml-intro/index.html#more-complex-regression-example-3",
    "title": "Introduction to Machine Learning",
    "section": "More Complex Regression Example",
    "text": "More Complex Regression Example\n\n\n\nCall:\nlm(formula = charges ~ age + smoker + sex + obese, data = insurance)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-13821.5  -3647.0   -225.8   1491.3  26884.1 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept) -4051.16     542.42  -7.469 1.46e-13 ***\nage           261.73      11.82  22.149  &lt; 2e-16 ***\nsmokeryes   23861.89     410.79  58.087  &lt; 2e-16 ***\nsexmale      -114.30     331.89  -0.344    0.731    \nobeseobese   4234.44     332.58  12.732  &lt; 2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 6044 on 1333 degrees of freedom\nMultiple R-squared:  0.7516,    Adjusted R-squared:  0.7509 \nF-statistic:  1008 on 4 and 1333 DF,  p-value: &lt; 2.2e-16"
  },
  {
    "objectID": "talks/ml-intro/index.html#algorithms-for-supervised-learning",
    "href": "talks/ml-intro/index.html#algorithms-for-supervised-learning",
    "title": "Introduction to Machine Learning",
    "section": "Algorithms for Supervised Learning",
    "text": "Algorithms for Supervised Learning\n\n\n\n\nCall:\nlm(formula = y ~ x)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-24.5356  -5.5236  -0.3462   6.4850  20.9487 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept) -0.36404    1.84287  -0.198    0.844    \nx            2.02511    0.03168  63.920   &lt;2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 9.145 on 98 degrees of freedom\nMultiple R-squared:  0.9766,    Adjusted R-squared:  0.9763 \nF-statistic:  4086 on 1 and 98 DF,  p-value: &lt; 2.2e-16"
  },
  {
    "objectID": "talks/ml-intro/index.html#algorithms-for-supervised-learning-1",
    "href": "talks/ml-intro/index.html#algorithms-for-supervised-learning-1",
    "title": "Introduction to Machine Learning",
    "section": "Algorithms for Supervised Learning",
    "text": "Algorithms for Supervised Learning\n\nAnscombe’s Quartet\nhttps://en.wikipedia.org/wiki/Anscombe%27s_quartet"
  },
  {
    "objectID": "talks/ml-intro/index.html#algorithms-for-supervised-learning-2",
    "href": "talks/ml-intro/index.html#algorithms-for-supervised-learning-2",
    "title": "Introduction to Machine Learning",
    "section": "Algorithms for Supervised Learning",
    "text": "Algorithms for Supervised Learning\n\nK-nearest neighbor (kNN) algorithm."
  },
  {
    "objectID": "talks/ml-intro/index.html#algorithms-for-supervised-learning-3",
    "href": "talks/ml-intro/index.html#algorithms-for-supervised-learning-3",
    "title": "Introduction to Machine Learning",
    "section": "Algorithms for Supervised Learning",
    "text": "Algorithms for Supervised Learning\n\nClassification and Regression Trees (CART)."
  },
  {
    "objectID": "talks/ml-intro/index.html#algorithms-for-supervised-learning-4",
    "href": "talks/ml-intro/index.html#algorithms-for-supervised-learning-4",
    "title": "Introduction to Machine Learning",
    "section": "Algorithms for Supervised Learning",
    "text": "Algorithms for Supervised Learning\n\nRandom Forests."
  },
  {
    "objectID": "talks/ml-intro/index.html#algorithms-for-supervised-learning-5",
    "href": "talks/ml-intro/index.html#algorithms-for-supervised-learning-5",
    "title": "Introduction to Machine Learning",
    "section": "Algorithms for Supervised Learning",
    "text": "Algorithms for Supervised Learning\n\nDeep learning."
  },
  {
    "objectID": "talks/ml-intro/index.html#applying-supervised-learning-algorithms",
    "href": "talks/ml-intro/index.html#applying-supervised-learning-algorithms",
    "title": "Introduction to Machine Learning",
    "section": "Applying Supervised Learning Algorithms",
    "text": "Applying Supervised Learning Algorithms\n\nThe mlr3 ecosystem in R."
  },
  {
    "objectID": "talks/ml-intro/index.html#key-concepts-in-supervised-learning",
    "href": "talks/ml-intro/index.html#key-concepts-in-supervised-learning",
    "title": "Introduction to Machine Learning",
    "section": "Key Concepts in Supervised Learning",
    "text": "Key Concepts in Supervised Learning\n\nFeature Engineering\nModel Selection\nHyperparameter Tuning\nEnsemble Methods\nCross-Validation\nEvaluation Metrics\n\n\nBriefly explain each concept: 1. Feature Engineering: Creating new features or transforming existing ones to improve model performance 2. Model Selection: Choosing the appropriate algorithm for your problem 3. Hyperparameter Tuning: Optimizing model parameters that are not learned from data 4. Ensemble Methods: Combining multiple models to improve performance 5. Cross-Validation: Technique for assessing how the model will generalize to an independent dataset 6. Evaluation Metrics: Different ways to measure model performance (accuracy, precision, recall, F1-score, ROC curve, etc.)"
  },
  {
    "objectID": "talks/ml-intro/index.html#challenges-in-machine-learning",
    "href": "talks/ml-intro/index.html#challenges-in-machine-learning",
    "title": "Introduction to Machine Learning",
    "section": "Challenges in Machine Learning",
    "text": "Challenges in Machine Learning\n\nData Quality and Quantity\nInterpretability vs Performance\nEthical Considerations and Bias\nComputational Resources\nModel Deployment and Maintenance\n\n\nDiscuss each challenge: 1. The importance of good, representative data and the challenges of data collection and cleaning 2. The tradeoff between complex, high-performing models and simpler, more interpretable ones 3. The risk of perpetuating or amplifying societal biases through ML models 4. The need for significant computational power, especially for deep learning models 5. The challenges of deploying models in production environments and keeping them updated"
  },
  {
    "objectID": "talks/ml-intro/index.html#clustering",
    "href": "talks/ml-intro/index.html#clustering",
    "title": "Introduction to Machine Learning",
    "section": "Clustering",
    "text": "Clustering\n\nGene expression measurements."
  },
  {
    "objectID": "talks/ml-intro/index.html#classes-of-unsupervised-learning-algorithms",
    "href": "talks/ml-intro/index.html#classes-of-unsupervised-learning-algorithms",
    "title": "Introduction to Machine Learning",
    "section": "Classes of unsupervised learning algorithms",
    "text": "Classes of unsupervised learning algorithms\n\n\n\n\n\nClustering.\n\n\n\n\n\n\nDimensionality reduction."
  },
  {
    "objectID": "talks/ml-intro/index.html#clustering-1",
    "href": "talks/ml-intro/index.html#clustering-1",
    "title": "Introduction to Machine Learning",
    "section": "Clustering",
    "text": "Clustering\n\nThinking about similarities and differences"
  },
  {
    "objectID": "talks/ml-intro/index.html#clustering-2",
    "href": "talks/ml-intro/index.html#clustering-2",
    "title": "Introduction to Machine Learning",
    "section": "Clustering",
    "text": "Clustering\n\nAlgorithm for hierarchical clustering"
  },
  {
    "objectID": "talks/ml-intro/index.html#clustering-3",
    "href": "talks/ml-intro/index.html#clustering-3",
    "title": "Introduction to Machine Learning",
    "section": "Clustering",
    "text": "Clustering\n\nAlgorithm for hierarchical clustering"
  },
  {
    "objectID": "talks/ml-intro/index.html#clustering-4",
    "href": "talks/ml-intro/index.html#clustering-4",
    "title": "Introduction to Machine Learning",
    "section": "Clustering",
    "text": "Clustering\n\nAlgorithm for hierarchical clustering"
  },
  {
    "objectID": "talks/ml-intro/index.html#dimensionality-reduction",
    "href": "talks/ml-intro/index.html#dimensionality-reduction",
    "title": "Introduction to Machine Learning",
    "section": "Dimensionality Reduction",
    "text": "Dimensionality Reduction\n\nSchematic PCA."
  },
  {
    "objectID": "talks/ml-intro/index.html#dimensionality-reduction-1",
    "href": "talks/ml-intro/index.html#dimensionality-reduction-1",
    "title": "Introduction to Machine Learning",
    "section": "Dimensionality Reduction",
    "text": "Dimensionality Reduction\n\nUsing dimensionality reduction to explore 22,000 dimensions of gene expression data on 280 samples.\nhttps://seandavi.github.io/ITR/geoquery_mds.html"
  },
  {
    "objectID": "talks/ml-intro/index.html#future-directions-in-machine-learning",
    "href": "talks/ml-intro/index.html#future-directions-in-machine-learning",
    "title": "Introduction to Machine Learning",
    "section": "Future Directions in Machine Learning",
    "text": "Future Directions in Machine Learning\n\nAutoML: Automating the ML pipeline\nFederated Learning: Training models on decentralized data\nExplainable AI: Making black-box models more interpretable\nQuantum Machine Learning: Leveraging quantum computing for ML\nContinual Learning: Adapting to new data without forgetting old patterns"
  },
  {
    "objectID": "talks/ml-intro/index.html#conclusion",
    "href": "talks/ml-intro/index.html#conclusion",
    "title": "Introduction to Machine Learning",
    "section": "Conclusion",
    "text": "Conclusion\n\nSupervised learning: Predicting outcomes based on labeled data\n\nClassification: Assigning labels to data\nRegression: Predicting continuous values\n\nUnsupervised learning: Finding patterns in unlabeled data\n\nClustering: Grouping similar data points\nDimensionality reduction: Simplifying complex data by reducing dimensions\n\nReinforcement learning: Learning through interaction with an environment"
  },
  {
    "objectID": "talks/ml-intro/index.html#resources",
    "href": "talks/ml-intro/index.html#resources",
    "title": "Introduction to Machine Learning",
    "section": "Resources",
    "text": "Resources\n\nRecent reviews\n\nMachine Learning in Genomic Medicine: A Review of Computational Problems and Data Sets\nOpportunities And Obstacles For Deep Learning In Biology And Medicine\n\nHands-on Tutorials\n\nhttps://seandavi.github.io/RBiocBook\nMany online courses and tutorials\n\nBlogs and online materials\n\nhttps://blog.recast.ai/machine-learning-algorithms/\nhttps://www.youtube.com/channel/UCWN3xxRkmTPmbKwht9FuE5A\nhttps://www.youtube.com/c/joshstarmer\n\nMachine Learning in R\n\nhttps://www.datacamp.com/community/tutorials/machine-learning-in-r\nhttps://daviddalpiaz.github.io/r4sl/"
  },
  {
    "objectID": "talks/llm-intro.html#word-embeddings",
    "href": "talks/llm-intro.html#word-embeddings",
    "title": "What are Large Language Models, anyway?",
    "section": "Word embeddings",
    "text": "Word embeddings"
  },
  {
    "objectID": "talks/llm-intro.html#training",
    "href": "talks/llm-intro.html#training",
    "title": "What are Large Language Models, anyway?",
    "section": "Training",
    "text": "Training\n\n\nCol 1\n\nCol 2\n\nCol 3\n\nCol 4"
  },
  {
    "objectID": "talks/llm-intro.html#training-1",
    "href": "talks/llm-intro.html#training-1",
    "title": "What are Large Language Models, anyway?",
    "section": "Training",
    "text": "Training\n\n\nCol 1"
  },
  {
    "objectID": "talks/llm-intro.html#training-2",
    "href": "talks/llm-intro.html#training-2",
    "title": "What are Large Language Models, anyway?",
    "section": "Training",
    "text": "Training\n\n\nCol 1\n\nCol 2\n\nCol 3\n\nCol 4"
  },
  {
    "objectID": "talks/llm-intro.html#section-1",
    "href": "talks/llm-intro.html#section-1",
    "title": "What are Large Language Models, anyway?",
    "section": "",
    "text": "Large, general-purpose language models pre-trained on large corpora of text data that can be fine-tuned for specific purposes."
  },
  {
    "objectID": "talks/llm-intro.html#section-2",
    "href": "talks/llm-intro.html#section-2",
    "title": "What are Large Language Models, anyway?",
    "section": "",
    "text": "Language Models, anyway?"
  },
  {
    "objectID": "talks/llm-intro.html#what-is-pre-training",
    "href": "talks/llm-intro.html#what-is-pre-training",
    "title": "What are Large Language Models, anyway?",
    "section": "What is pre-training?",
    "text": "What is pre-training?\n\n\nStay!\n\n\nCome!\n\n\nSit!\n\n\nBeg!\n\n\n\nOur dog has received general-purpose training and is a good canine citizen."
  },
  {
    "objectID": "talks/llm-intro.html#section-3",
    "href": "talks/llm-intro.html#section-3",
    "title": "What are Large Language Models, anyway?",
    "section": "",
    "text": "Animating content"
  },
  {
    "objectID": "talks/llm-intro.html#section-4",
    "href": "talks/llm-intro.html#section-4",
    "title": "What are Large Language Models, anyway?",
    "section": "",
    "text": "Animating content"
  },
  {
    "objectID": "talks/llm-intro.html#title",
    "href": "talks/llm-intro.html#title",
    "title": "What are Large Language Models, anyway?",
    "section": "title",
    "text": "title\n\nFine-tuning is the process of training a model on a specific task or dataset."
  },
  {
    "objectID": "talks/llm-intro.html#title-1",
    "href": "talks/llm-intro.html#title-1",
    "title": "What are Large Language Models, anyway?",
    "section": "title",
    "text": "title\n\nFine-tuning is the process of training a model on a specific task or dataset."
  },
  {
    "objectID": "talks/llm-intro.html#title-2",
    "href": "talks/llm-intro.html#title-2",
    "title": "What are Large Language Models, anyway?",
    "section": "title",
    "text": "title\n\nFine-tuning is the process of training a model on a specific task or dataset."
  },
  {
    "objectID": "talks/llm-intro.html#title-3",
    "href": "talks/llm-intro.html#title-3",
    "title": "What are Large Language Models, anyway?",
    "section": "title",
    "text": "title\n\nFine-tuning is the process of training a model on a specific task or dataset."
  },
  {
    "objectID": "talks/llm-intro.html#title-4",
    "href": "talks/llm-intro.html#title-4",
    "title": "What are Large Language Models, anyway?",
    "section": "title",
    "text": "title\n\nFine-tuning is the process of training a model on a specific task or dataset.\nGeneral-purpose models can be fine-tuned for specific tasks."
  },
  {
    "objectID": "talks/llm-intro.html#title-5",
    "href": "talks/llm-intro.html#title-5",
    "title": "What are Large Language Models, anyway?",
    "section": "title",
    "text": "title\n\n\nFine-tuning is the process of training a model on a specific task or dataset.\n\n\n\nGeneral-purpose models can be fine-tuned for specific tasks."
  },
  {
    "objectID": "talks/llm-intro.html#title-6",
    "href": "talks/llm-intro.html#title-6",
    "title": "What are Large Language Models, anyway?",
    "section": "title",
    "text": "title\n\n\nFine-tuning is the process of training a model on a specific task or dataset.\nGeneral-purpose models can be fine-tuned for specific tasks."
  },
  {
    "objectID": "talks/llm-intro.html#title-7",
    "href": "talks/llm-intro.html#title-7",
    "title": "What are Large Language Models, anyway?",
    "section": "title",
    "text": "title\n\n\n\n\nFine-tuning is the process of training a model on a specific task or dataset.\n\n\n\nGeneral-purpose models can be fine-tuned for specific tasks.\n\n\n\naGeneral-purpose models can be fine-tuned for specific tasks."
  },
  {
    "objectID": "talks/llm-intro.html#title-8",
    "href": "talks/llm-intro.html#title-8",
    "title": "What are Large Language Models, anyway?",
    "section": "title",
    "text": "title\n\n\n\n\nFine-tuning is the process of training a model on a specific task or dataset.\n\n\n\nGeneral-purpose models can be fine-tuned for specific tasks.\n\n\n\naGeneral-purpose models can be fine-tuned for specific tasks."
  },
  {
    "objectID": "talks/llm-intro.html#title-9",
    "href": "talks/llm-intro.html#title-9",
    "title": "What are Large Language Models, anyway?",
    "section": "title",
    "text": "title\n\n\n\n\nFine-tuning is the process of training a model on a specific task or dataset.\n\n\n\nGeneral-purpose models can be fine-tuned for specific tasks.\n\n\n\naGeneral-purpose models can be fine-tuned for specific tasks."
  },
  {
    "objectID": "talks/llm-intro.html#section-5",
    "href": "talks/llm-intro.html#section-5",
    "title": "What are Large Language Models, anyway?",
    "section": "",
    "text": "Linear combinations of dimensions in vector space correlate with the semantic and syntactic roles of the words in the corpus. For illustration purposes, dimension d1 in the figure has a high positive correlation with living beings. A properly tuned word embedding model will map words with similar semantic or syntactic roles to adjacent regions in vector space. This property can be visualized through dimensionality reduction techniques such as t-SNE or PCA. Cultural concepts are also apparent in vector space as consistent offsets between vector representations of words sharing a particular relationship. For instance, in the bottom right of the figure, the dotted vector represents a gender regularity that goes from masculinity to femininity."
  },
  {
    "objectID": "talks/llm-intro.html#section-6",
    "href": "talks/llm-intro.html#section-6",
    "title": "What are Large Language Models, anyway?",
    "section": "",
    "text": "Which dimension shows a strong correlation with masculinity-femininity?\n\n\n\n\nAnd what about royalty-commoner?\n\n\n\n\nHow about dog-cat?\n\n\n\n\nGiven the answer to the above, what might be an approximate value of the dog-cat dimension for kitten?"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this site\n\n\n\nCitationBibTeX citation:@online{davis,\n  author = {Davis, Sean},\n  title = {About},\n  url = {https://seandavi.github.io/IDPT-8079/about.html},\n  langid = {en}\n}\nFor attribution, please cite this work as:\nDavis, Sean. n.d. “About.” https://seandavi.github.io/IDPT-8079/about.html."
  },
  {
    "objectID": "Exercises/pubmed.html",
    "href": "Exercises/pubmed.html",
    "title": "IDPT-8079: Frontier of AI in Medicine",
    "section": "",
    "text": "!uv init\n\n\nRunning cells with 'Python 3.12.4' requires the ipykernel package.\n\nRun the following command to install 'ipykernel' into the Python environment. \n\nCommand: '/opt/homebrew/bin/python3 -m pip install ipykernel -U --user --force-reinstall'\n\n\n\n\n\n\nCitationBibTeX citation:@online{davis,\n  author = {Davis, Sean},\n  url = {https://seandavi.github.io/IDPT-8079/Exercises/pubmed.html},\n  langid = {en}\n}\nFor attribution, please cite this work as:\nDavis, Sean. n.d. https://seandavi.github.io/IDPT-8079/Exercises/pubmed.html."
  },
  {
    "objectID": "book/nlp-section/llms.html",
    "href": "book/nlp-section/llms.html",
    "title": "Transition to Large Language Models",
    "section": "",
    "text": "Natural Language Processing (NLP) has advanced remarkably in recent years, driven by a transition from traditional approaches like word embeddings to large language models (LLMs) based on transformer architectures. To understand this leap, it is crucial to first grasp the limitations of earlier methods and how LLMs overcome them.\n\n\nWord embeddings, such as Word2Vec and GloVe, marked a significant step forward in NLP by representing words as continuous vectors in a high-dimensional space. These embeddings allowed models to capture semantic relationships between words based on their co-occurrence in large corpora. For instance, the famous relationship between “king” and “queen” being similar to “man” and “woman” ?@fig-king-queen-analogy became a canonical example of how word vectors capture analogies.\nHowever, static word embeddings like Word2Vec have a key limitation: they assign each word a single vector, regardless of context. For example, the word “bank” will have the same vector whether we are talking about a financial institution or the side of a river. This one-size-fits-all representation struggles with polysemy (multiple meanings of a word) and fails to incorporate the dynamic context in which a word appears.\nThis limitation set the stage for context-aware models—first through innovations like ELMo (Embeddings from Language Models), which introduced context-dependent embeddings, and later through the transformer architecture, which powers today’s LLMs.\n\n\n\nThe transformer architecture, introduced by [@vaswaniAttentionAllYou2017], represents a paradigm shift in NLP. Unlike earlier recurrent neural networks (RNNs), transformers do not process data sequentially. Instead, they operate on entire sequences of words (or tokens) at once, making them highly parallelizable and more efficient for training on large datasets.\nAt the heart of transformers is the attention mechanism. Attention allows the model to focus on relevant parts of the input sequence while processing a word. This capability enables transformers to capture long-range dependencies and relationships between words more effectively than RNNs or convolutional neural networks (CNNs).\nThe input to a transformer is typically a sequence of word embeddings, which are passed through multiple layers of encoders. Each encoder consists of two main components: a self-attention mechanism and a feed-forward neural network. The self-attention mechanism helps the model weigh the importance of different words in the sequence, while the feed-forward network processes this information to generate the final output. Remember that one of the shortcomings of word embeddings is that they do not capture context; each word has one-and-only-one embedding vector. Transformers address this by considering the entire sequence when encoding a word.\nFigure 1 shows how the attention mechanism helps the model understand the context of a word in a sentence. The encoding of the word “it” in the sentence “The animal didn’t cross the street because it was too tired” is influenced by the attention mechanism, which focuses on “The Animal” to understand the referent of “it”.\n\n\n\n\n\n\nFigure 1: Attention: As we are encoding the word “it” in encoder #5 (the top encoder in the stack), part of the attention mechanism was focusing on “The Animal”, and baked a part of its representation into the encoding of “it”.\n\n\n\nFigure 2: Example of attention mechanism highlighting key word dependencies within a sentence.\nThe architecture of transformers consists of an encoder and a decoder. While the original transformer model was designed for sequence-to-sequence tasks like translation, recent advancements focus on pre-training the encoder (in models like BERT) or both encoder and decoder (in models like GPT). These models, known as large language models, can be fine-tuned for various downstream tasks, including text generation, question answering, and summarization.\nAgain, one of the key innovations in transformers is the concept of self-attention, which allows the model to weigh the importance of different words in a sentence when encoding a particular word. In transformers, this process is done in parallel for multiple attention heads, leading to the concept of multi-head attention. Multi-head attention enables the model to focus on different aspects of a sentence simultaneously. While one head might focus on syntactic structure (such as subject-verb agreement), another might capture semantic relationships (like identifying the recipient of an action).\nTable 1 below summarizes the advantages of self-attention and multi-head attention compared to previous methods like RNNs and CNNs:\nTable 1: Advantages of Self-Attention and Multi-Head Attention\n\n\n\n\n\n\n\n\nFeature\nRNNs / CNNs\nTransformers (Self-Attention)\n\n\n\n\nSequential Processing\nYes (slower, non-parallel)\nNo (parallel processing of entire input)\n\n\nCapturing Long-Range Dependencies\nLimited (vanishing gradients)\nEfficiently captures distant relationships\n\n\nContextual Understanding\nLimited to fixed window\nFull sequence considered for each word\n\n\nTraining Efficiency\nSlower due to sequence dependencies\nHighly efficient (leverages parallelism)\n\n\n\n\n\n\nTransformers provided the foundation for large language models (LLMs), but what distinguishes LLMs from smaller models is their sheer size. LLMs such as OpenAI’s GPT (Generative Pre-trained Transformer) and Google’s BERT (Bidirectional Encoder Representations from Transformers) are trained on massive corpora of text, often with billions or even trillions of parameters. This enables them to generalize across a wide variety of NLP tasks.\nGPT models, for example, are designed for text generation tasks, while BERT models are pre-trained for bidirectional understanding of language. BERT’s bidirectional nature allows it to capture context from both left and right contexts, making it particularly effective for tasks like question answering and text classification.\nWhen discussing the process of building and refining large language models (LLMs), it’s crucial to understand the progression from pre-training to fine-tuning and instruction tuning. These phases build upon each other, and all rely on the powerful principle of transfer learning.\n\n\nThe first step in developing a large language model is pre-training. In this phase, the model is trained on vast amounts of diverse text data from the internet—news articles, books, websites, social media posts, etc. The goal is for the model to learn general patterns in language: grammar, sentence structure, and relationships between words.\nDuring pre-training, the model is not explicitly trained to perform any specific task (such as answering questions or translating text). Instead, it learns by predicting the next word in a sentence (a common objective known as masked language modeling or causal language modeling). This helps the model build a broad, high-level understanding of how language works.\n\nExample: If the model is given the sentence, “The cat is sitting on the ___,” it learns to predict that “mat” or “sofa” might be appropriate completions based on what it has seen in similar contexts during training.\n\nBy the end of this phase, the model has developed a deep, though general, understanding of language, but it hasn’t yet been specialized for any particular task.\n\n\n\nThe fine-tuning phase builds on the knowledge gained during pre-training. Here, the model is trained on smaller, task-specific datasets to specialize in a particular task, such as medical diagnosis, summarization, or chatbot responses.\nIn this stage, transfer learning is applied. The general language understanding developed during pre-training is transferred to the new task, allowing the model to adapt quickly with much less data than would otherwise be required. Fine-tuning modifies the model slightly to better fit the specific needs of the task, but it doesn’t start from scratch. Instead, the model reuses and adapts what it already knows.\n\nExample: Suppose a pre-trained model is fine-tuned for medical language. During fine-tuning, it adapts its broad language knowledge to better understand medical terminology, patient reports, and clinical guidelines. This allows the model to assist healthcare professionals more effectively in tasks like summarizing patient history or answering medical queries.\n\nThe use of transfer learning means that the model can generalize well from smaller datasets, because it leverages the vast amount of language knowledge it has already acquired during pre-training.\n\n\n\nInstruction tuning is a refinement of fine-tuning where the model is trained to follow structured, task-specific human instructions. In this phase, the model is provided with examples of how humans give instructions and what the desired outcomes should look like.\nTransfer learning plays a role here too—again, the model is building upon the language patterns learned during pre-training, and it adapts those patterns to better understand and respond to human commands.\n\nExample: A model might be given a prompt like, “Summarize this article in two sentences” or “Translate this sentence to French.” During instruction tuning, it learns how to execute these specific requests more effectively.\n\nBy the end of instruction tuning, the model becomes more user-friendly and better at handling structured, goal-oriented tasks. This is the stage where models begin to behave more like assistants that can respond coherently to specific requests from users.\n\n\n\nTransfer learning is the foundation that makes the transition from pre-training to fine-tuning and instruction tuning possible. It enables the model to transfer its general knowledge from the pre-training phase to the more specialized tasks it encounters during fine-tuning and instruction tuning. This is why transfer learning is considered a key advantage of LLMs—without it, each task would require training a model from scratch, which would be computationally expensive and data-intensive.\nIn simpler terms, transfer learning is the reason why a model trained on large, general datasets can still perform well on specific tasks with relatively small amounts of data. It’s not a separate step but rather a fundamental property that makes fine-tuning and instruction tuning both efficient and effective.\nThis version emphasizes the flow of how transfer learning operates across the stages, clarifying that it is the mechanism enabling these transitions, rather than a separate part of the model-building process. Let me know if this works for you or if you’d like further adjustments!\n\n\n\n\nWhile most folks are familiar with ChatGPT, there are many other LLMs that are available for us (See Table 1). Many of the commercially available LLMs have a “free-tier” that allows for everyday use. In addition to very large models like ChatGPT, there are smaller models that, in many cases, are more than sufficient for many tasks, are more cost-effective, are faster to run, and are more energy-efficient.\n\n\n\nTable 1: A selection of large language models (LLMs) available for use, including ChatGPT, Claude, Gemini, HuggingChat, Microsoft Copilot, and groq.\n\n\n\n\n\nModel Name\nLink\n\n\n\n\nChatGPT\nLink\n\n\nClaude\nLink\n\n\nGemini\nLink\n\n\nHuggingChat\nLink\n\n\nMicrosoft Copilot\nLink\n\n\ngroq\nLink\n\n\n\n\n\n\n\n\n\nThis section is structured as an abbreviated literature review, highlighting key studies and findings in the field of healthcare NLP. It showcases the transformative impact of large language models (LLMs) like GPT and BERT on various healthcare applications, including clinical documentation, medical imaging, and patient care.\nIn this short review by @shahCreationAdoptionLarge2023, the authors observe that LLMs are being adopted in healthcare, but often without proper evaluation and focus on the goals and the extent to which LLMs reach them. They propose that instead of asking “New users have been asking how the LLMs and the chatbots powered by them will reshape medicine,” we should be asking “How can the intended medical use shape the training of the LLMs and the chatbots or the other applications they power?”\nIn what is now considered a seminal paper, @ayersComparingPhysicianArtificial2023 compared the responses of physicians and AI chatbots to patient questions sourced from Reddit’s r/AskDocs. Table 2 summarizes the key findings of this cross-sectional study, highlighting the advantages of chatbot responses in terms of length, quality of information, and empathy.\n\n\n\nTable 2: Summary of findings from a cross-sectional study comparing chatbot (ChatGPT) and physician responses to patient questions sourced from Reddit’s r/AskDocs. Evaluators significantly favored chatbot responses, which were longer, rated as higher quality, and more empathetic. This suggests AI chatbots may be useful for drafting patient responses, potentially reducing clinician workload and improving patient engagement. Future research, including randomized trials, is warranted to explore AI’s role in enhancing clinical care and reducing physician burnout.\n\n\n\n\n\n\n\n\n\n\n\nMeasure\nPhysicians\nChatbot\nStatistical Significance\n\n\n\n\nEvaluator Preference\nPreferred in 21.4% (95% CI, 18.2%-25.0%)\nPreferred in 78.6% (95% CI, 75.0%-81.8%)\n-\n\n\nResponse Length (mean words)\n52 (IQR 17-62)\n211 (IQR 168-245)\nt = 25.4, P &lt; .001\n\n\nQuality of Information (mean score)\nSignificantly lower (22.1% rated as good or very good, 95% CI, 16.4%-28.2%)\nSignificantly higher (78.5% rated as good or very good, 95% CI, 72.3%-84.1%)\nt = 13.3, P &lt; .001\n\n\nEmpathy of Responses (mean score)\n4.6% rated empathetic or very empathetic (95% CI, 2.1%-7.7%)\n45.1% rated empathetic or very empathetic (95% CI, 38.5%-51.8%)\nt = 18.9, P &lt; .001\n\n\n\n\n\n\nAn extensive review of research about and use of LLMs in healthcare by @luLargeLanguageModels2024 provides a comprehensive summary of the Journal of the American Medical Informatics Association (JAMIA) special issue on LLMs in healthcare. The review covers a wide range of topics, including the use of LLMs in clinical documentation, medical imaging, patient care, and more. Figure 2 visualizes the various LLMs discussed in the special issue.\n\n\n\n\n\n\nFigure 2: LLMs used in the special issue of JAMIA [^]\n\n\n\nIntegrating LLMs into healthcare settings has a lot of potential, but doing so is hard. @labkoffResponsibleFutureRecommendations2024 “aims to make practical suggestions for creating methods, rules, and guidelines to ensure that the development, testing, supervision, and use of AI in clinical decision support (CDS) systems are done well and safely for patients.” The authors suggest four key recommendations for doing so [@labkoffResponsibleFutureRecommendations2024].\n\nBuilding safe and trustworthy systems;\nDeveloping validation, verification, and certification processes for AI-CDS systems;\nProviding a means of safety monitoring and reporting at the national level; and\nEnsuring that appropriate documentation and end-user training are provided.\n\nThe paper is packed with practical advice and insights for healthcare professionals and AI developers looking to integrate LLMs into clinical practice.\nThe status of public comfort with the use of ChatGPT in healthcare was evaluated by @plattPublicComfortUse2024a.\nA group of investigators has been collaborating to produce and inroduce a CLinical Artificial Intelligence Checklist (MI-CLAIM-GEN) for reporting information about a generative model [@miaoMinimumInformationCLinical2024]. The checklist is designed to help developers and users of generative models understand the model’s development, intended use, performance, limitations, and recommendations for safe deployment. The checklist is intended to improve transparency and trust in the use of generative models in clinical settings. An example of a suggested clinical model card is shown in Figure 3.\n\n\n\n\n\n\n\n\nFigure 3: An example model card as proposed by @miaoMinimumInformationCLinical2024, formatted as a clinical “model facts” label, for a fictional model created to assist in clinical decision support around sepsis diagnosis and management. The clinical model card should provide a summary of how a model was developed, intended use, out-of-scope uses, performance, limitations, and recommendations for safe deployment.\n\n\n\nNumerous collections of high-quality, highly-cited work that includes LLMs in healthcare and biomedical research are available and highlighted in Table 3.\n\n\n\nTable 3: Collections of research articles on AI and LLMs in healthcare from leading journals and publishers.\n\n\n\n\n\nCollection\nDescription\n\n\n\n\nJAMIA Special Issue\nA collection of research articles on LLMs in healthcare\n\n\nJAMA Network AI Collection\nA series of articles on AI in healthcare from JAMA Network\n\n\nNature AI Collection\nA curated selection of AI research in medicine from Nature Portfolio\n\n\n\n\n\n\n\n\n\nA foundation model refers to a large, pre-trained model that serves as a general-purpose starting point for a wide range of downstream tasks. These models are typically trained on massive datasets using self-supervised learning techniques, allowing them to capture a broad and versatile understanding of the data, such as language or images. Once trained, foundation models can be fine-tuned or adapted for specific tasks, like translation, summarization, or image recognition, through additional, smaller-scale training phases.\nThe term is often used in the context of large-scale machine learning models like GPT (Generative Pre-trained Transformers) and BERT (Bidirectional Encoder Representations from Transformers) in natural language processing (NLP), or models like CLIP and DALL-E for vision tasks. These models can be thought of as foundational because they provide a base of knowledge that can be reused and customized for numerous applications.\n\n\n\nPre-trained on Massive Datasets: Foundation models are typically pre-trained on vast amounts of unlabeled data, such as text scraped from the web or millions of images, enabling them to learn patterns and representations that generalize across domains.\nSelf-supervised Learning: Pre-training often uses self-supervised learning techniques, where the model learns to predict parts of the input (e.g., predicting the next word in a sentence) without requiring labeled data. This enables the model to scale to very large datasets.\nVersatility: Because they are trained to capture general patterns in the data, foundation models can be fine-tuned or adapted for a wide range of tasks with relatively little task-specific data. For example, a foundation language model can be fine-tuned for tasks like question answering, summarization, or even medical diagnosis with only a modest amount of new data for each specific task.\nTransfer Learning: Foundation models are excellent at leveraging transfer learning, meaning that the knowledge they acquire during pre-training is transferable to new tasks with minimal additional training. This reduces the need for training a new model from scratch for each task.\nScalability: The term “foundation” highlights how these models serve as a scalable base for many different applications. Once the initial model is pre-trained, it can be fine-tuned for different domains, such as legal text, scientific literature, or medical data, without needing to retrain the entire model from scratch.\nGeneralization across Modalities: Some foundation models, such as CLIP, operate across different data types (e.g., images and text), allowing them to generalize across modalities, making them highly adaptable for diverse use cases.\n\n\n\n\nThe significance of foundation models lies in their ability to democratize machine learning development. Instead of requiring each new application to build a model from scratch, developers can use these pre-trained models as a starting point, saving time, computational resources, and data. This shift allows for the rapid deployment of models in a wide variety of fields, from healthcare to finance to creative industries.\nFor example: - GPT-3, a foundation model for natural language processing, can be adapted to answer questions, write essays, or even generate programming code. - BERT has been used as the foundation for various NLP tasks, such as named entity recognition, text classification, and sentiment analysis. - CLIP combines text and images to provide capabilities such as image-text matching, zero-shot classification, and creative image generation.\n\n\n\nConsider GPT-3, one of the most well-known foundation models in NLP. GPT-3 was trained on a diverse range of text data from the internet, giving it a broad understanding of language patterns and general knowledge. After pre-training, GPT-3 can be fine-tuned or adapted to various tasks—whether it’s answering customer support questions, translating text between languages, or generating creative content. The key is that GPT-3 doesn’t need to be retrained from scratch for every new task; its “foundational” understanding of language can be reused and adapted.\n\n\n\nWhile foundation models have opened up numerous possibilities, there are also challenges associated with them: - Bias: Since foundation models are trained on vast and uncurated datasets, they often inherit biases present in the data (e.g., gender, racial, or societal biases). Fine-tuning can help reduce these biases, but they remain a significant concern. - Compute and Energy Costs: Pre-training foundation models requires enormous computational resources, and the environmental impact of training such large models is a growing area of concern. - Overfitting to the Internet’s Text: Pre-trained foundation models may overfit to the types of data they were exposed to during training (often text from the internet) and may struggle with highly specialized domains without substantial fine-tuning.\n\n\n\nA foundation model is a large, pre-trained machine learning model that serves as a versatile base for a wide variety of downstream tasks. It leverages transfer learning to apply the broad patterns it learned during pre-training to specific tasks with relatively little additional data. While they offer powerful capabilities, foundation models also pose challenges related to bias, resource requirements, and task-specific adaptation.\n\n\n\n\nThe transition to large language models (LLMs) based on transformer architectures has significantly advanced the field of natural language processing. By moving beyond static word embeddings to context-aware models, LLMs like GPT and BERT have demonstrated remarkable capabilities in understanding and generating human language. These models, powered by transfer learning and self-attention mechanisms, have found diverse applications across industries, including healthcare, finance, and creative fields."
  },
  {
    "objectID": "book/nlp-section/llms.html#introduction-from-word-embeddings-to-context-aware-models",
    "href": "book/nlp-section/llms.html#introduction-from-word-embeddings-to-context-aware-models",
    "title": "Transition to Large Language Models",
    "section": "",
    "text": "Word embeddings, such as Word2Vec and GloVe, marked a significant step forward in NLP by representing words as continuous vectors in a high-dimensional space. These embeddings allowed models to capture semantic relationships between words based on their co-occurrence in large corpora. For instance, the famous relationship between “king” and “queen” being similar to “man” and “woman” ?@fig-king-queen-analogy became a canonical example of how word vectors capture analogies.\nHowever, static word embeddings like Word2Vec have a key limitation: they assign each word a single vector, regardless of context. For example, the word “bank” will have the same vector whether we are talking about a financial institution or the side of a river. This one-size-fits-all representation struggles with polysemy (multiple meanings of a word) and fails to incorporate the dynamic context in which a word appears.\nThis limitation set the stage for context-aware models—first through innovations like ELMo (Embeddings from Language Models), which introduced context-dependent embeddings, and later through the transformer architecture, which powers today’s LLMs."
  },
  {
    "objectID": "book/nlp-section/llms.html#transformers-the-foundation-of-large-language-models",
    "href": "book/nlp-section/llms.html#transformers-the-foundation-of-large-language-models",
    "title": "Transition to Large Language Models",
    "section": "",
    "text": "The transformer architecture, introduced by [@vaswaniAttentionAllYou2017], represents a paradigm shift in NLP. Unlike earlier recurrent neural networks (RNNs), transformers do not process data sequentially. Instead, they operate on entire sequences of words (or tokens) at once, making them highly parallelizable and more efficient for training on large datasets.\nAt the heart of transformers is the attention mechanism. Attention allows the model to focus on relevant parts of the input sequence while processing a word. This capability enables transformers to capture long-range dependencies and relationships between words more effectively than RNNs or convolutional neural networks (CNNs).\nThe input to a transformer is typically a sequence of word embeddings, which are passed through multiple layers of encoders. Each encoder consists of two main components: a self-attention mechanism and a feed-forward neural network. The self-attention mechanism helps the model weigh the importance of different words in the sequence, while the feed-forward network processes this information to generate the final output. Remember that one of the shortcomings of word embeddings is that they do not capture context; each word has one-and-only-one embedding vector. Transformers address this by considering the entire sequence when encoding a word.\nFigure 1 shows how the attention mechanism helps the model understand the context of a word in a sentence. The encoding of the word “it” in the sentence “The animal didn’t cross the street because it was too tired” is influenced by the attention mechanism, which focuses on “The Animal” to understand the referent of “it”.\n\n\n\n\n\n\nFigure 1: Attention: As we are encoding the word “it” in encoder #5 (the top encoder in the stack), part of the attention mechanism was focusing on “The Animal”, and baked a part of its representation into the encoding of “it”.\n\n\n\nFigure 2: Example of attention mechanism highlighting key word dependencies within a sentence.\nThe architecture of transformers consists of an encoder and a decoder. While the original transformer model was designed for sequence-to-sequence tasks like translation, recent advancements focus on pre-training the encoder (in models like BERT) or both encoder and decoder (in models like GPT). These models, known as large language models, can be fine-tuned for various downstream tasks, including text generation, question answering, and summarization.\nAgain, one of the key innovations in transformers is the concept of self-attention, which allows the model to weigh the importance of different words in a sentence when encoding a particular word. In transformers, this process is done in parallel for multiple attention heads, leading to the concept of multi-head attention. Multi-head attention enables the model to focus on different aspects of a sentence simultaneously. While one head might focus on syntactic structure (such as subject-verb agreement), another might capture semantic relationships (like identifying the recipient of an action).\nTable 1 below summarizes the advantages of self-attention and multi-head attention compared to previous methods like RNNs and CNNs:\nTable 1: Advantages of Self-Attention and Multi-Head Attention\n\n\n\n\n\n\n\n\nFeature\nRNNs / CNNs\nTransformers (Self-Attention)\n\n\n\n\nSequential Processing\nYes (slower, non-parallel)\nNo (parallel processing of entire input)\n\n\nCapturing Long-Range Dependencies\nLimited (vanishing gradients)\nEfficiently captures distant relationships\n\n\nContextual Understanding\nLimited to fixed window\nFull sequence considered for each word\n\n\nTraining Efficiency\nSlower due to sequence dependencies\nHighly efficient (leverages parallelism)"
  },
  {
    "objectID": "book/nlp-section/llms.html#scaling-up-large-language-models-llms-like-gpt-and-bert",
    "href": "book/nlp-section/llms.html#scaling-up-large-language-models-llms-like-gpt-and-bert",
    "title": "Transition to Large Language Models",
    "section": "",
    "text": "Transformers provided the foundation for large language models (LLMs), but what distinguishes LLMs from smaller models is their sheer size. LLMs such as OpenAI’s GPT (Generative Pre-trained Transformer) and Google’s BERT (Bidirectional Encoder Representations from Transformers) are trained on massive corpora of text, often with billions or even trillions of parameters. This enables them to generalize across a wide variety of NLP tasks.\nGPT models, for example, are designed for text generation tasks, while BERT models are pre-trained for bidirectional understanding of language. BERT’s bidirectional nature allows it to capture context from both left and right contexts, making it particularly effective for tasks like question answering and text classification.\nWhen discussing the process of building and refining large language models (LLMs), it’s crucial to understand the progression from pre-training to fine-tuning and instruction tuning. These phases build upon each other, and all rely on the powerful principle of transfer learning.\n\n\nThe first step in developing a large language model is pre-training. In this phase, the model is trained on vast amounts of diverse text data from the internet—news articles, books, websites, social media posts, etc. The goal is for the model to learn general patterns in language: grammar, sentence structure, and relationships between words.\nDuring pre-training, the model is not explicitly trained to perform any specific task (such as answering questions or translating text). Instead, it learns by predicting the next word in a sentence (a common objective known as masked language modeling or causal language modeling). This helps the model build a broad, high-level understanding of how language works.\n\nExample: If the model is given the sentence, “The cat is sitting on the ___,” it learns to predict that “mat” or “sofa” might be appropriate completions based on what it has seen in similar contexts during training.\n\nBy the end of this phase, the model has developed a deep, though general, understanding of language, but it hasn’t yet been specialized for any particular task.\n\n\n\nThe fine-tuning phase builds on the knowledge gained during pre-training. Here, the model is trained on smaller, task-specific datasets to specialize in a particular task, such as medical diagnosis, summarization, or chatbot responses.\nIn this stage, transfer learning is applied. The general language understanding developed during pre-training is transferred to the new task, allowing the model to adapt quickly with much less data than would otherwise be required. Fine-tuning modifies the model slightly to better fit the specific needs of the task, but it doesn’t start from scratch. Instead, the model reuses and adapts what it already knows.\n\nExample: Suppose a pre-trained model is fine-tuned for medical language. During fine-tuning, it adapts its broad language knowledge to better understand medical terminology, patient reports, and clinical guidelines. This allows the model to assist healthcare professionals more effectively in tasks like summarizing patient history or answering medical queries.\n\nThe use of transfer learning means that the model can generalize well from smaller datasets, because it leverages the vast amount of language knowledge it has already acquired during pre-training.\n\n\n\nInstruction tuning is a refinement of fine-tuning where the model is trained to follow structured, task-specific human instructions. In this phase, the model is provided with examples of how humans give instructions and what the desired outcomes should look like.\nTransfer learning plays a role here too—again, the model is building upon the language patterns learned during pre-training, and it adapts those patterns to better understand and respond to human commands.\n\nExample: A model might be given a prompt like, “Summarize this article in two sentences” or “Translate this sentence to French.” During instruction tuning, it learns how to execute these specific requests more effectively.\n\nBy the end of instruction tuning, the model becomes more user-friendly and better at handling structured, goal-oriented tasks. This is the stage where models begin to behave more like assistants that can respond coherently to specific requests from users.\n\n\n\nTransfer learning is the foundation that makes the transition from pre-training to fine-tuning and instruction tuning possible. It enables the model to transfer its general knowledge from the pre-training phase to the more specialized tasks it encounters during fine-tuning and instruction tuning. This is why transfer learning is considered a key advantage of LLMs—without it, each task would require training a model from scratch, which would be computationally expensive and data-intensive.\nIn simpler terms, transfer learning is the reason why a model trained on large, general datasets can still perform well on specific tasks with relatively small amounts of data. It’s not a separate step but rather a fundamental property that makes fine-tuning and instruction tuning both efficient and effective.\nThis version emphasizes the flow of how transfer learning operates across the stages, clarifying that it is the mechanism enabling these transitions, rather than a separate part of the model-building process. Let me know if this works for you or if you’d like further adjustments!"
  },
  {
    "objectID": "book/nlp-section/llms.html#llms-in-the-wild",
    "href": "book/nlp-section/llms.html#llms-in-the-wild",
    "title": "Transition to Large Language Models",
    "section": "",
    "text": "While most folks are familiar with ChatGPT, there are many other LLMs that are available for us (See Table 1). Many of the commercially available LLMs have a “free-tier” that allows for everyday use. In addition to very large models like ChatGPT, there are smaller models that, in many cases, are more than sufficient for many tasks, are more cost-effective, are faster to run, and are more energy-efficient.\n\n\n\nTable 1: A selection of large language models (LLMs) available for use, including ChatGPT, Claude, Gemini, HuggingChat, Microsoft Copilot, and groq.\n\n\n\n\n\nModel Name\nLink\n\n\n\n\nChatGPT\nLink\n\n\nClaude\nLink\n\n\nGemini\nLink\n\n\nHuggingChat\nLink\n\n\nMicrosoft Copilot\nLink\n\n\ngroq\nLink"
  },
  {
    "objectID": "book/nlp-section/llms.html#applications-of-llms-in-healthcare-a-revolution-in-nlp",
    "href": "book/nlp-section/llms.html#applications-of-llms-in-healthcare-a-revolution-in-nlp",
    "title": "Transition to Large Language Models",
    "section": "",
    "text": "This section is structured as an abbreviated literature review, highlighting key studies and findings in the field of healthcare NLP. It showcases the transformative impact of large language models (LLMs) like GPT and BERT on various healthcare applications, including clinical documentation, medical imaging, and patient care.\nIn this short review by @shahCreationAdoptionLarge2023, the authors observe that LLMs are being adopted in healthcare, but often without proper evaluation and focus on the goals and the extent to which LLMs reach them. They propose that instead of asking “New users have been asking how the LLMs and the chatbots powered by them will reshape medicine,” we should be asking “How can the intended medical use shape the training of the LLMs and the chatbots or the other applications they power?”\nIn what is now considered a seminal paper, @ayersComparingPhysicianArtificial2023 compared the responses of physicians and AI chatbots to patient questions sourced from Reddit’s r/AskDocs. Table 2 summarizes the key findings of this cross-sectional study, highlighting the advantages of chatbot responses in terms of length, quality of information, and empathy.\n\n\n\nTable 2: Summary of findings from a cross-sectional study comparing chatbot (ChatGPT) and physician responses to patient questions sourced from Reddit’s r/AskDocs. Evaluators significantly favored chatbot responses, which were longer, rated as higher quality, and more empathetic. This suggests AI chatbots may be useful for drafting patient responses, potentially reducing clinician workload and improving patient engagement. Future research, including randomized trials, is warranted to explore AI’s role in enhancing clinical care and reducing physician burnout.\n\n\n\n\n\n\n\n\n\n\n\nMeasure\nPhysicians\nChatbot\nStatistical Significance\n\n\n\n\nEvaluator Preference\nPreferred in 21.4% (95% CI, 18.2%-25.0%)\nPreferred in 78.6% (95% CI, 75.0%-81.8%)\n-\n\n\nResponse Length (mean words)\n52 (IQR 17-62)\n211 (IQR 168-245)\nt = 25.4, P &lt; .001\n\n\nQuality of Information (mean score)\nSignificantly lower (22.1% rated as good or very good, 95% CI, 16.4%-28.2%)\nSignificantly higher (78.5% rated as good or very good, 95% CI, 72.3%-84.1%)\nt = 13.3, P &lt; .001\n\n\nEmpathy of Responses (mean score)\n4.6% rated empathetic or very empathetic (95% CI, 2.1%-7.7%)\n45.1% rated empathetic or very empathetic (95% CI, 38.5%-51.8%)\nt = 18.9, P &lt; .001\n\n\n\n\n\n\nAn extensive review of research about and use of LLMs in healthcare by @luLargeLanguageModels2024 provides a comprehensive summary of the Journal of the American Medical Informatics Association (JAMIA) special issue on LLMs in healthcare. The review covers a wide range of topics, including the use of LLMs in clinical documentation, medical imaging, patient care, and more. Figure 2 visualizes the various LLMs discussed in the special issue.\n\n\n\n\n\n\nFigure 2: LLMs used in the special issue of JAMIA [^]\n\n\n\nIntegrating LLMs into healthcare settings has a lot of potential, but doing so is hard. @labkoffResponsibleFutureRecommendations2024 “aims to make practical suggestions for creating methods, rules, and guidelines to ensure that the development, testing, supervision, and use of AI in clinical decision support (CDS) systems are done well and safely for patients.” The authors suggest four key recommendations for doing so [@labkoffResponsibleFutureRecommendations2024].\n\nBuilding safe and trustworthy systems;\nDeveloping validation, verification, and certification processes for AI-CDS systems;\nProviding a means of safety monitoring and reporting at the national level; and\nEnsuring that appropriate documentation and end-user training are provided.\n\nThe paper is packed with practical advice and insights for healthcare professionals and AI developers looking to integrate LLMs into clinical practice.\nThe status of public comfort with the use of ChatGPT in healthcare was evaluated by @plattPublicComfortUse2024a.\nA group of investigators has been collaborating to produce and inroduce a CLinical Artificial Intelligence Checklist (MI-CLAIM-GEN) for reporting information about a generative model [@miaoMinimumInformationCLinical2024]. The checklist is designed to help developers and users of generative models understand the model’s development, intended use, performance, limitations, and recommendations for safe deployment. The checklist is intended to improve transparency and trust in the use of generative models in clinical settings. An example of a suggested clinical model card is shown in Figure 3.\n\n\n\n\n\n\n\n\nFigure 3: An example model card as proposed by @miaoMinimumInformationCLinical2024, formatted as a clinical “model facts” label, for a fictional model created to assist in clinical decision support around sepsis diagnosis and management. The clinical model card should provide a summary of how a model was developed, intended use, out-of-scope uses, performance, limitations, and recommendations for safe deployment.\n\n\n\nNumerous collections of high-quality, highly-cited work that includes LLMs in healthcare and biomedical research are available and highlighted in Table 3.\n\n\n\nTable 3: Collections of research articles on AI and LLMs in healthcare from leading journals and publishers.\n\n\n\n\n\nCollection\nDescription\n\n\n\n\nJAMIA Special Issue\nA collection of research articles on LLMs in healthcare\n\n\nJAMA Network AI Collection\nA series of articles on AI in healthcare from JAMA Network\n\n\nNature AI Collection\nA curated selection of AI research in medicine from Nature Portfolio"
  },
  {
    "objectID": "book/nlp-section/llms.html#an-aside-foundation-models-as-the-base-for-diverse-applications",
    "href": "book/nlp-section/llms.html#an-aside-foundation-models-as-the-base-for-diverse-applications",
    "title": "Transition to Large Language Models",
    "section": "",
    "text": "A foundation model refers to a large, pre-trained model that serves as a general-purpose starting point for a wide range of downstream tasks. These models are typically trained on massive datasets using self-supervised learning techniques, allowing them to capture a broad and versatile understanding of the data, such as language or images. Once trained, foundation models can be fine-tuned or adapted for specific tasks, like translation, summarization, or image recognition, through additional, smaller-scale training phases.\nThe term is often used in the context of large-scale machine learning models like GPT (Generative Pre-trained Transformers) and BERT (Bidirectional Encoder Representations from Transformers) in natural language processing (NLP), or models like CLIP and DALL-E for vision tasks. These models can be thought of as foundational because they provide a base of knowledge that can be reused and customized for numerous applications.\n\n\n\nPre-trained on Massive Datasets: Foundation models are typically pre-trained on vast amounts of unlabeled data, such as text scraped from the web or millions of images, enabling them to learn patterns and representations that generalize across domains.\nSelf-supervised Learning: Pre-training often uses self-supervised learning techniques, where the model learns to predict parts of the input (e.g., predicting the next word in a sentence) without requiring labeled data. This enables the model to scale to very large datasets.\nVersatility: Because they are trained to capture general patterns in the data, foundation models can be fine-tuned or adapted for a wide range of tasks with relatively little task-specific data. For example, a foundation language model can be fine-tuned for tasks like question answering, summarization, or even medical diagnosis with only a modest amount of new data for each specific task.\nTransfer Learning: Foundation models are excellent at leveraging transfer learning, meaning that the knowledge they acquire during pre-training is transferable to new tasks with minimal additional training. This reduces the need for training a new model from scratch for each task.\nScalability: The term “foundation” highlights how these models serve as a scalable base for many different applications. Once the initial model is pre-trained, it can be fine-tuned for different domains, such as legal text, scientific literature, or medical data, without needing to retrain the entire model from scratch.\nGeneralization across Modalities: Some foundation models, such as CLIP, operate across different data types (e.g., images and text), allowing them to generalize across modalities, making them highly adaptable for diverse use cases.\n\n\n\n\nThe significance of foundation models lies in their ability to democratize machine learning development. Instead of requiring each new application to build a model from scratch, developers can use these pre-trained models as a starting point, saving time, computational resources, and data. This shift allows for the rapid deployment of models in a wide variety of fields, from healthcare to finance to creative industries.\nFor example: - GPT-3, a foundation model for natural language processing, can be adapted to answer questions, write essays, or even generate programming code. - BERT has been used as the foundation for various NLP tasks, such as named entity recognition, text classification, and sentiment analysis. - CLIP combines text and images to provide capabilities such as image-text matching, zero-shot classification, and creative image generation.\n\n\n\nConsider GPT-3, one of the most well-known foundation models in NLP. GPT-3 was trained on a diverse range of text data from the internet, giving it a broad understanding of language patterns and general knowledge. After pre-training, GPT-3 can be fine-tuned or adapted to various tasks—whether it’s answering customer support questions, translating text between languages, or generating creative content. The key is that GPT-3 doesn’t need to be retrained from scratch for every new task; its “foundational” understanding of language can be reused and adapted.\n\n\n\nWhile foundation models have opened up numerous possibilities, there are also challenges associated with them: - Bias: Since foundation models are trained on vast and uncurated datasets, they often inherit biases present in the data (e.g., gender, racial, or societal biases). Fine-tuning can help reduce these biases, but they remain a significant concern. - Compute and Energy Costs: Pre-training foundation models requires enormous computational resources, and the environmental impact of training such large models is a growing area of concern. - Overfitting to the Internet’s Text: Pre-trained foundation models may overfit to the types of data they were exposed to during training (often text from the internet) and may struggle with highly specialized domains without substantial fine-tuning.\n\n\n\nA foundation model is a large, pre-trained machine learning model that serves as a versatile base for a wide variety of downstream tasks. It leverages transfer learning to apply the broad patterns it learned during pre-training to specific tasks with relatively little additional data. While they offer powerful capabilities, foundation models also pose challenges related to bias, resource requirements, and task-specific adaptation."
  },
  {
    "objectID": "book/nlp-section/llms.html#conclusion",
    "href": "book/nlp-section/llms.html#conclusion",
    "title": "Transition to Large Language Models",
    "section": "",
    "text": "The transition to large language models (LLMs) based on transformer architectures has significantly advanced the field of natural language processing. By moving beyond static word embeddings to context-aware models, LLMs like GPT and BERT have demonstrated remarkable capabilities in understanding and generating human language. These models, powered by transfer learning and self-attention mechanisms, have found diverse applications across industries, including healthcare, finance, and creative fields."
  },
  {
    "objectID": "book/intro.html",
    "href": "book/intro.html",
    "title": "Introduction",
    "section": "",
    "text": "Introduction\nThis is a book created from markdown and executable code.\nSee @knuth84 for additional discussion of literate programming.\n\n\n\n\nCitationBibTeX citation:@online{davis,\n  author = {Davis, Sean},\n  url = {https://seandavi.github.io/IDPT-8079/book/intro.html},\n  langid = {en}\n}\nFor attribution, please cite this work as:\nDavis, Sean. n.d. https://seandavi.github.io/IDPT-8079/book/intro.html."
  },
  {
    "objectID": "book/index.html",
    "href": "book/index.html",
    "title": "Preface",
    "section": "",
    "text": "Preface\nThis is a Quarto book.\nTo learn more about Quarto books visit https://quarto.org/docs/books.\n\n\n\n\nCitationBibTeX citation:@online{davis,\n  author = {Davis, Sean},\n  url = {https://seandavi.github.io/IDPT-8079/book/},\n  langid = {en}\n}\nFor attribution, please cite this work as:\nDavis, Sean. n.d. https://seandavi.github.io/IDPT-8079/book/."
  },
  {
    "objectID": "book/history-of-ai.html",
    "href": "book/history-of-ai.html",
    "title": "The Evolution of Artificial Intelligence",
    "section": "",
    "text": "Artificial Intelligence (AI) and Machine Learning (ML) have a rich and fascinating history that spans decades of human ingenuity and technological advancement. From the early theoretical concepts to the cutting-edge applications we see today, the journey of AI has been marked by periods of rapid progress, setbacks, and revolutionary breakthroughs. This chapter will take you through the key milestones and developments that have shaped the field of AI, offering insights into how we arrived at the current state of this transformative technology."
  },
  {
    "objectID": "book/history-of-ai.html#the-dawn-of-artificial-intelligence",
    "href": "book/history-of-ai.html#the-dawn-of-artificial-intelligence",
    "title": "The Evolution of Artificial Intelligence",
    "section": "The Dawn of Artificial Intelligence",
    "text": "The Dawn of Artificial Intelligence\nThe seeds of artificial intelligence were planted in the mid-20th century, with pioneering thinkers laying the groundwork for what would become a revolutionary field of study. In 1936, Alan Turing published his seminal paper on “Computable Numbers,” which introduced the concept of a universal machine capable of computing anything that is computable (Turing 1936). This theoretical framework would later become crucial in the development of modern computers and, by extension, artificial intelligence.\nBuilding on Turing’s work, Warren McCulloch and Walter Pitts made a significant contribution in 1943 by creating a computational model for neural networks (McCulloch and Pitts 1943). This early model, while simplistic by today’s standards, was a crucial step in understanding how the human brain processes information and how this process might be replicated in machines.\nThe year 1950 marked another pivotal moment when Alan Turing proposed what is now known as the Turing Test (Turing 1950). This test was designed to assess a machine’s ability to exhibit intelligent behavior indistinguishable from that of a human. The Turing Test sparked intense debate and research into the nature of intelligence and consciousness, issues that continue to be central to AI development and philosophy today.\nThe term “Artificial Intelligence” itself was coined in 1956 at the Dartmouth Conference, a gathering of prominent researchers who came together to discuss the possibility of creating machines that could think. This conference is widely regarded as the birth of AI as a formal field of study, setting the stage for decades of research and development to come."
  },
  {
    "objectID": "book/history-of-ai.html#science-fiction-meets-reality",
    "href": "book/history-of-ai.html#science-fiction-meets-reality",
    "title": "The Evolution of Artificial Intelligence",
    "section": "Science Fiction Meets Reality",
    "text": "Science Fiction Meets Reality\nWhile scientists were laying the theoretical foundations for AI, science fiction writers were exploring its potential implications for society. One of the most influential works in this regard was Isaac Asimov’s “I, Robot,” published in 1950 (Asimov 2004). This collection of nine science fiction short stories introduced the concept of positronic robots and, more importantly, the Three Laws of Robotics.\nAsimov’s Three Laws of Robotics were:\n\nA robot may not injure a human being or, through inaction, allow a human being to come to harm.\nA robot must obey the orders given it by human beings except where such orders would conflict with the First Law.\nA robot must protect its own existence as long as such protection does not conflict with the First or Second Laws.\n\nLater, Asimov added a “Zeroth Law” that superseded the others: A robot may not harm humanity, or, by inaction, allow humanity to come to harm.\nWhile these laws were created for fictional stories, they have had a profound impact on real-world AI development. Asimov’s work sparked crucial discussions about machine ethics and AI safety, influencing researchers to consider the ethical implications of their work. The concept of “friendly AI” draws clear parallels to Asimov’s laws, and many of the challenges presented in his stories mirror real-world AI alignment problems that researchers grapple with today.\nIn a darker, more mainstream vein, Stanley Kubrick’s 1968 film “2001: A Space Odyssey,” developed in parallel with Arthur C. Clarke, introduced the world to HAL 9000, a sentient AI system that goes rogue and poses a threat to the human crew of the spaceship Discovery One (Clarke and Kubrick 1968). HAL’s chilling portrayal as a seemingly benevolent but ultimately malevolent AI system raised important questions about the risks and ethical considerations of creating intelligent machines.\nAs we continue to develop increasingly sophisticated AI systems, we can draw valuable lessons from these fictional works, reminding us of the importance of ethical design, human-AI collaboration, and the potential consequences of unchecked technological advancement. Much of our understanding of how AI should be developed and deployed has been shaped by these early explorations of AI in science fiction."
  },
  {
    "objectID": "book/history-of-ai.html#the-golden-years-and-early-milestones",
    "href": "book/history-of-ai.html#the-golden-years-and-early-milestones",
    "title": "The Evolution of Artificial Intelligence",
    "section": "The Golden Years and Early Milestones",
    "text": "The Golden Years and Early Milestones\nThe period from 1956 to 1974 is often referred to as the “Golden Years” of AI research. During this time, there was great optimism about the potential of AI, and several significant developments took place. In 1957, Frank Rosenblatt developed the Perceptron, an early type of neural network that could learn to recognize simple patterns. This was a major step forward in machine learning, demonstrating that computers could be trained to perform tasks rather than simply following pre-programmed instructions.\nOne of the most notable achievements of this era was the creation of ELIZA in 1964 by Joseph Weizenbaum. ELIZA was one of the first chatbots, designed to simulate a conversation between a human and a machine as shown in Figure 1. ELIZA’s creator, Weizenbaum, intended the program as a method to explore communication between humans and machines. He was surprised and shocked that some people, including Weizenbaum’s secretary, attributed human-like feelings to the computer program. While its capabilities were limited by today’s standards, ELIZA was remarkably effective at creating the illusion of understanding. The program used pattern matching and substitution methodology to engage in conversation, often in the role of a Rogerian psychotherapist.\n\n\n\n\n\n\n\n\nFigure 1: An example conversation with ELIZA.\n\n\n\nELIZA would take users’ input and reflect their statements back to them in a way that encouraged further conversation. For example, if a user said, “I’m feeling sad today,” ELIZA might respond with, “Why do you think you’re feeling sad today?” This simple but effective approach to natural language processing was groundbreaking for its time.\nWhat was particularly fascinating about ELIZA was how quickly people became emotionally attached to the program, even when they knew it wasn’t genuinely intelligent. This phenomenon highlighted the potential for AI to engage with humans on an emotional level, a concept that continues to be explored and refined in modern AI development.\nWhile ELIZA’s responses were largely superficial, the program marked an important milestone in the development of AI and human-computer interaction. It demonstrated how conversation-based interfaces could influence the perception of intelligence and paved the way for more sophisticated natural language processing systems in the future."
  },
  {
    "objectID": "book/history-of-ai.html#the-rise-of-expert-systems",
    "href": "book/history-of-ai.html#the-rise-of-expert-systems",
    "title": "The Evolution of Artificial Intelligence",
    "section": "The Rise of Expert Systems",
    "text": "The Rise of Expert Systems\nAs AI research progressed, a new paradigm emerged in the 1970s and 1980s: expert systems. These were computer programs designed to emulate the decision-making ability of a human expert in a specific domain. Expert systems represented a shift from general problem-solving approaches to more focused, knowledge-intensive methods.\nAn expert system typically consists of three key components:\n\nA Knowledge Base: This contains domain-specific information and rules, essentially capturing the expertise of human specialists in a particular field.\nAn Inference Engine: This applies the rules in the knowledge base to derive new information or make decisions.\nA User Interface: This allows non-expert users to interact with the system, input data, and receive outputs.\n\nOne of the most famous expert systems was MYCIN, developed in the early 1970s at Stanford University. MYCIN was designed to assist physicians in diagnosing and treating bacterial infections, particularly bloodstream infections like bacteremia and meningitis. The system contained approximately 600 rules and used a backward chaining inference engine to arrive at diagnoses and treatment recommendations.\nMYCIN was groundbreaking in several ways. It incorporated certainty factors to handle uncertainty, a crucial feature in medical diagnosis where symptoms and test results are not always definitive. The system could also explain its reasoning process to users, enhancing transparency and trust. Perhaps most impressively, MYCIN achieved performance comparable to human experts in its domain.\nDespite its capabilities, MYCIN was never used in clinical practice due to ethical and legal concerns. However, its impact on AI research was significant. MYCIN pioneered several important concepts in AI and expert systems, including the separation of the knowledge base from the inference engine, the ability to explain reasoning, and methods for handling uncertainty. These principles influenced the development of subsequent expert systems and laid the groundwork for modern clinical decision support tools.\nThe era of expert systems demonstrated the potential of AI in specialized domains and highlighted the importance of capturing and utilizing expert knowledge. While these systems had limitations, such as difficulty in capturing tacit knowledge and struggles with unusual situations, they represented a significant step forward in practical AI applications."
  },
  {
    "objectID": "book/history-of-ai.html#challenges-and-the-ai-winter",
    "href": "book/history-of-ai.html#challenges-and-the-ai-winter",
    "title": "The Evolution of Artificial Intelligence",
    "section": "Challenges and the AI Winter",
    "text": "Challenges and the AI Winter\nDespite the initial enthusiasm and progress, the field of AI faced significant challenges in the mid-1970s and again in the late 1980s. These periods, known as “AI Winters,” were characterized by reduced funding and interest in AI research.\nThe first AI Winter (1974-1980) came about largely due to overpromising and underdelivering. Early AI researchers, buoyed by initial successes, made ambitious predictions about the capabilities of AI systems that failed to materialize in the expected timeframes. This led to skepticism among funders and policy-makers, resulting in cutbacks in AI research funding.\nThe second AI Winter (1987-1993) was triggered by the collapse of the market for specialized AI hardware. Many companies had invested heavily in developing specialized computers for AI applications, particularly for running expert systems. However, as general-purpose computers became more powerful and cost-effective, the market for these specialized machines dried up, leading to financial losses and another period of reduced investment in AI.\nThese challenging periods forced the AI community to reassess its goals and methods. Researchers shifted their focus towards more practical, focused applications of AI technology. This pragmatic approach would eventually lead to a revival of the field and set the stage for the machine learning revolution of the 1990s and beyond."
  },
  {
    "objectID": "book/history-of-ai.html#the-machine-learning-renaissance",
    "href": "book/history-of-ai.html#the-machine-learning-renaissance",
    "title": "The Evolution of Artificial Intelligence",
    "section": "The Machine Learning Renaissance",
    "text": "The Machine Learning Renaissance\nThe 1990s marked a significant shift in AI research towards data-driven approaches, particularly in the field of machine learning. This shift was driven by several factors, including increased computational power, the growing availability of large datasets, and advances in statistical methods.\nOne of the most visible successes of this era was IBM’s Deep Blue, a chess-playing computer that defeated world champion Garry Kasparov in 1997. This achievement captured the public imagination and demonstrated the potential of AI in mastering complex strategic tasks.\nThe focus on machine learning led to renewed interest in neural networks and other statistical methods. Researchers began developing more sophisticated algorithms capable of learning from data, paving the way for breakthroughs in areas such as computer vision, speech recognition, and natural language processing."
  },
  {
    "objectID": "book/history-of-ai.html#the-modern-era-big-data-and-deep-learning",
    "href": "book/history-of-ai.html#the-modern-era-big-data-and-deep-learning",
    "title": "The Evolution of Artificial Intelligence",
    "section": "The Modern Era: Big Data and Deep Learning",
    "text": "The Modern Era: Big Data and Deep Learning\nThe 2000s and 2010s saw exponential growth in AI capabilities, driven by the confluence of big data, increased computational power, and advances in deep learning algorithms. This period has been marked by a series of breakthroughs that have transformed AI from a primarily academic pursuit to a technology with wide-ranging practical applications.\nIn 2006, Geoffrey Hinton and his team introduced “deep belief networks,” marking the resurgence of deep learning. This work laid the foundation for modern AI applications, especially in image and speech recognition. The power of these techniques was dramatically demonstrated in 2012 when a deep neural network called AlexNet won the ImageNet competition, significantly outperforming traditional computer vision methods.\nThe development of more sophisticated AI systems led to high-profile achievements such as IBM Watson’s victory on the quiz show Jeopardy! in 2011. This demonstrated AI’s ability to process and understand natural language, leading to applications in healthcare, finance, and customer service. However, the subsequent challenges faced by Watson in real-world applications, such as its setbacks at MD Anderson Cancer Center, highlighted the complexity of applying AI to domains like healthcare.\nIn 2014, Ian Goodfellow introduced Generative Adversarial Networks (GANs), a novel approach where two neural networks compete to generate realistic data. This innovation has revolutionized image generation and unsupervised learning, powering advancements in AI-generated art and deepfake technology.\nThe field of AI continued to push boundaries with achievements like Google DeepMind’s AlphaGo defeating world champion Go player Lee Sedol in 2016. This milestone showcased the power of combining deep learning with reinforcement learning techniques.\nA major breakthrough came in 2017 with the introduction of the Transformer architecture by Vaswani et al. This innovation laid the groundwork for state-of-the-art natural language processing models like BERT and GPT, transforming our ability to understand and generate human language.\nRecent years have seen AI making significant contributions to scientific research, as exemplified by DeepMind’s AlphaFold solving the long-standing challenge of protein structure prediction in 2020. This breakthrough has opened new doors in drug discovery and molecular biology.\nThe development of large language models, culminating in systems like GPT-4 in 2023, has showcased the potential of AI for complex, nuanced language understanding and generation. These models have accelerated the development of AI-driven content creation and enhanced human-computer interaction, while also raising important questions about the nature of machine intelligence and the ethical implications of increasingly capable AI systems."
  },
  {
    "objectID": "book/history-of-ai.html#ai-and-machine-learning-in-healthcare-promises-and-pitfalls",
    "href": "book/history-of-ai.html#ai-and-machine-learning-in-healthcare-promises-and-pitfalls",
    "title": "The Evolution of Artificial Intelligence",
    "section": "AI and Machine Learning in Healthcare: Promises and Pitfalls",
    "text": "AI and Machine Learning in Healthcare: Promises and Pitfalls\nThe application of AI and Machine Learning in healthcare has been one of the most promising and closely watched areas of development in recent years. From diagnosis and treatment planning to drug discovery and personalized medicine, AI has shown potential to revolutionize various aspects of healthcare. However, this journey has been marked by both significant triumphs and notable setbacks, illustrating the complexities of applying AI to this critical domain.\n\nEarly Applications and Promise\nThe use of AI in healthcare dates back to the expert systems era of the 1970s. One of the earliest and most famous examples was MYCIN, developed at Stanford University in 1972. MYCIN was designed to identify bacteria causing severe infections and recommend antibiotics. Although it performed at a level comparable to human experts, it was never used in clinical practice due to ethical and legal concerns. Nevertheless, MYCIN laid important groundwork for future clinical decision support systems.\nIn the 1990s and 2000s, as machine learning techniques advanced, new applications in healthcare began to emerge. These included systems for analyzing medical images, predicting patient outcomes, and identifying patterns in electronic health records. For instance, computer-aided detection (CAD) systems for mammography, developed in the 1990s, became widely adopted to assist radiologists in identifying potential breast cancers.\n\n\nThe Watson Era: High Hopes and Hard Lessons\nOne of the most high-profile attempts to bring AI to healthcare was IBM’s Watson. Following its triumph on the quiz show Jeopardy! in 2011, IBM positioned Watson as a revolutionary tool for healthcare, particularly in oncology. The vision was to use Watson’s natural language processing and machine learning capabilities to analyze vast amounts of medical literature and patient data, providing clinicians with evidence-based treatment recommendations.\nIn 2013, IBM announced a collaboration with MD Anderson Cancer Center to use Watson in cancer care. The project, known as Oncology Expert Advisor, aimed to create a clinical decision support system for leukemia treatment. However, by 2017, the project had been put on hold after years of development and millions of dollars spent (Swetlitz 2017).\nThe challenges faced by Watson at MD Anderson highlighted several key issues:\n\nData Integration: Integrating Watson with the hospital’s electronic health records proved more difficult than anticipated.\nCustomization: The system required extensive customization to align with MD Anderson’s specific protocols and practices.\nValidation: There were concerns about the accuracy and reliability of Watson’s recommendations.\nCost: The project’s costs significantly exceeded initial estimates.\n\nThis setback was a sobering reminder of the complexities involved in applying AI to real-world healthcare settings. It underscored the importance of robust validation, careful integration with existing systems, and clear communication about the capabilities and limitations of AI tools.\n\n\nRecent Successes and Ongoing Challenges\nDespite setbacks, the field has seen significant progress in recent years. Some notable successes include:\n\nMedical Imaging: AI systems have shown remarkable accuracy in analyzing medical images. For example, in 2018, a deep learning algorithm developed by Google achieved better performance than human radiologists in detecting breast cancer in mammograms.\nDrug Discovery: AI is accelerating the drug discovery process. In 2020, an AI system developed by DeepMind, AlphaFold, made a major breakthrough in predicting protein structures, a critical step in understanding diseases and developing new treatments.\nPersonalized Medicine: Machine learning algorithms are being used to analyze genetic data and predict patient responses to treatments, paving the way for more personalized medical care.\nPredictive Analytics: AI models are being employed to predict patient outcomes, identify individuals at high risk of certain conditions, and optimize hospital operations.\n\nHowever, challenges remain. These include:\n\nData Quality and Bias: The performance of AI systems is heavily dependent on the quality and representativeness of the data they’re trained on. Biases in training data can lead to biased outcomes, potentially exacerbating health disparities.\nInterpretability: Many advanced AI models, particularly deep learning models, operate as “black boxes,” making it difficult to understand how they arrive at their conclusions. This lack of interpretability can be problematic in healthcare, where understanding the reasoning behind decisions is crucial.\nIntegration and Workflow: Successfully integrating AI tools into clinical workflows remains a challenge. Tools that disrupt rather than enhance existing workflows are unlikely to be adopted.\nRegulatory Challenges: As AI systems become more complex and autonomous, regulators are grappling with how to ensure their safety and efficacy.\nEthical Considerations: The use of AI in healthcare raises numerous ethical questions, from data privacy and consent to the potential for AI to influence life-and-death decisions.\n\n\n\nLooking Ahead\nThe application of AI in healthcare remains a rapidly evolving field with enormous potential. While early setbacks have tempered some of the initial hype, they have also led to more realistic expectations and a greater focus on rigorous validation and real-world applicability.\nMoving forward, successful implementation of AI in healthcare will likely require close collaboration between AI researchers, healthcare professionals, and domain experts. It will also necessitate ongoing dialogue about the ethical implications of these technologies and the development of robust governance frameworks.\nAs AI continues to advance, it has the potential to significantly improve healthcare outcomes, increase efficiency, and make high-quality care more accessible. However, realizing this potential will require navigating complex technical, clinical, and ethical challenges. The history of AI in healthcare serves as a reminder of both the field’s promise and the importance of a measured, evidence-based approach to its development and deployment."
  },
  {
    "objectID": "book/history-of-ai.html#looking-to-the-future",
    "href": "book/history-of-ai.html#looking-to-the-future",
    "title": "The Evolution of Artificial Intelligence",
    "section": "Looking to the Future",
    "text": "Looking to the Future\nAs we look to the future of AI, several exciting directions are emerging. Research into Artificial General Intelligence (AGI) continues, with the goal of creating AI systems that can match or exceed human-level intelligence across a wide range of tasks. The integration of AI with quantum computing holds the promise of solving complex problems at unprecedented speeds. Neuromorphic computing, which aims to mimic the structure and function of the human brain, offers potential for more efficient and adaptable AI systems.\nHowever, as AI capabilities continue to advance, we face significant challenges and responsibilities. Ensuring the ethical development of AI, addressing issues of bias and fairness, and developing appropriate governance and regulatory frameworks are crucial tasks. Balancing the drive for innovation with responsible development practices will be key to realizing the full potential of AI while mitigating potential risks.\nThe history of AI is a testament to human ingenuity and perseverance. From its theoretical beginnings to its current state as a transformative technology, AI has come a long way. As we continue to push the boundaries of what’s possible, the lessons from this rich history will guide us in creating AI systems that are not only powerful and capable but also aligned with human values and beneficial to society as a whole."
  },
  {
    "objectID": "book/ml-overview.html",
    "href": "book/ml-overview.html",
    "title": "Overview of Machine Learning in Medicine",
    "section": "",
    "text": "Machine learning (ML) has emerged as a transformative tool in modern medicine, reshaping how we approach diagnosis, treatment, and the management of complex health data. As medical professionals, understanding the foundational concepts and applications of ML is increasingly critical to improving patient care, optimizing operational efficiency, and driving innovative medical research.\nThis section introduces you to the key principles of machine learning, focusing on its practical applications in healthcare. From the basics of supervised and unsupervised learning to the more advanced techniques of deep learning, we will explore how these tools are used to solve real-world medical problems. This overview aims to give you the knowledge required to critically evaluate ML models and their impact on clinical practice."
  },
  {
    "objectID": "book/ml-overview.html#introduction",
    "href": "book/ml-overview.html#introduction",
    "title": "Overview of Machine Learning in Medicine",
    "section": "",
    "text": "Machine learning (ML) has emerged as a transformative tool in modern medicine, reshaping how we approach diagnosis, treatment, and the management of complex health data. As medical professionals, understanding the foundational concepts and applications of ML is increasingly critical to improving patient care, optimizing operational efficiency, and driving innovative medical research.\nThis section introduces you to the key principles of machine learning, focusing on its practical applications in healthcare. From the basics of supervised and unsupervised learning to the more advanced techniques of deep learning, we will explore how these tools are used to solve real-world medical problems. This overview aims to give you the knowledge required to critically evaluate ML models and their impact on clinical practice."
  },
  {
    "objectID": "book/ml-overview.html#learning-objectives",
    "href": "book/ml-overview.html#learning-objectives",
    "title": "Overview of Machine Learning in Medicine",
    "section": "Learning Objectives",
    "text": "Learning Objectives\nBy the end of this section, you will be able to:\n\nDefine machine learning and its subtypes, including supervised, unsupervised, and deep learning.\nUnderstand how machine learning is applied to medical problems, such as diagnosis, prognosis, and personalized treatment.\nIdentify key concepts in model evaluation, such as accuracy, precision, recall, and the importance of balancing bias and variance.\nRecognize the challenges and limitations of using machine learning in medical contexts, including issues of interpretability, fairness, and ethical considerations."
  },
  {
    "objectID": "book/ml-overview.html#structure-of-the-section",
    "href": "book/ml-overview.html#structure-of-the-section",
    "title": "Overview of Machine Learning in Medicine",
    "section": "Structure of the Section",
    "text": "Structure of the Section\nThis section is divided into the following chapters, each focusing on different aspects of machine learning in medicine:\n\nChapter 1: Introduction to Machine Learning in Medicine\nHere, you will learn the fundamental concepts of machine learning, including how data-driven algorithms learn patterns from clinical data. We will discuss the various types of learning models and their relevance to different medical tasks.\n\n\nChapter 2: Supervised Learning\nThis chapter focuses on the most common type of machine learning—supervised learning. We will explore key algorithms like decision trees and support vector machines, and how they are applied in tasks like disease classification and predictive analytics.\n\n\nChapter 3: Unsupervised Learning\nUnsupervised learning techniques are essential for discovering hidden patterns in data. In this chapter, we will cover clustering and dimensionality reduction methods and their uses in medical research, such as patient stratification and exploratory analysis.\n\n\nChapter 4: Model Evaluation and Validation\nBuilding an accurate model is only half the challenge. In this chapter, we will delve into evaluating models using metrics such as sensitivity, specificity, and the importance of balancing precision and recall in clinical settings.\n\n\nChapter 5: Deep Learning in Medicine\nDeep learning has become especially useful in analyzing complex medical data, including medical images and genomic sequences. We will discuss the architecture of neural networks and their applications in healthcare.\n\n\nChapter 6: Challenges in Medical Machine Learning\nWhile machine learning holds great promise, it also comes with significant challenges. This final chapter addresses the limitations of current models, including issues of interpretability, fairness, and ethical implications in medical decision-making.\n\nThis overview sets the stage for a detailed exploration of machine learning techniques and their critical role in healthcare. Each chapter builds upon core principles to deepen your understanding of how machine learning can be leveraged to enhance medical practice and research.\n\nWould you like to adjust or expand on any part of this section overview?"
  }
]