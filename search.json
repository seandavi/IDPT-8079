[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Machine Learning and Arfificial Intelligence for Medical Professionals",
    "section": "",
    "text": "Preface\nThis is a Quarto book.\nTo learn more about Quarto books visit https://quarto.org/docs/books.",
    "crumbs": [
      "Preface"
    ]
  },
  {
    "objectID": "history-of-ai.html",
    "href": "history-of-ai.html",
    "title": "1  The Evolution of Artificial Intelligence",
    "section": "",
    "text": "1.1 The Dawn of Artificial Intelligence\nThe seeds of artificial intelligence were planted in the mid-20th century, with pioneering thinkers laying the groundwork for what would become a revolutionary field of study. In 1936, Alan Turing published his seminal paper on “Computable Numbers,” which introduced the concept of a universal machine capable of computing anything that is computable (Turing 1936). This theoretical framework would later become crucial in the development of modern computers and, by extension, artificial intelligence.\nBuilding on Turing’s work, Warren McCulloch and Walter Pitts made a significant contribution in 1943 by creating a computational model for neural networks (McCulloch and Pitts 1943). This early model, while simplistic by today’s standards, was a crucial step in understanding how the human brain processes information and how this process might be replicated in machines.\nThe year 1950 marked another pivotal moment when Alan Turing proposed what is now known as the Turing Test (Turing 1950). This test was designed to assess a machine’s ability to exhibit intelligent behavior indistinguishable from that of a human. The Turing Test sparked intense debate and research into the nature of intelligence and consciousness, issues that continue to be central to AI development and philosophy today.\nThe term “Artificial Intelligence” itself was coined in 1956 at the Dartmouth Conference, a gathering of prominent researchers who came together to discuss the possibility of creating machines that could think. This conference is widely regarded as the birth of AI as a formal field of study, setting the stage for decades of research and development to come.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>The Evolution of Artificial Intelligence</span>"
    ]
  },
  {
    "objectID": "history-of-ai.html#science-fiction-meets-reality",
    "href": "history-of-ai.html#science-fiction-meets-reality",
    "title": "1  The Evolution of Artificial Intelligence",
    "section": "1.2 Science Fiction Meets Reality",
    "text": "1.2 Science Fiction Meets Reality\nWhile scientists were laying the theoretical foundations for AI, science fiction writers were exploring its potential implications for society. One of the most influential works in this regard was Isaac Asimov’s “I, Robot,” published in 1950 (Asimov 2004). This collection of nine science fiction short stories introduced the concept of positronic robots and, more importantly, the Three Laws of Robotics.\nAsimov’s Three Laws of Robotics were:\n\nA robot may not injure a human being or, through inaction, allow a human being to come to harm.\nA robot must obey the orders given it by human beings except where such orders would conflict with the First Law.\nA robot must protect its own existence as long as such protection does not conflict with the First or Second Laws.\n\nLater, Asimov added a “Zeroth Law” that superseded the others: A robot may not harm humanity, or, by inaction, allow humanity to come to harm.\nWhile these laws were created for fictional stories, they have had a profound impact on real-world AI development. Asimov’s work sparked crucial discussions about machine ethics and AI safety, influencing researchers to consider the ethical implications of their work. The concept of “friendly AI” draws clear parallels to Asimov’s laws, and many of the challenges presented in his stories mirror real-world AI alignment problems that researchers grapple with today.\nIn a darker, more mainstream vein, Stanley Kubrick’s 1968 film “2001: A Space Odyssey,” developed in parallel with Arthur C. Clarke, introduced the world to HAL 9000, a sentient AI system that goes rogue and poses a threat to the human crew of the spaceship Discovery One (Clarke and Kubrick 1968). HAL’s chilling portrayal as a seemingly benevolent but ultimately malevolent AI system raised important questions about the risks and ethical considerations of creating intelligent machines.\nAs we continue to develop increasingly sophisticated AI systems, we can draw valuable lessons from these fictional works, reminding us of the importance of ethical design, human-AI collaboration, and the potential consequences of unchecked technological advancement. Much of our understanding of how AI should be developed and deployed has been shaped by these early explorations of AI in science fiction.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>The Evolution of Artificial Intelligence</span>"
    ]
  },
  {
    "objectID": "history-of-ai.html#the-golden-years-and-early-milestones",
    "href": "history-of-ai.html#the-golden-years-and-early-milestones",
    "title": "1  The Evolution of Artificial Intelligence",
    "section": "1.3 The Golden Years and Early Milestones",
    "text": "1.3 The Golden Years and Early Milestones\nThe period from 1956 to 1974 is often referred to as the “Golden Years” of AI research. During this time, there was great optimism about the potential of AI, and several significant developments took place. In 1957, Frank Rosenblatt developed the Perceptron, an early type of neural network that could learn to recognize simple patterns. This was a major step forward in machine learning, demonstrating that computers could be trained to perform tasks rather than simply following pre-programmed instructions.\nOne of the most notable achievements of this era was the creation of ELIZA in 1964 by Joseph Weizenbaum. ELIZA was one of the first chatbots, designed to simulate a conversation between a human and a machine as shown in Figure 1.1. ELIZA’s creator, Weizenbaum, intended the program as a method to explore communication between humans and machines. He was surprised and shocked that some people, including Weizenbaum’s secretary, attributed human-like feelings to the computer program. While its capabilities were limited by today’s standards, ELIZA was remarkably effective at creating the illusion of understanding. The program used pattern matching and substitution methodology to engage in conversation, often in the role of a Rogerian psychotherapist.\n\n\n\n\n\n\n\n\nFigure 1.1: An example conversation with ELIZA.\n\n\n\nELIZA would take users’ input and reflect their statements back to them in a way that encouraged further conversation. For example, if a user said, “I’m feeling sad today,” ELIZA might respond with, “Why do you think you’re feeling sad today?” This simple but effective approach to natural language processing was groundbreaking for its time.\nWhat was particularly fascinating about ELIZA was how quickly people became emotionally attached to the program, even when they knew it wasn’t genuinely intelligent. This phenomenon highlighted the potential for AI to engage with humans on an emotional level, a concept that continues to be explored and refined in modern AI development.\nWhile ELIZA’s responses were largely superficial, the program marked an important milestone in the development of AI and human-computer interaction. It demonstrated how conversation-based interfaces could influence the perception of intelligence and paved the way for more sophisticated natural language processing systems in the future.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>The Evolution of Artificial Intelligence</span>"
    ]
  },
  {
    "objectID": "history-of-ai.html#the-rise-of-expert-systems",
    "href": "history-of-ai.html#the-rise-of-expert-systems",
    "title": "1  The Evolution of Artificial Intelligence",
    "section": "1.4 The Rise of Expert Systems",
    "text": "1.4 The Rise of Expert Systems\nAs AI research progressed, a new paradigm emerged in the 1970s and 1980s: expert systems. These were computer programs designed to emulate the decision-making ability of a human expert in a specific domain. Expert systems represented a shift from general problem-solving approaches to more focused, knowledge-intensive methods.\nAn expert system typically consists of three key components:\n\nA Knowledge Base: This contains domain-specific information and rules, essentially capturing the expertise of human specialists in a particular field.\nAn Inference Engine: This applies the rules in the knowledge base to derive new information or make decisions.\nA User Interface: This allows non-expert users to interact with the system, input data, and receive outputs.\n\nOne of the most famous expert systems was MYCIN, developed in the early 1970s at Stanford University. MYCIN was designed to assist physicians in diagnosing and treating bacterial infections, particularly bloodstream infections like bacteremia and meningitis. The system contained approximately 600 rules and used a backward chaining inference engine to arrive at diagnoses and treatment recommendations.\nMYCIN was groundbreaking in several ways. It incorporated certainty factors to handle uncertainty, a crucial feature in medical diagnosis where symptoms and test results are not always definitive. The system could also explain its reasoning process to users, enhancing transparency and trust. Perhaps most impressively, MYCIN achieved performance comparable to human experts in its domain.\nDespite its capabilities, MYCIN was never used in clinical practice due to ethical and legal concerns. However, its impact on AI research was significant. MYCIN pioneered several important concepts in AI and expert systems, including the separation of the knowledge base from the inference engine, the ability to explain reasoning, and methods for handling uncertainty. These principles influenced the development of subsequent expert systems and laid the groundwork for modern clinical decision support tools.\nThe era of expert systems demonstrated the potential of AI in specialized domains and highlighted the importance of capturing and utilizing expert knowledge. While these systems had limitations, such as difficulty in capturing tacit knowledge and struggles with unusual situations, they represented a significant step forward in practical AI applications.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>The Evolution of Artificial Intelligence</span>"
    ]
  },
  {
    "objectID": "history-of-ai.html#challenges-and-the-ai-winter",
    "href": "history-of-ai.html#challenges-and-the-ai-winter",
    "title": "1  The Evolution of Artificial Intelligence",
    "section": "1.5 Challenges and the AI Winter",
    "text": "1.5 Challenges and the AI Winter\nDespite the initial enthusiasm and progress, the field of AI faced significant challenges in the mid-1970s and again in the late 1980s. These periods, known as “AI Winters,” were characterized by reduced funding and interest in AI research.\nThe first AI Winter (1974-1980) came about largely due to overpromising and underdelivering. Early AI researchers, buoyed by initial successes, made ambitious predictions about the capabilities of AI systems that failed to materialize in the expected timeframes. This led to skepticism among funders and policy-makers, resulting in cutbacks in AI research funding.\nThe second AI Winter (1987-1993) was triggered by the collapse of the market for specialized AI hardware. Many companies had invested heavily in developing specialized computers for AI applications, particularly for running expert systems. However, as general-purpose computers became more powerful and cost-effective, the market for these specialized machines dried up, leading to financial losses and another period of reduced investment in AI.\nThese challenging periods forced the AI community to reassess its goals and methods. Researchers shifted their focus towards more practical, focused applications of AI technology. This pragmatic approach would eventually lead to a revival of the field and set the stage for the machine learning revolution of the 1990s and beyond.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>The Evolution of Artificial Intelligence</span>"
    ]
  },
  {
    "objectID": "history-of-ai.html#the-machine-learning-renaissance",
    "href": "history-of-ai.html#the-machine-learning-renaissance",
    "title": "1  The Evolution of Artificial Intelligence",
    "section": "1.6 The Machine Learning Renaissance",
    "text": "1.6 The Machine Learning Renaissance\nThe 1990s marked a significant shift in AI research towards data-driven approaches, particularly in the field of machine learning. This shift was driven by several factors, including increased computational power, the growing availability of large datasets, and advances in statistical methods.\nOne of the most visible successes of this era was IBM’s Deep Blue, a chess-playing computer that defeated world champion Garry Kasparov in 1997. This achievement captured the public imagination and demonstrated the potential of AI in mastering complex strategic tasks.\nThe focus on machine learning led to renewed interest in neural networks and other statistical methods. Researchers began developing more sophisticated algorithms capable of learning from data, paving the way for breakthroughs in areas such as computer vision, speech recognition, and natural language processing.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>The Evolution of Artificial Intelligence</span>"
    ]
  },
  {
    "objectID": "history-of-ai.html#the-modern-era-big-data-and-deep-learning",
    "href": "history-of-ai.html#the-modern-era-big-data-and-deep-learning",
    "title": "1  The Evolution of Artificial Intelligence",
    "section": "1.7 The Modern Era: Big Data and Deep Learning",
    "text": "1.7 The Modern Era: Big Data and Deep Learning\nThe 2000s and 2010s saw exponential growth in AI capabilities, driven by the confluence of big data, increased computational power, and advances in deep learning algorithms. This period has been marked by a series of breakthroughs that have transformed AI from a primarily academic pursuit to a technology with wide-ranging practical applications.\nIn 2006, Geoffrey Hinton and his team introduced “deep belief networks,” marking the resurgence of deep learning. This work laid the foundation for modern AI applications, especially in image and speech recognition. The power of these techniques was dramatically demonstrated in 2012 when a deep neural network called AlexNet won the ImageNet competition, significantly outperforming traditional computer vision methods.\nThe development of more sophisticated AI systems led to high-profile achievements such as IBM Watson’s victory on the quiz show Jeopardy! in 2011. This demonstrated AI’s ability to process and understand natural language, leading to applications in healthcare, finance, and customer service. However, the subsequent challenges faced by Watson in real-world applications, such as its setbacks at MD Anderson Cancer Center, highlighted the complexity of applying AI to domains like healthcare.\nIn 2014, Ian Goodfellow introduced Generative Adversarial Networks (GANs), a novel approach where two neural networks compete to generate realistic data. This innovation has revolutionized image generation and unsupervised learning, powering advancements in AI-generated art and deepfake technology.\nThe field of AI continued to push boundaries with achievements like Google DeepMind’s AlphaGo defeating world champion Go player Lee Sedol in 2016. This milestone showcased the power of combining deep learning with reinforcement learning techniques.\nA major breakthrough came in 2017 with the introduction of the Transformer architecture by Vaswani et al. This innovation laid the groundwork for state-of-the-art natural language processing models like BERT and GPT, transforming our ability to understand and generate human language.\nRecent years have seen AI making significant contributions to scientific research, as exemplified by DeepMind’s AlphaFold solving the long-standing challenge of protein structure prediction in 2020. This breakthrough has opened new doors in drug discovery and molecular biology.\nThe development of large language models, culminating in systems like GPT-4 in 2023, has showcased the potential of AI for complex, nuanced language understanding and generation. These models have accelerated the development of AI-driven content creation and enhanced human-computer interaction, while also raising important questions about the nature of machine intelligence and the ethical implications of increasingly capable AI systems.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>The Evolution of Artificial Intelligence</span>"
    ]
  },
  {
    "objectID": "history-of-ai.html#ai-and-machine-learning-in-healthcare-promises-and-pitfalls",
    "href": "history-of-ai.html#ai-and-machine-learning-in-healthcare-promises-and-pitfalls",
    "title": "1  The Evolution of Artificial Intelligence",
    "section": "1.8 AI and Machine Learning in Healthcare: Promises and Pitfalls",
    "text": "1.8 AI and Machine Learning in Healthcare: Promises and Pitfalls\nThe application of AI and Machine Learning in healthcare has been one of the most promising and closely watched areas of development in recent years. From diagnosis and treatment planning to drug discovery and personalized medicine, AI has shown potential to revolutionize various aspects of healthcare. However, this journey has been marked by both significant triumphs and notable setbacks, illustrating the complexities of applying AI to this critical domain.\n\n1.8.1 Early Applications and Promise\nThe use of AI in healthcare dates back to the expert systems era of the 1970s. One of the earliest and most famous examples was MYCIN, developed at Stanford University in 1972. MYCIN was designed to identify bacteria causing severe infections and recommend antibiotics. Although it performed at a level comparable to human experts, it was never used in clinical practice due to ethical and legal concerns. Nevertheless, MYCIN laid important groundwork for future clinical decision support systems.\nIn the 1990s and 2000s, as machine learning techniques advanced, new applications in healthcare began to emerge. These included systems for analyzing medical images, predicting patient outcomes, and identifying patterns in electronic health records. For instance, computer-aided detection (CAD) systems for mammography, developed in the 1990s, became widely adopted to assist radiologists in identifying potential breast cancers.\n\n\n1.8.2 The Watson Era: High Hopes and Hard Lessons\nOne of the most high-profile attempts to bring AI to healthcare was IBM’s Watson. Following its triumph on the quiz show Jeopardy! in 2011, IBM positioned Watson as a revolutionary tool for healthcare, particularly in oncology. The vision was to use Watson’s natural language processing and machine learning capabilities to analyze vast amounts of medical literature and patient data, providing clinicians with evidence-based treatment recommendations.\nIn 2013, IBM announced a collaboration with MD Anderson Cancer Center to use Watson in cancer care. The project, known as Oncology Expert Advisor, aimed to create a clinical decision support system for leukemia treatment. However, by 2017, the project had been put on hold after years of development and millions of dollars spent (Swetlitz 2017).\nThe challenges faced by Watson at MD Anderson highlighted several key issues:\n\nData Integration: Integrating Watson with the hospital’s electronic health records proved more difficult than anticipated.\nCustomization: The system required extensive customization to align with MD Anderson’s specific protocols and practices.\nValidation: There were concerns about the accuracy and reliability of Watson’s recommendations.\nCost: The project’s costs significantly exceeded initial estimates.\n\nThis setback was a sobering reminder of the complexities involved in applying AI to real-world healthcare settings. It underscored the importance of robust validation, careful integration with existing systems, and clear communication about the capabilities and limitations of AI tools.\n\n\n1.8.3 Recent Successes and Ongoing Challenges\nDespite setbacks, the field has seen significant progress in recent years. Some notable successes include:\n\nMedical Imaging: AI systems have shown remarkable accuracy in analyzing medical images. For example, in 2018, a deep learning algorithm developed by Google achieved better performance than human radiologists in detecting breast cancer in mammograms.\nDrug Discovery: AI is accelerating the drug discovery process. In 2020, an AI system developed by DeepMind, AlphaFold, made a major breakthrough in predicting protein structures, a critical step in understanding diseases and developing new treatments.\nPersonalized Medicine: Machine learning algorithms are being used to analyze genetic data and predict patient responses to treatments, paving the way for more personalized medical care.\nPredictive Analytics: AI models are being employed to predict patient outcomes, identify individuals at high risk of certain conditions, and optimize hospital operations.\n\nHowever, challenges remain. These include:\n\nData Quality and Bias: The performance of AI systems is heavily dependent on the quality and representativeness of the data they’re trained on. Biases in training data can lead to biased outcomes, potentially exacerbating health disparities.\nInterpretability: Many advanced AI models, particularly deep learning models, operate as “black boxes,” making it difficult to understand how they arrive at their conclusions. This lack of interpretability can be problematic in healthcare, where understanding the reasoning behind decisions is crucial.\nIntegration and Workflow: Successfully integrating AI tools into clinical workflows remains a challenge. Tools that disrupt rather than enhance existing workflows are unlikely to be adopted.\nRegulatory Challenges: As AI systems become more complex and autonomous, regulators are grappling with how to ensure their safety and efficacy.\nEthical Considerations: The use of AI in healthcare raises numerous ethical questions, from data privacy and consent to the potential for AI to influence life-and-death decisions.\n\n\n\n1.8.4 Looking Ahead\nThe application of AI in healthcare remains a rapidly evolving field with enormous potential. While early setbacks have tempered some of the initial hype, they have also led to more realistic expectations and a greater focus on rigorous validation and real-world applicability.\nMoving forward, successful implementation of AI in healthcare will likely require close collaboration between AI researchers, healthcare professionals, and domain experts. It will also necessitate ongoing dialogue about the ethical implications of these technologies and the development of robust governance frameworks.\nAs AI continues to advance, it has the potential to significantly improve healthcare outcomes, increase efficiency, and make high-quality care more accessible. However, realizing this potential will require navigating complex technical, clinical, and ethical challenges. The history of AI in healthcare serves as a reminder of both the field’s promise and the importance of a measured, evidence-based approach to its development and deployment.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>The Evolution of Artificial Intelligence</span>"
    ]
  },
  {
    "objectID": "history-of-ai.html#looking-to-the-future",
    "href": "history-of-ai.html#looking-to-the-future",
    "title": "1  The Evolution of Artificial Intelligence",
    "section": "1.9 Looking to the Future",
    "text": "1.9 Looking to the Future\nAs we look to the future of AI, several exciting directions are emerging. Research into Artificial General Intelligence (AGI) continues, with the goal of creating AI systems that can match or exceed human-level intelligence across a wide range of tasks. The integration of AI with quantum computing holds the promise of solving complex problems at unprecedented speeds. Neuromorphic computing, which aims to mimic the structure and function of the human brain, offers potential for more efficient and adaptable AI systems.\nHowever, as AI capabilities continue to advance, we face significant challenges and responsibilities. Ensuring the ethical development of AI, addressing issues of bias and fairness, and developing appropriate governance and regulatory frameworks are crucial tasks. Balancing the drive for innovation with responsible development practices will be key to realizing the full potential of AI while mitigating potential risks.\nThe history of AI is a testament to human ingenuity and perseverance. From its theoretical beginnings to its current state as a transformative technology, AI has come a long way. As we continue to push the boundaries of what’s possible, the lessons from this rich history will guide us in creating AI systems that are not only powerful and capable but also aligned with human values and beneficial to society as a whole.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>The Evolution of Artificial Intelligence</span>"
    ]
  },
  {
    "objectID": "history-of-ai.html#references",
    "href": "history-of-ai.html#references",
    "title": "1  The Evolution of Artificial Intelligence",
    "section": "References",
    "text": "References\n\n\n\n\nAsimov, Isaac. 2004. I, Robot. Bantam hardcover ed. (2). New York: Bantam Books.\n\n\nClarke, Arthur C., and Stanley Kubrick. 1968. 2001: A Space Odyssey. London: Hutchinson.\n\n\nMcCulloch, Warren S., and Walter Pitts. 1943. “A Logical Calculus of the Ideas Immanent in Nervous Activity.” The Bulletin of Mathematical Biophysics 5 (4): 115–33. https://doi.org/10.1007/BF02478259.\n\n\nSwetlitz, Casey Ross, Ike. 2017. “IBM Pitched Its Watson Supercomputer as a Revolution in Cancer Care. It’s Nowhere Close.” STAT. https://www.statnews.com/2017/09/05/watson-ibm-cancer/.\n\n\nTuring, Alan. 1936. “On Computable Numbers, with an Application to the Entscheidungsproblem.” https://www.abelard.org/turpap2/tp2-ie.asp.\n\n\n———. 1950. “Computing Machinery and Intelligence.” Mind 59 (October): 433–60. https://doi.org/10.1093/mind/lix.236.433.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>The Evolution of Artificial Intelligence</span>"
    ]
  },
  {
    "objectID": "ml-overview.html",
    "href": "ml-overview.html",
    "title": "Overview of Machine Learning in Medicine",
    "section": "",
    "text": "Introduction\nMachine learning (ML) has emerged as a transformative tool in modern medicine, reshaping how we approach diagnosis, treatment, and the management of complex health data. As medical professionals, understanding the foundational concepts and applications of ML is increasingly critical to improving patient care, optimizing operational efficiency, and driving innovative medical research.\nThis section introduces you to the key principles of machine learning, focusing on its practical applications in healthcare. From the basics of supervised and unsupervised learning to the more advanced techniques of deep learning, we will explore how these tools are used to solve real-world medical problems. This overview aims to give you the knowledge required to critically evaluate ML models and their impact on clinical practice.",
    "crumbs": [
      "Overview of Machine Learning in Medicine"
    ]
  },
  {
    "objectID": "ml-overview.html#learning-objectives",
    "href": "ml-overview.html#learning-objectives",
    "title": "Overview of Machine Learning in Medicine",
    "section": "Learning Objectives",
    "text": "Learning Objectives\nBy the end of this section, you will be able to:\n\nDefine machine learning and its subtypes, including supervised, unsupervised, and deep learning.\nUnderstand how machine learning is applied to medical problems, such as diagnosis, prognosis, and personalized treatment.\nIdentify key concepts in model evaluation, such as accuracy, precision, recall, and the importance of balancing bias and variance.\nRecognize the challenges and limitations of using machine learning in medical contexts, including issues of interpretability, fairness, and ethical considerations.",
    "crumbs": [
      "Overview of Machine Learning in Medicine"
    ]
  },
  {
    "objectID": "ml-overview.html#structure-of-the-section",
    "href": "ml-overview.html#structure-of-the-section",
    "title": "Overview of Machine Learning in Medicine",
    "section": "Structure of the Section",
    "text": "Structure of the Section\nThis section is divided into the following chapters, each focusing on different aspects of machine learning in medicine:\n\nChapter 1: Introduction to Machine Learning in Medicine\nHere, you will learn the fundamental concepts of machine learning, including how data-driven algorithms learn patterns from clinical data. We will discuss the various types of learning models and their relevance to different medical tasks.\n\n\nChapter 2: Supervised Learning\nThis chapter focuses on the most common type of machine learning—supervised learning. We will explore key algorithms like decision trees and support vector machines, and how they are applied in tasks like disease classification and predictive analytics.\n\n\nChapter 3: Unsupervised Learning\nUnsupervised learning techniques are essential for discovering hidden patterns in data. In this chapter, we will cover clustering and dimensionality reduction methods and their uses in medical research, such as patient stratification and exploratory analysis.\n\n\nChapter 4: Model Evaluation and Validation\nBuilding an accurate model is only half the challenge. In this chapter, we will delve into evaluating models using metrics such as sensitivity, specificity, and the importance of balancing precision and recall in clinical settings.\n\n\nChapter 5: Deep Learning in Medicine\nDeep learning has become especially useful in analyzing complex medical data, including medical images and genomic sequences. We will discuss the architecture of neural networks and their applications in healthcare.\n\n\nChapter 6: Challenges in Medical Machine Learning\nWhile machine learning holds great promise, it also comes with significant challenges. This final chapter addresses the limitations of current models, including issues of interpretability, fairness, and ethical implications in medical decision-making.\n\nThis overview sets the stage for a detailed exploration of machine learning techniques and their critical role in healthcare. Each chapter builds upon core principles to deepen your understanding of how machine learning can be leveraged to enhance medical practice and research.\n\nWould you like to adjust or expand on any part of this section overview?",
    "crumbs": [
      "Overview of Machine Learning in Medicine"
    ]
  },
  {
    "objectID": "nlp-section/word-embeddings.html",
    "href": "nlp-section/word-embeddings.html",
    "title": "3  Word Embeddings and Representation in Text",
    "section": "",
    "text": "3.1 Embedding People: Analogies in Personality Dimensions\nThe HEXACO model of personality structure is a six-dimensional model of human personality that was created by Ashton and Lee and explained in their book, The H Factor of Personality,[1] based on findings from a series of lexical studies involving several European and Asian languages. The six factors, or dimensions, include honesty-humility (H), emotionality (E), extraversion (X), agreeableness (A), conscientiousness (C), and openness to experience (O). Each factor is composed of traits with characteristics indicating high and low levels of the factor. If you’ve ever taken a personality test, you might have encountered these dimensions.\nWe have three hypothetical colleagues, Jay, Kay, and May. Each has taken a personality test and received scores for two personality dimensions which we’ll call “Dimension 1” and “Dimension 2.” The scores are as shown Figure 3.1 depicted graphically in the top left. We can take these scores and represent them as vectors in a two-dimensional space, where each dimension corresponds to one of the personality dimensions as shown in the bottom of Figure 3.1. Using these vectors, we can visualize the relationships between Jay, Kay, and May in this two-dimensional space as shown on the right plot of Figure 3.1.\nThe idea of “embedding people” allows us to take abstract concepts like personality traits and represent them in a numerical space. This concept is extended to words in natural language processing, where we represent words as vectors in a high-dimensional space. These word embeddings capture the meaning and relationships between words, allowing us to perform various tasks like sentiment analysis, machine translation, and named entity recognition. Just like with Jay, Kay, and May, words that are similar in meaning are close together in this space.\nIn the case of personality traits the dimensions are derived from a psychological model, but in the case of word embeddings, the dimensions are learned from large text corpora using models like Word2Vec, GloVe, or fastText. These models learn to represent words in a way that captures their semantic and syntactic relationships based on the context they appear in.",
    "crumbs": [
      "Natural Language Processing",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Word Embeddings and Representation in Text</span>"
    ]
  },
  {
    "objectID": "nlp-section/word-embeddings.html#embedding-people-analogies-in-personality-dimensions",
    "href": "nlp-section/word-embeddings.html#embedding-people-analogies-in-personality-dimensions",
    "title": "3  Word Embeddings and Representation in Text",
    "section": "",
    "text": "Figure 3.1: Schematic of three hypothetical embeddings of people. Our embeddings are based on personality “dimensions” represented by two different scores (colored orange and blue).",
    "crumbs": [
      "Natural Language Processing",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Word Embeddings and Representation in Text</span>"
    ]
  },
  {
    "objectID": "nlp-section/word-embeddings.html#word-embeddings-capturing-semantic-relationships",
    "href": "nlp-section/word-embeddings.html#word-embeddings-capturing-semantic-relationships",
    "title": "3  Word Embeddings and Representation in Text",
    "section": "3.2 Word Embeddings: Capturing Semantic Relationships",
    "text": "3.2 Word Embeddings: Capturing Semantic Relationships\nText is one of the most abundant forms of data in healthcare, with sources ranging from electronic health records (EHRs) to published research articles, clinical notes, and even patient-reported outcomes. However, computers don’t understand words as humans do—they require numerical representations of text to analyze, model, and make predictions. The challenge is: how do we represent the meaning of words in a way that captures their context and relationships in a way that machines can understand?\nThis is where word embeddings come into play. Word embeddings provide a way to represent words as vectors (numerical arrays), capturing semantic relationships and making it possible to apply machine learning models to text. By converting text into embeddings, we open the door to a range of applications, from clinical text mining to predicting patient outcomes based on unstructured medical notes.\nThis chapter introduces word embeddings and explains how they allow us to map words into a vectors that encode semantic and syntactic meaning. We’ll cover why this is an improvement over older methods, how these embeddings are learned, and how they are used in medical applications.",
    "crumbs": [
      "Natural Language Processing",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Word Embeddings and Representation in Text</span>"
    ]
  },
  {
    "objectID": "nlp-section/word-embeddings.html#limitations-of-traditional-text-representations",
    "href": "nlp-section/word-embeddings.html#limitations-of-traditional-text-representations",
    "title": "3  Word Embeddings and Representation in Text",
    "section": "3.3 Limitations of Traditional Text Representations",
    "text": "3.3 Limitations of Traditional Text Representations\nBefore diving into embeddings, let’s briefly review older techniques for representing text. The simplest representations were based on bag-of-words (BoW) models and term frequency-inverse document frequency (TF-IDF) scores.\n\n3.3.1 Bag-of-Words and TF-IDF\n\nBag-of-words ignores the order of words and represents text based on word occurrences. For example, a clinical note with the text: “Patient experiences chest pain” would be represented simply as [\"patient\", \"experiences\", \"chest\", \"pain\"]. The model doesn’t understand that “chest” and “pain” are related, or that their combination is meaningful.\nTF-IDF refines this by weighing how frequently words appear in a document relative to how common they are across all documents. This addresses the fact that some words are very frequent and not informative, like “the” or “patient.”\n\n\n\n3.3.2 Limitations\n\nLack of Context: These methods do not capture word order or semantics. For example, in BoW, the words “chest pain” and “pain in the chest” would be represented the same.\nHigh Dimensionality: BoW and TF-IDF result in large sparse matrices, making it difficult to work with longer documents.\nNo Concept of Similarity: In these models, words like “doctor” and “physician” are treated as completely independent, despite their similar meanings.\n\nThis leads us to modern word embeddings, which solve many of these issues.",
    "crumbs": [
      "Natural Language Processing",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Word Embeddings and Representation in Text</span>"
    ]
  },
  {
    "objectID": "nlp-section/word-embeddings.html#what-are-word-embeddings",
    "href": "nlp-section/word-embeddings.html#what-are-word-embeddings",
    "title": "3  Word Embeddings and Representation in Text",
    "section": "3.4 What Are Word Embeddings?",
    "text": "3.4 What Are Word Embeddings?\nWord embeddings are dense, low-dimensional vector representations of words, where words with similar meanings have similar vector representations. The key idea is that these embeddings capture both the syntactic and semantic properties of words. The most popular models for learning embeddings include Word2Vec (Mikolov et al. 2013), GloVe (Pennington, Socher, and Manning 2014), and fastText (Bojanowski et al. 2017).\n\n\n\n\n\n\nFigure 3.2: Linear combinations of dimensions in vector space correlate with the semantic and syntactic roles of the words in the corpus[^1]. For illustration purposes, dimension d1 in the figure has a high positive correlation with living beings. A properly tuned word embedding model will map words with similar semantic or syntactic roles to adjacent regions in vector space. This property can be visualized through dimensionality reduction techniques such as t-SNE or PCA. Cultural concepts are also apparent in vector space as consistent offsets between vector representations of words sharing a particular relationship. For instance, in the bottom right of the figure, the dotted vector represents a gender regularity that goes from masculinity to femininity.\n\n\n\nFigure 3.2 effectively demonstrates how word embeddings capture the meaning and relationships between words in a numerical space, and how this can be visualized after reducing the dimensionality. Let’s break down each part of the figure to build intuition.\nIn the left section of the figure, you see word embeddings for seven different words: “dog,” “puppy,” “cat,” “houses,” “man,” “woman,” “king,” and “queen.” Each word is represented as a vector in a seven-dimensional space (d1 to d7), where each number in the row corresponds to a particular dimension in this space.\nFor example: - “dog” is represented as the vector [0.6, 0.9, 0.1, 0.4, -0.7, -0.3, -0.2] - “cat” is represented as [0.7, -0.1, 0.4, 0.3, -0.4, -0.1, -0.3]\nThese vectors encode the meaning of the words, capturing their relationships to other words in the vocabulary based on the corpus they were trained on.\n\n3.4.1 Word embeddings are numerical representations of words\nEach word is represented as a dense vector of real numbers. The dimensions (d1 to d7) don’t have a simple interpretable meaning like “animal” or “emotion,” but the relationships between the vectors capture such nuances. 1. Similarity and Relationship: Words that are semantically similar or related (like “dog” and “puppy”) tend to have similar vectors, meaning that in seven-dimensional space, they are near each other. We’ll see how this manifests in the visualization on the right.\nThe right side of Figure 3.2 shows what happens when we reduce the dimensionality of these word embeddings from 7D to 2D (for visualization). Dimensionality reduction techniques like Principal Component Analysis (PCA) or t-SNE are often used to reduce the complexity of the data while retaining its most important features. Here, reducing from 7 dimensions to 2 allows us to visualize the relationships between the words in 2D space. Note that the actual embeddings are learned in much higher dimensions (e.g., 100 to 300) and that the 2D projection is for visualization purposes only.\nIn the top-right plot of Figure 3.2, we see the 2D embeddings for “dog,” “puppy,” “cat,” and “houses.”\n“Dog” and “puppy” are close together in the embedding space, reflecting their semantic similarity. Both refer to canines, with “puppy” being a younger dog. This proximity in vector space is a hallmark of how embeddings capture semantic similarity. - “Cat” is a bit further away, as it represents a different animal, but it is still in proximity, highlighting some shared characteristics between cats and dogs (both are pets/animals). - “Houses” is far from all the animal-related words. This makes sense because “houses” is a completely different concept (object vs. animal). The fact that it’s distant in the embedding space highlights that the embeddings successfully differentiate unrelated terms.\nFigure 3.2 is a simplified example, but it captures the essence of how word embeddings work and how they can be visualized in lower dimensions to reveal relationships between words.\n\n\n3.4.2 Real world example: King-Queen Analogy\nIn Figure 3.3, we see a classic example of how word embeddings capture relationships between words. The figure shows the embeddings a number of words, including “king,” “queen,” “man,” and “woman” in 2D space. The axes have been adjusted to highlight the relationships between these words so that the y-axis represents the woman–queen axis representing a sense of royalty. The x-axis, aligned with the he–she axis represents a gender dimension.\n\n\n\n\n\n\nFigure 3.3: GloVE embeddings are the inputs to this 2D plot. The words/points are placed based on their location along the queen–woman or royalty axis and the he–she or gender axis in the GloVE space.\n\n\n\nAn amazing property of word embeddings is that they can capture analogies like “King is to Queen” as “Man is to woman.” This is known as the king-queen analogy and is a classic example of how embeddings can encode relationships between words. To use embeddings to solve this analogy, we can perform vector arithmetic. In this case, the vector operation we could use is given in Equation 3.1.\n\\[\\text{vector(\"king\")} - \\text{vector(\"man\")} + \\text{vector(\"woman\")} \\approx \\text{vector(\"queen\")} \\tag{3.1}\\]\nHere are a few ways of thinking about Equation 3.1.\nThis figure illustrates word embeddings in a 2D space, where the x-axis represents the spectrum from “he” to “she” and the y-axis represents the spectrum from “woman” to “queen”. The famous analogy “king - man + woman = queen” can be intuitively explained using this geometric representation:\nVector representation:\n\nIn this space, each word is represented as a 2D vector. The position of each word encodes semantic information about gender and royalty/status.\n“king - man”: This subtraction shifts the vector from “king” in the direction opposite to “man”. Geometrically, it moves the point left and slightly down, removing the “maleness” from “king”.\n“+ woman”: Adding “woman” shifts the resulting vector right and down, adding “femaleness”.\nResult ≈ queen: The final position after these operations ends up very close to “queen”.\n\nGeometric interpretation:\n\nSubtraction (king - man): Imagine drawing a vector from “man” to “king”. This represents the concept of “royalty” independent of gender.\nAddition (+ woman): Now apply this “royalty” vector starting from “woman”. It brings you to a point very close to “queen”.\n\nSemantic relationships:\n\n“king” is to “man” as “queen” is to “woman”\nThe difference between “king” and “man” (royalty) is similar to the difference between “queen” and “woman”\n“king” and “queen” are at similar heights (y-values), representing similar levels of royalty/status.\n“man” and “woman” are at similar heights, but lower than king/queen.\nThe gender axis (x-axis) separates male and female terms consistently while the royalty axis (y-axis) separates royal titles from less “regal” terms.",
    "crumbs": [
      "Natural Language Processing",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Word Embeddings and Representation in Text</span>"
    ]
  },
  {
    "objectID": "nlp-section/word-embeddings.html#where-do-word-embeddings-come-from",
    "href": "nlp-section/word-embeddings.html#where-do-word-embeddings-come-from",
    "title": "3  Word Embeddings and Representation in Text",
    "section": "3.5 Where do Word Embeddings Come From?",
    "text": "3.5 Where do Word Embeddings Come From?\nWord embeddings are learned from large text corpora using models like Word2Vec, GloVe, or fastText. These models are trained to predict words based on their context in the text, capturing the relationships between words in the process.\nThe word2vec model, developed by Mikolov et al., is one of the most popular methods for learning word embeddings. It comes in two flavors: Continuous Bag of Words (CBOW) and Skip-gram. The skip-gram model is particularly effective at capturing semantic relationships between words. It learns to predict the context words given a target word, effectively learning the embeddings that encode these relationships. Figure 3.4 illustrates how the skip-gram approach applies to a sentence. The model learns to predict the surrounding words given the current word, capturing the context in which words appear.\n\n\n\n\n\n\n\n\nFigure 3.4: Learning word embeddings using the skip-gram model. Figure from 1\n\n1 https://www.tensorflow.org/tutorials/text/word2vec\n\nThe word2vec architecture consists of a single hidden layer neural network with a softmax output layer. The input to the model is a one-hot encoded vector representing the target word, and the output is a probability distribution over the vocabulary. The model is trained using backpropagation to minimize the loss between the predicted and actual context words. This process results in word embeddings that capture the semantic relationships between words. Figure 3.5 illustrates how the skip-gram model is trained using backpropagation.\n\n\n\n\n\n\nNote\n\n\n\nOne-hot encoding is a way of representing words as binary vectors, where each word is represented by a vector with a 1 in the position corresponding to the word’s index in the vocabulary and 0s elsewhere. For example, in a “vocabulary” of the six words [“cat”, “hat”, “the”, “in”, “green”, “eggs”], the word “cat” might be represented as [0, 0, 1, 0, 0, 0] and “green” as [0, 0, 0, 1, 0, 0]. Thus, when we want to provide input to our word embedder for training, we supply the first vector for “cat” and for “green” we use the second, and so on. In reality, our “vocabulary” would be much larger, but this is the basic idea.\nWhen a vector consists of mostly zeros, like our one-hot encoding vectors, they are referred to as “sparse.” Word embeddings provide a “dense” representation word embedding vectors do not generally contain zeros. The dense vector for each word is in a lower-dimensional space (typically 100-500 dimensions), capturing semantic relationships more effectively. Another way of thinking of word embeddings is as a “lookup table” that maps the words in the one-hot encoding to continuous vectors.\n\n\n\n\n\n\n\n\n\n\n\n\n\n(a) Model incorrectly predicts neighboring words.\n\n\n\n\n\n\n\n\n\n\n\n\n\n(b) Model has “learned” new weights and now correctly predicts neighboring words.\n\n\n\n\n\n\n\nFigure 3.5: The skip-gram model is trained using backpropagation to minimize the loss between the predicted and actual context words. The diagram illustrates the training process. The goal is to learn weights such that the model can predict correctly that the word “the” comes before “wide” and is followed by the word “road.” Figure 3.5 (a) demonstrates that the model has made a mistake; we can see that because the \\(y_{pred}\\) vector representing the prediction does not match the \\(y\\) vector which is the “correct” value. Figure 3.5 (b) shows the correct prediction after adjusting the weights and the \\(y_{pred}\\) vector now matches the \\(y\\) vector.\n\n\n\n\n3.5.1 Applications in Healthcare\nIn medical contexts, word embeddings can capture similar nuances. For example:\n\nMedical Conditions: Words like “diabetes” and “insulin” might cluster closely together because they frequently co-occur in medical texts.\nDrug-Condition Relationships: Embeddings might place medications and their corresponding conditions near each other, such as “metformin” and “diabetes.”\nSemantic Analogies: Embeddings could capture analogies such as “insulin is to diabetes as chemotherapy is to cancer.”\n\nVisualizing embeddings in medical text could help identify clinically relevant clusters, group patients with similar conditions, or even highlight previously unknown associations between treatments and conditions.\nIn an embedding space, similar words are closer together. For example, in a model trained on medical notes, the words “diabetes” and “insulin” might be closer to each other than “diabetes” and “antibiotic.”",
    "crumbs": [
      "Natural Language Processing",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Word Embeddings and Representation in Text</span>"
    ]
  },
  {
    "objectID": "nlp-section/word-embeddings.html#why-word-embeddings-are-powerful-for-medical-text",
    "href": "nlp-section/word-embeddings.html#why-word-embeddings-are-powerful-for-medical-text",
    "title": "3  Word Embeddings and Representation in Text",
    "section": "3.6 Why Word Embeddings Are Powerful for Medical Text",
    "text": "3.6 Why Word Embeddings Are Powerful for Medical Text\nThe power of word embeddings lies in their ability to capture both semantic similarity and relationships between terms. Some key benefits include:\n\nContextual Relationships: Embeddings capture the relationships between words based on the context they appear in. For instance, embeddings might learn that “heart attack” is more related to “chest pain” than to “headache.”\nTransfer Learning: Once embeddings are trained on a large dataset, they can be transferred to other tasks. This is particularly useful in medicine, where labeled datasets are often scarce.\nReduced Dimensionality: Instead of having thousands of word features (as in BoW or TF-IDF), word embeddings map words into a continuous vector space of, say, 300 dimensions, significantly reducing computational complexity.",
    "crumbs": [
      "Natural Language Processing",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Word Embeddings and Representation in Text</span>"
    ]
  },
  {
    "objectID": "nlp-section/word-embeddings.html#applications-of-word-embeddings-in-healthcare",
    "href": "nlp-section/word-embeddings.html#applications-of-word-embeddings-in-healthcare",
    "title": "3  Word Embeddings and Representation in Text",
    "section": "3.7 Applications of Word Embeddings in Healthcare",
    "text": "3.7 Applications of Word Embeddings in Healthcare\nWord embeddings have broad applications in healthcare, ranging from clinical note processing to biomedical literature mining.",
    "crumbs": [
      "Natural Language Processing",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Word Embeddings and Representation in Text</span>"
    ]
  },
  {
    "objectID": "nlp-section/word-embeddings.html#challenges-and-considerations",
    "href": "nlp-section/word-embeddings.html#challenges-and-considerations",
    "title": "3  Word Embeddings and Representation in Text",
    "section": "3.8 Challenges and Considerations",
    "text": "3.8 Challenges and Considerations\nWhile word embeddings are powerful, they are not without limitations, particularly in the medical context.\n\nData Quality: Embeddings reflect the biases of the text they are trained on. Incomplete or biased data (e.g., underrepresentation of minority groups in medical datasets) may lead to biased embeddings.\nOut-of-Vocabulary Words: Traditional embeddings struggle with out-of-vocabulary (OOV) words, such as rare medical terms or abbreviations not present in the training data. This is addressed by newer models like fastText, which breaks words into subword units.\nInterpretability: The embedding space is often not human-interpretable. We can visualize relationships between terms, but it is difficult to explain why certain words cluster together beyond their proximity in the vector space.",
    "crumbs": [
      "Natural Language Processing",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Word Embeddings and Representation in Text</span>"
    ]
  },
  {
    "objectID": "nlp-section/word-embeddings.html#conclusion",
    "href": "nlp-section/word-embeddings.html#conclusion",
    "title": "3  Word Embeddings and Representation in Text",
    "section": "3.9 Conclusion",
    "text": "3.9 Conclusion\nWord embeddings revolutionized how text is represented in machine learning models, particularly in complex domains like healthcare. By capturing both syntactic and semantic relationships between words, embeddings allow for more effective processing of clinical texts, patient records, and biomedical literature.\nIn the next chapter, we will delve into how more advanced architectures, like recurrent neural networks, build on the foundation of word embeddings to handle sequential data, setting the stage for even more powerful models like transformers and large language models.",
    "crumbs": [
      "Natural Language Processing",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Word Embeddings and Representation in Text</span>"
    ]
  },
  {
    "objectID": "nlp-section/word-embeddings.html#exercises",
    "href": "nlp-section/word-embeddings.html#exercises",
    "title": "3  Word Embeddings and Representation in Text",
    "section": "3.10 Exercises",
    "text": "3.10 Exercises\n\n3.10.1 TensorFlow Embedding Projector\nThe TensorFlow Embedding Projector is a web-based tool that allows you to visualize word embeddings in a 3D space. You can use it to explore the relationships between words and see how they are clustered together. Navigate to the TensorFlow Embedding Projector and experiment a bit.\n\nBy mousing over the points in the 3D space, you can see the words that are closest to a given word. You can also search for a specific word and see how it is related to other words in the space. If you click on a word, you can see a list of the words that are closest to it (based on cosine similarity in the embedding space, not necessarily in the 2D projection).\n\n\n3.10.2 Word Embedding Visualization\nIn this exercise, you can play with a really cool interactive word embedding visualization tool. The tool allows you to explore word embeddings in a 2D space and see how words are related to each other.\nFirst, watch the video below to see how the tool works:\n\n\nNavigate to the word2viz website.\nExplore the controls and inputs on the right.\nPLAY!\n\n\n\n3.10.3 [Optional] Playing with Word Embeddings in Python\nIn this exercise, you will use the gensim library to load pre-trained word embeddings and explore the relationships between words. Gensim is a popular library for working with word embeddings and provides an easy way to load pre-trained models or to train your own embeddings!\nFirst, you need to install the gensim library if you haven’t already. You can do this using pip:\npip install gensim\nNext, you can use the following code to load a pre-trained word embedding model and explore the relationships between words.\n\nimport gensim.downloader as api\n\n# Download a pre-trained word embedding model (if not already downloaded)\nmodel = api.load(\"glove-wiki-gigaword-50\")\n\nThe model object is now a word embedding model that you can use to get word vectors and find similar words. Someone else has trained the model already. Here are a few things you can do with the model:\n\n# Get the word embedding vector for a word\nword = \"king\"\nvector = model[word]\nprint(f\"Word embedding for '{word}': {vector}\")\n\nWord embedding for 'king': [ 0.50451   0.68607  -0.59517  -0.022801  0.60046  -0.13498  -0.08813\n  0.47377  -0.61798  -0.31012  -0.076666  1.493    -0.034189 -0.98173\n  0.68229   0.81722  -0.51874  -0.31503  -0.55809   0.66421   0.1961\n -0.13495  -0.11476  -0.30344   0.41177  -2.223    -1.0756   -1.0783\n -0.34354   0.33505   1.9927   -0.04234  -0.64319   0.71125   0.49159\n  0.16754   0.34344  -0.25663  -0.8523    0.1661    0.40102   1.1685\n -1.0137   -0.21585  -0.15155   0.78321  -0.91241  -1.6106   -0.64426\n -0.51042 ]\n\n\nThe vector variable now contains the word embedding for the word “king.” You can use this to find similar words or perform vector arithmetic. Here’s an example:\n\n# Find similar words\nsimilar_words = model.most_similar(word, topn=5)\n\n# Display similar words and their similarity scores\nprint(f\"Words similar to '{word}':\")\nfor similar_word, score in similar_words:\n    print(f\"    {similar_word}: {score}\")\n\nWords similar to 'king':\n    prince: 0.8236179351806641\n    queen: 0.7839044332504272\n    ii: 0.7746230363845825\n    emperor: 0.7736247777938843\n    son: 0.766719400882721\n\n\nYou can also perform vector arithmetic to find relationships between words. Coming back to our earlier example of the king-queen analogy, you can use the word embeddings to find the word that completes the analogy “Man is to king as woman is to ___.”\n\n# Perform vector arithmetic\nresult = model.most_similar(positive=[\"king\", \"woman\"], negative=[\"man\"], topn=1)\nprint(f\"King + Woman - Man = {result}\")\n\nKing + Woman - Man = [('queen', 0.8523604273796082)]\n\n\nFor those who want to try this themselves, I’ve created a Google Colab notebook that you can use to experiment with word embeddings in Python.\nYou can watch this short video to see how to use the notebook:",
    "crumbs": [
      "Natural Language Processing",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Word Embeddings and Representation in Text</span>"
    ]
  },
  {
    "objectID": "nlp-section/word-embeddings.html#references",
    "href": "nlp-section/word-embeddings.html#references",
    "title": "3  Word Embeddings and Representation in Text",
    "section": "References",
    "text": "References\n\n\n\n\nBojanowski, Piotr, Edouard Grave, Armand Joulin, and Tomas Mikolov. 2017. “Enriching Word Vectors with Subword Information.” arXiv. https://doi.org/10.48550/arXiv.1607.04606.\n\n\nMikolov, Tomas, Kai Chen, Greg Corrado, and Jeffrey Dean. 2013. “Efficient Estimation of Word Representations in Vector Space.” arXiv. https://doi.org/10.48550/arXiv.1301.3781.\n\n\nPennington, Jeffrey, Richard Socher, and Christopher Manning. 2014. “GloVe: Global Vectors for Word Representation.” In Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP), edited by Alessandro Moschitti, Bo Pang, and Walter Daelemans, 1532–43. Doha, Qatar: Association for Computational Linguistics. https://doi.org/10.3115/v1/D14-1162.",
    "crumbs": [
      "Natural Language Processing",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Word Embeddings and Representation in Text</span>"
    ]
  },
  {
    "objectID": "nlp-section/llms.html",
    "href": "nlp-section/llms.html",
    "title": "4  Transition to Large Language Models",
    "section": "",
    "text": "4.1 Introduction: From Word Embeddings to Context-Aware Models\nWord embeddings, such as Word2Vec and GloVe, marked a significant step forward in NLP by representing words as continuous vectors in a high-dimensional space. These embeddings allowed models to capture semantic relationships between words based on their co-occurrence in large corpora. For instance, the famous relationship between “king” and “queen” being similar to “man” and “woman” Figure 3.3 became a canonical example of how word vectors capture analogies.\nHowever, static word embeddings like Word2Vec have a key limitation: they assign each word a single vector, regardless of context. For example, the word “bank” will have the same vector whether we are talking about a financial institution or the side of a river. This one-size-fits-all representation struggles with polysemy (multiple meanings of a word) and fails to incorporate the dynamic context in which a word appears.\nThis limitation set the stage for context-aware models—first through innovations like ELMo (Embeddings from Language Models), which introduced context-dependent embeddings, and later through the transformer architecture, which powers today’s LLMs.",
    "crumbs": [
      "Natural Language Processing",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Transition to Large Language Models</span>"
    ]
  },
  {
    "objectID": "nlp-section/llms.html#transformers-the-foundation-of-large-language-models",
    "href": "nlp-section/llms.html#transformers-the-foundation-of-large-language-models",
    "title": "4  Transition to Large Language Models",
    "section": "4.2 Transformers: The Foundation of Large Language Models",
    "text": "4.2 Transformers: The Foundation of Large Language Models\nThe transformer architecture, introduced by (Vaswani et al. 2017), represents a paradigm shift in NLP. Unlike earlier recurrent neural networks (RNNs), transformers do not process data sequentially. Instead, they operate on entire sequences of words (or tokens) at once, making them highly parallelizable and more efficient for training on large datasets.\nAt the heart of transformers is the attention mechanism. Attention allows the model to focus on relevant parts of the input sequence while processing a word. This capability enables transformers to capture long-range dependencies and relationships between words more effectively than RNNs or convolutional neural networks (CNNs).\nThe input to a transformer is typically a sequence of word embeddings, which are passed through multiple layers of encoders. Each encoder consists of two main components: a self-attention mechanism and a feed-forward neural network. The self-attention mechanism helps the model weigh the importance of different words in the sequence, while the feed-forward network processes this information to generate the final output. Remember that one of the shortcomings of word embeddings is that they do not capture context; each word has one-and-only-one embedding vector. Transformers address this by considering the entire sequence when encoding a word.\nFigure 4.1 shows how the attention mechanism helps the model understand the context of a word in a sentence. The encoding of the word “it” in the sentence “The animal didn’t cross the street because it was too tired” is influenced by the attention mechanism, which focuses on “The Animal” to understand the referent of “it”.\n\n\n\n\n\n\nFigure 4.1: Attention: As we are encoding the word “it” in encoder #5 (the top encoder in the stack), part of the attention mechanism was focusing on “The Animal”, and baked a part of its representation into the encoding of “it”.\n\n\n\nFigure 2: Example of attention mechanism highlighting key word dependencies within a sentence.\nThe architecture of transformers consists of an encoder and a decoder. While the original transformer model was designed for sequence-to-sequence tasks like translation, recent advancements focus on pre-training the encoder (in models like BERT) or both encoder and decoder (in models like GPT). These models, known as large language models, can be fine-tuned for various downstream tasks, including text generation, question answering, and summarization.\nAgain, one of the key innovations in transformers is the concept of self-attention, which allows the model to weigh the importance of different words in a sentence when encoding a particular word. In transformers, this process is done in parallel for multiple attention heads, leading to the concept of multi-head attention. Multi-head attention enables the model to focus on different aspects of a sentence simultaneously. While one head might focus on syntactic structure (such as subject-verb agreement), another might capture semantic relationships (like identifying the recipient of an action).\nTable 1 below summarizes the advantages of self-attention and multi-head attention compared to previous methods like RNNs and CNNs:\nTable 1: Advantages of Self-Attention and Multi-Head Attention\n\n\n\n\n\n\n\n\nFeature\nRNNs / CNNs\nTransformers (Self-Attention)\n\n\n\n\nSequential Processing\nYes (slower, non-parallel)\nNo (parallel processing of entire input)\n\n\nCapturing Long-Range Dependencies\nLimited (vanishing gradients)\nEfficiently captures distant relationships\n\n\nContextual Understanding\nLimited to fixed window\nFull sequence considered for each word\n\n\nTraining Efficiency\nSlower due to sequence dependencies\nHighly efficient (leverages parallelism)",
    "crumbs": [
      "Natural Language Processing",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Transition to Large Language Models</span>"
    ]
  },
  {
    "objectID": "nlp-section/llms.html#scaling-up-large-language-models-llms-like-gpt-and-bert",
    "href": "nlp-section/llms.html#scaling-up-large-language-models-llms-like-gpt-and-bert",
    "title": "4  Transition to Large Language Models",
    "section": "4.3 Scaling Up: Large Language Models (LLMs) like GPT and BERT",
    "text": "4.3 Scaling Up: Large Language Models (LLMs) like GPT and BERT\nTransformers provided the foundation for large language models (LLMs), but what distinguishes LLMs from smaller models is their sheer size. LLMs such as OpenAI’s GPT (Generative Pre-trained Transformer) and Google’s BERT (Bidirectional Encoder Representations from Transformers) are trained on massive corpora of text, often with billions or even trillions of parameters. This enables them to generalize across a wide variety of NLP tasks.\nGPT models, for example, are designed for text generation tasks, while BERT models are pre-trained for bidirectional understanding of language. BERT’s bidirectional nature allows it to capture context from both left and right contexts, making it particularly effective for tasks like question answering and text classification.\nWhen discussing the process of building and refining large language models (LLMs), it’s crucial to understand the progression from pre-training to fine-tuning and instruction tuning. These phases build upon each other, and all rely on the powerful principle of transfer learning.\n\n4.3.1 Pre-training: Learning General Knowledge from Large Datasets\nThe first step in developing a large language model is pre-training. In this phase, the model is trained on vast amounts of diverse text data from the internet—news articles, books, websites, social media posts, etc. The goal is for the model to learn general patterns in language: grammar, sentence structure, and relationships between words.\nDuring pre-training, the model is not explicitly trained to perform any specific task (such as answering questions or translating text). Instead, it learns by predicting the next word in a sentence (a common objective known as masked language modeling or causal language modeling). This helps the model build a broad, high-level understanding of how language works.\n\nExample: If the model is given the sentence, “The cat is sitting on the ___,” it learns to predict that “mat” or “sofa” might be appropriate completions based on what it has seen in similar contexts during training.\n\nBy the end of this phase, the model has developed a deep, though general, understanding of language, but it hasn’t yet been specialized for any particular task.\n\n\n4.3.2 Fine-tuning: Specializing for Specific Tasks\nThe fine-tuning phase builds on the knowledge gained during pre-training. Here, the model is trained on smaller, task-specific datasets to specialize in a particular task, such as medical diagnosis, summarization, or chatbot responses.\nIn this stage, transfer learning is applied. The general language understanding developed during pre-training is transferred to the new task, allowing the model to adapt quickly with much less data than would otherwise be required. Fine-tuning modifies the model slightly to better fit the specific needs of the task, but it doesn’t start from scratch. Instead, the model reuses and adapts what it already knows.\n\nExample: Suppose a pre-trained model is fine-tuned for medical language. During fine-tuning, it adapts its broad language knowledge to better understand medical terminology, patient reports, and clinical guidelines. This allows the model to assist healthcare professionals more effectively in tasks like summarizing patient history or answering medical queries.\n\nThe use of transfer learning means that the model can generalize well from smaller datasets, because it leverages the vast amount of language knowledge it has already acquired during pre-training.\n\n\n4.3.3 Instruction Tuning: Adapting to Follow Human Instructions\nInstruction tuning is a refinement of fine-tuning where the model is trained to follow structured, task-specific human instructions. In this phase, the model is provided with examples of how humans give instructions and what the desired outcomes should look like.\nTransfer learning plays a role here too—again, the model is building upon the language patterns learned during pre-training, and it adapts those patterns to better understand and respond to human commands.\n\nExample: A model might be given a prompt like, “Summarize this article in two sentences” or “Translate this sentence to French.” During instruction tuning, it learns how to execute these specific requests more effectively.\n\nBy the end of instruction tuning, the model becomes more user-friendly and better at handling structured, goal-oriented tasks. This is the stage where models begin to behave more like assistants that can respond coherently to specific requests from users.\n\n\n4.3.4 The Role of Transfer Learning: The Key Underlying Principle\nTransfer learning is the foundation that makes the transition from pre-training to fine-tuning and instruction tuning possible. It enables the model to transfer its general knowledge from the pre-training phase to the more specialized tasks it encounters during fine-tuning and instruction tuning. This is why transfer learning is considered a key advantage of LLMs—without it, each task would require training a model from scratch, which would be computationally expensive and data-intensive.\nIn simpler terms, transfer learning is the reason why a model trained on large, general datasets can still perform well on specific tasks with relatively small amounts of data. It’s not a separate step but rather a fundamental property that makes fine-tuning and instruction tuning both efficient and effective.\nThis version emphasizes the flow of how transfer learning operates across the stages, clarifying that it is the mechanism enabling these transitions, rather than a separate part of the model-building process. Let me know if this works for you or if you’d like further adjustments!",
    "crumbs": [
      "Natural Language Processing",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Transition to Large Language Models</span>"
    ]
  },
  {
    "objectID": "nlp-section/llms.html#llms-in-the-wild",
    "href": "nlp-section/llms.html#llms-in-the-wild",
    "title": "4  Transition to Large Language Models",
    "section": "4.4 LLMs in the wild",
    "text": "4.4 LLMs in the wild\nWhile most folks are familiar with ChatGPT, there are many other LLMs that are available for us (See Table 4.1). Many of the commercially available LLMs have a “free-tier” that allows for everyday use. In addition to very large models like ChatGPT, there are smaller models that, in many cases, are more than sufficient for many tasks, are more cost-effective, are faster to run, and are more energy-efficient.\n\n\n\n\n\n\nModel Name\nLink\n\n\n\n\nChatGPT\nLink\n\n\nClaude\nLink\n\n\nGemini\nLink\n\n\nHuggingChat\nLink\n\n\nMicrosoft Copilot\nLink\n\n\ngroq\nLink\n\n\n\n\n\nTable 4.1: A selection of large language models (LLMs) available for use, including ChatGPT, Claude, Gemini, HuggingChat, Microsoft Copilot, and groq.",
    "crumbs": [
      "Natural Language Processing",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Transition to Large Language Models</span>"
    ]
  },
  {
    "objectID": "nlp-section/llms.html#applications-of-llms-in-healthcare-a-revolution-in-nlp",
    "href": "nlp-section/llms.html#applications-of-llms-in-healthcare-a-revolution-in-nlp",
    "title": "4  Transition to Large Language Models",
    "section": "4.5 Applications of LLMs in Healthcare: A Revolution in NLP",
    "text": "4.5 Applications of LLMs in Healthcare: A Revolution in NLP\nThis section is structured as an abbreviated literature review, highlighting key studies and findings in the field of healthcare NLP. It showcases the transformative impact of large language models (LLMs) like GPT and BERT on various healthcare applications, including clinical documentation, medical imaging, and patient care.\nIn this short review by Shah, Entwistle, and Pfeffer (2023), the authors observe that LLMs are being adopted in healthcare, but often without proper evaluation and focus on the goals and the extent to which LLMs reach them. They propose that instead of asking “New users have been asking how the LLMs and the chatbots powered by them will reshape medicine,” we should be asking “How can the intended medical use shape the training of the LLMs and the chatbots or the other applications they power?”\nIn what is now considered a seminal paper, Ayers et al. (2023) compared the responses of physicians and AI chatbots to patient questions sourced from Reddit’s r/AskDocs. Table 4.2 summarizes the key findings of this cross-sectional study, highlighting the advantages of chatbot responses in terms of length, quality of information, and empathy.\n\n\n\n\n\n\n\n\n\n\n\n\nMeasure\nPhysicians\nChatbot\nStatistical Significance\n\n\n\n\nEvaluator Preference\nPreferred in 21.4% (95% CI, 18.2%-25.0%)\nPreferred in 78.6% (95% CI, 75.0%-81.8%)\n-\n\n\nResponse Length (mean words)\n52 (IQR 17-62)\n211 (IQR 168-245)\nt = 25.4, P &lt; .001\n\n\nQuality of Information (mean score)\nSignificantly lower (22.1% rated as good or very good, 95% CI, 16.4%-28.2%)\nSignificantly higher (78.5% rated as good or very good, 95% CI, 72.3%-84.1%)\nt = 13.3, P &lt; .001\n\n\nEmpathy of Responses (mean score)\n4.6% rated empathetic or very empathetic (95% CI, 2.1%-7.7%)\n45.1% rated empathetic or very empathetic (95% CI, 38.5%-51.8%)\nt = 18.9, P &lt; .001\n\n\n\n\n\nTable 4.2: Summary of findings from a cross-sectional study comparing chatbot (ChatGPT) and physician responses to patient questions sourced from Reddit’s r/AskDocs. Evaluators significantly favored chatbot responses, which were longer, rated as higher quality, and more empathetic. This suggests AI chatbots may be useful for drafting patient responses, potentially reducing clinician workload and improving patient engagement. Future research, including randomized trials, is warranted to explore AI’s role in enhancing clinical care and reducing physician burnout.\n\n\n\nAn extensive review of research about and use of LLMs in healthcare by Lu et al. (2024) provides a comprehensive summary of the Journal of the American Medical Informatics Association (JAMIA) special issue on LLMs in healthcare. The review covers a wide range of topics, including the use of LLMs in clinical documentation, medical imaging, patient care, and more. Figure 4.2 visualizes the various LLMs discussed in the special issue.\n\n\n\n\n\n\nFigure 4.2: LLMs used in the special issue of JAMIA [^]\n\n\n\nIntegrating LLMs into healthcare settings has a lot of potential, but doing so is hard. Labkoff et al. (2024) “aims to make practical suggestions for creating methods, rules, and guidelines to ensure that the development, testing, supervision, and use of AI in clinical decision support (CDS) systems are done well and safely for patients.” The authors suggest four key recommendations for doing so (Labkoff et al. 2024).\n\nBuilding safe and trustworthy systems;\nDeveloping validation, verification, and certification processes for AI-CDS systems;\nProviding a means of safety monitoring and reporting at the national level; and\nEnsuring that appropriate documentation and end-user training are provided.\n\nThe paper is packed with practical advice and insights for healthcare professionals and AI developers looking to integrate LLMs into clinical practice.\nThe status of public comfort with the use of ChatGPT in healthcare was evaluated by Platt et al. (2024).\nA group of investigators has been collaborating to produce and inroduce a CLinical Artificial Intelligence Checklist (MI-CLAIM-GEN) for reporting information about a generative model (Miao et al. 2024). The checklist is designed to help developers and users of generative models understand the model’s development, intended use, performance, limitations, and recommendations for safe deployment. The checklist is intended to improve transparency and trust in the use of generative models in clinical settings. An example of a suggested clinical model card is shown in Figure 4.3.\n\n\n\n\n\n\n\n\nFigure 4.3: An example model card as proposed by Miao et al. (2024), formatted as a clinical “model facts” label, for a fictional model created to assist in clinical decision support around sepsis diagnosis and management. The clinical model card should provide a summary of how a model was developed, intended use, out-of-scope uses, performance, limitations, and recommendations for safe deployment.\n\n\n\nNumerous collections of high-quality, highly-cited work that includes LLMs in healthcare and biomedical research are available and highlighted in Table 4.3.\n\n\n\n\n\n\nCollection\nDescription\n\n\n\n\nJAMIA Special Issue\nA collection of research articles on LLMs in healthcare\n\n\nJAMA Network AI Collection\nA series of articles on AI in healthcare from JAMA Network\n\n\nNature AI Collection\nA curated selection of AI research in medicine from Nature Portfolio\n\n\n\n\n\nTable 4.3: Collections of research articles on AI and LLMs in healthcare from leading journals and publishers.",
    "crumbs": [
      "Natural Language Processing",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Transition to Large Language Models</span>"
    ]
  },
  {
    "objectID": "nlp-section/llms.html#an-aside-foundation-models-as-the-base-for-diverse-applications",
    "href": "nlp-section/llms.html#an-aside-foundation-models-as-the-base-for-diverse-applications",
    "title": "4  Transition to Large Language Models",
    "section": "4.6 An aside: Foundation Models as the Base for Diverse Applications",
    "text": "4.6 An aside: Foundation Models as the Base for Diverse Applications\nA foundation model refers to a large, pre-trained model that serves as a general-purpose starting point for a wide range of downstream tasks. These models are typically trained on massive datasets using self-supervised learning techniques, allowing them to capture a broad and versatile understanding of the data, such as language or images. Once trained, foundation models can be fine-tuned or adapted for specific tasks, like translation, summarization, or image recognition, through additional, smaller-scale training phases.\nThe term is often used in the context of large-scale machine learning models like GPT (Generative Pre-trained Transformers) and BERT (Bidirectional Encoder Representations from Transformers) in natural language processing (NLP), or models like CLIP and DALL-E for vision tasks. These models can be thought of as foundational because they provide a base of knowledge that can be reused and customized for numerous applications.\n\n4.6.1 Key Characteristics of Foundation Models:\n\nPre-trained on Massive Datasets: Foundation models are typically pre-trained on vast amounts of unlabeled data, such as text scraped from the web or millions of images, enabling them to learn patterns and representations that generalize across domains.\nSelf-supervised Learning: Pre-training often uses self-supervised learning techniques, where the model learns to predict parts of the input (e.g., predicting the next word in a sentence) without requiring labeled data. This enables the model to scale to very large datasets.\nVersatility: Because they are trained to capture general patterns in the data, foundation models can be fine-tuned or adapted for a wide range of tasks with relatively little task-specific data. For example, a foundation language model can be fine-tuned for tasks like question answering, summarization, or even medical diagnosis with only a modest amount of new data for each specific task.\nTransfer Learning: Foundation models are excellent at leveraging transfer learning, meaning that the knowledge they acquire during pre-training is transferable to new tasks with minimal additional training. This reduces the need for training a new model from scratch for each task.\nScalability: The term “foundation” highlights how these models serve as a scalable base for many different applications. Once the initial model is pre-trained, it can be fine-tuned for different domains, such as legal text, scientific literature, or medical data, without needing to retrain the entire model from scratch.\nGeneralization across Modalities: Some foundation models, such as CLIP, operate across different data types (e.g., images and text), allowing them to generalize across modalities, making them highly adaptable for diverse use cases.\n\n\n\n4.6.2 Why the Term “Foundation Model” Is Important\nThe significance of foundation models lies in their ability to democratize machine learning development. Instead of requiring each new application to build a model from scratch, developers can use these pre-trained models as a starting point, saving time, computational resources, and data. This shift allows for the rapid deployment of models in a wide variety of fields, from healthcare to finance to creative industries.\nFor example: - GPT-3, a foundation model for natural language processing, can be adapted to answer questions, write essays, or even generate programming code. - BERT has been used as the foundation for various NLP tasks, such as named entity recognition, text classification, and sentiment analysis. - CLIP combines text and images to provide capabilities such as image-text matching, zero-shot classification, and creative image generation.\n\n\n4.6.3 Example: GPT as a Foundation Model\nConsider GPT-3, one of the most well-known foundation models in NLP. GPT-3 was trained on a diverse range of text data from the internet, giving it a broad understanding of language patterns and general knowledge. After pre-training, GPT-3 can be fine-tuned or adapted to various tasks—whether it’s answering customer support questions, translating text between languages, or generating creative content. The key is that GPT-3 doesn’t need to be retrained from scratch for every new task; its “foundational” understanding of language can be reused and adapted.\n\n\n4.6.4 Challenges and Considerations\nWhile foundation models have opened up numerous possibilities, there are also challenges associated with them: - Bias: Since foundation models are trained on vast and uncurated datasets, they often inherit biases present in the data (e.g., gender, racial, or societal biases). Fine-tuning can help reduce these biases, but they remain a significant concern. - Compute and Energy Costs: Pre-training foundation models requires enormous computational resources, and the environmental impact of training such large models is a growing area of concern. - Overfitting to the Internet’s Text: Pre-trained foundation models may overfit to the types of data they were exposed to during training (often text from the internet) and may struggle with highly specialized domains without substantial fine-tuning.\n\n\n4.6.5 In Summary\nA foundation model is a large, pre-trained machine learning model that serves as a versatile base for a wide variety of downstream tasks. It leverages transfer learning to apply the broad patterns it learned during pre-training to specific tasks with relatively little additional data. While they offer powerful capabilities, foundation models also pose challenges related to bias, resource requirements, and task-specific adaptation.",
    "crumbs": [
      "Natural Language Processing",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Transition to Large Language Models</span>"
    ]
  },
  {
    "objectID": "nlp-section/llms.html#conclusion",
    "href": "nlp-section/llms.html#conclusion",
    "title": "4  Transition to Large Language Models",
    "section": "4.7 Conclusion",
    "text": "4.7 Conclusion\nThe transition to large language models (LLMs) based on transformer architectures has significantly advanced the field of natural language processing. By moving beyond static word embeddings to context-aware models, LLMs like GPT and BERT have demonstrated remarkable capabilities in understanding and generating human language. These models, powered by transfer learning and self-attention mechanisms, have found diverse applications across industries, including healthcare, finance, and creative fields.",
    "crumbs": [
      "Natural Language Processing",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Transition to Large Language Models</span>"
    ]
  },
  {
    "objectID": "nlp-section/llms.html#references",
    "href": "nlp-section/llms.html#references",
    "title": "4  Transition to Large Language Models",
    "section": "References",
    "text": "References\n\n\n\n\nAyers, John W., Adam Poliak, Mark Dredze, Eric C. Leas, Zechariah Zhu, Jessica B. Kelley, Dennis J. Faix, et al. 2023. “Comparing Physician and Artificial Intelligence Chatbot Responses to Patient Questions Posted to a Public Social Media Forum.” JAMA Internal Medicine 183 (6): 589–96. https://doi.org/10.1001/jamainternmed.2023.1838.\n\n\nLabkoff, Steven, Bilikis Oladimeji, Joseph Kannry, Anthony Solomonides, Russell Leftwich, Eileen Koski, Amanda L Joseph, et al. 2024. “Toward a Responsible Future: Recommendations for AI-Enabled Clinical Decision Support.” Journal of the American Medical Informatics Association, September, ocae209. https://doi.org/10.1093/jamia/ocae209.\n\n\nLu, Zhiyong, Yifan Peng, Trevor Cohen, Marzyeh Ghassemi, Chunhua Weng, and Shubo Tian. 2024. “Large Language Models in Biomedicine and Health: Current Research Landscape and Future Directions.” Journal of the American Medical Informatics Association 31 (9): 1801–11. https://doi.org/10.1093/jamia/ocae202.\n\n\nMiao, Brenda Y., Irene Y. Chen, Christopher YK Williams, Jaysón Davidson, Augusto Garcia-Agundez, Shenghuan Sun, Travis Zack, et al. 2024. “The Minimum Information about CLinical Artificial Intelligence Checklist for Generative Modeling Research (MI-CLAIM-GEN).” arXiv. http://arxiv.org/abs/2403.02558.\n\n\nPlatt, Jodyn, Paige Nong, Renée Smiddy, Reema Hamasha, Gloria Carmona Clavijo, Joshua Richardson, and Sharon L R Kardia. 2024. “Public Comfort with the Use of ChatGPT and Expectations for Healthcare.” Journal of the American Medical Informatics Association 31 (9): 1976–82. https://doi.org/10.1093/jamia/ocae164.\n\n\nShah, Nigam H, David Entwistle, and Michael A Pfeffer. 2023. “Creation and Adoption of Large Language Models in Medicine.” JAMA: The Journal of the American Medical Association 330 (9): 866–69. https://doi.org/10.1001/jama.2023.14217.\n\n\nVaswani, Ashish, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N Gomez, Lukasz Kaiser, and Illia Polosukhin. 2017. “Attention Is All You Need.” arXiv [Cs.CL], June. http://arxiv.org/abs/1706.03762.",
    "crumbs": [
      "Natural Language Processing",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Transition to Large Language Models</span>"
    ]
  }
]