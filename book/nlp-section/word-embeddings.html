<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.6.19">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="Sean Davis">

<title>word-embeddings – IDPT-8079: Frontier of AI in Medicine</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { display: inline-block; text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
</style>


<script src="../../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../../site_libs/quarto-search/fuse.min.js"></script>
<script src="../../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../../">
<script src="../../site_libs/quarto-html/quarto.js"></script>
<script src="../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../../site_libs/quarto-html/anchor.min.js"></script>
<link href="../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../site_libs/quarto-html/quarto-syntax-highlighting-018089954d508eae8a473f0b7f0491f0.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../../site_libs/bootstrap/bootstrap-fe4cc245a31873b96c1add286a26fa35.min.css" rel="stylesheet" append-hash="true" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>
<script async="" src="https://www.googletagmanager.com/gtag/js?id=G-KLLV1GCF4E"></script>

<script type="text/javascript">

window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'G-KLLV1GCF4E', { 'anonymize_ip': true});
</script>

  <script src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN") {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

</head>

<body class="nav-fixed">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
    <nav class="navbar navbar-expand-lg " data-bs-theme="dark">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container mx-auto">
    <a class="navbar-brand" href="../../index.html">
    <span class="navbar-title">IDPT-8079: Frontier of AI in Medicine</span>
    </a>
  </div>
            <div id="quarto-search" class="" title="Search"></div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" role="menu" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll me-auto">
  <li class="nav-item">
    <a class="nav-link" href="../../index.html"> 
<span class="menu-text">Home</span></a>
  </li>  
</ul>
          </div> <!-- /navcollapse -->
            <div class="quarto-navbar-tools">
</div>
      </div> <!-- /container-fluid -->
    </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">On this page</h2>
   
  <ul>
  <li><a href="#embedding-people-analogies-in-personality-dimensions" id="toc-embedding-people-analogies-in-personality-dimensions" class="nav-link active" data-scroll-target="#embedding-people-analogies-in-personality-dimensions">Embedding People: Analogies in Personality Dimensions</a></li>
  <li><a href="#word-embeddings-capturing-semantic-relationships" id="toc-word-embeddings-capturing-semantic-relationships" class="nav-link" data-scroll-target="#word-embeddings-capturing-semantic-relationships">Word Embeddings: Capturing Semantic Relationships</a></li>
  <li><a href="#limitations-of-traditional-text-representations" id="toc-limitations-of-traditional-text-representations" class="nav-link" data-scroll-target="#limitations-of-traditional-text-representations">Limitations of Traditional Text Representations</a>
  <ul class="collapse">
  <li><a href="#bag-of-words-and-tf-idf" id="toc-bag-of-words-and-tf-idf" class="nav-link" data-scroll-target="#bag-of-words-and-tf-idf">Bag-of-Words and TF-IDF</a></li>
  <li><a href="#limitations" id="toc-limitations" class="nav-link" data-scroll-target="#limitations">Limitations</a></li>
  </ul></li>
  <li><a href="#what-are-word-embeddings" id="toc-what-are-word-embeddings" class="nav-link" data-scroll-target="#what-are-word-embeddings">What Are Word Embeddings?</a>
  <ul class="collapse">
  <li><a href="#word-embeddings-are-numerical-representations-of-words" id="toc-word-embeddings-are-numerical-representations-of-words" class="nav-link" data-scroll-target="#word-embeddings-are-numerical-representations-of-words">Word embeddings are numerical representations of words</a></li>
  <li><a href="#real-world-example-king-queen-analogy" id="toc-real-world-example-king-queen-analogy" class="nav-link" data-scroll-target="#real-world-example-king-queen-analogy">Real world example: King-Queen Analogy</a></li>
  </ul></li>
  <li><a href="#where-do-word-embeddings-come-from" id="toc-where-do-word-embeddings-come-from" class="nav-link" data-scroll-target="#where-do-word-embeddings-come-from">Where do Word Embeddings Come From?</a>
  <ul class="collapse">
  <li><a href="#applications-in-healthcare" id="toc-applications-in-healthcare" class="nav-link" data-scroll-target="#applications-in-healthcare"><strong>Applications in Healthcare</strong></a></li>
  </ul></li>
  <li><a href="#why-word-embeddings-are-powerful-for-medical-text" id="toc-why-word-embeddings-are-powerful-for-medical-text" class="nav-link" data-scroll-target="#why-word-embeddings-are-powerful-for-medical-text">Why Word Embeddings Are Powerful for Medical Text</a></li>
  <li><a href="#applications-of-word-embeddings-in-healthcare" id="toc-applications-of-word-embeddings-in-healthcare" class="nav-link" data-scroll-target="#applications-of-word-embeddings-in-healthcare">Applications of Word Embeddings in Healthcare</a></li>
  <li><a href="#challenges-and-considerations" id="toc-challenges-and-considerations" class="nav-link" data-scroll-target="#challenges-and-considerations">Challenges and Considerations</a></li>
  <li><a href="#conclusion" id="toc-conclusion" class="nav-link" data-scroll-target="#conclusion">Conclusion</a></li>
  <li><a href="#exercises" id="toc-exercises" class="nav-link" data-scroll-target="#exercises">Exercises</a>
  <ul class="collapse">
  <li><a href="#tp-exercise" id="toc-tp-exercise" class="nav-link" data-scroll-target="#tp-exercise">TensorFlow Embedding Projector</a></li>
  <li><a href="#word-embedding-exercise" id="toc-word-embedding-exercise" class="nav-link" data-scroll-target="#word-embedding-exercise">Word Embedding Visualization</a></li>
  <li><a href="#optional-playing-with-word-embeddings-in-python" id="toc-optional-playing-with-word-embeddings-in-python" class="nav-link" data-scroll-target="#optional-playing-with-word-embeddings-in-python">[Optional] Playing with Word Embeddings in Python</a></li>
  </ul></li>
  <li><a href="#references" id="toc-references" class="nav-link" data-scroll-target="#references">References</a></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content page-columns page-full" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title">Word Embeddings and Representation in Text</h1>
</div>


<div class="quarto-title-meta-author">
  <div class="quarto-title-meta-heading">Author</div>
  <div class="quarto-title-meta-heading">Affiliation</div>
  
    <div class="quarto-title-meta-contents">
    <p class="author"><a href="string">Sean Davis, MD, PhD</a> <a href="mailto:seandavi@gmail.com" class="quarto-title-author-email"><i class="bi bi-envelope"></i></a> <a href="https://orcid.org/0000-0002-8991-6458" class="quarto-title-author-orcid"> <img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABAAAAAQCAYAAAAf8/9hAAAAGXRFWHRTb2Z0d2FyZQBBZG9iZSBJbWFnZVJlYWR5ccllPAAAA2ZpVFh0WE1MOmNvbS5hZG9iZS54bXAAAAAAADw/eHBhY2tldCBiZWdpbj0i77u/IiBpZD0iVzVNME1wQ2VoaUh6cmVTek5UY3prYzlkIj8+IDx4OnhtcG1ldGEgeG1sbnM6eD0iYWRvYmU6bnM6bWV0YS8iIHg6eG1wdGs9IkFkb2JlIFhNUCBDb3JlIDUuMC1jMDYwIDYxLjEzNDc3NywgMjAxMC8wMi8xMi0xNzozMjowMCAgICAgICAgIj4gPHJkZjpSREYgeG1sbnM6cmRmPSJodHRwOi8vd3d3LnczLm9yZy8xOTk5LzAyLzIyLXJkZi1zeW50YXgtbnMjIj4gPHJkZjpEZXNjcmlwdGlvbiByZGY6YWJvdXQ9IiIgeG1sbnM6eG1wTU09Imh0dHA6Ly9ucy5hZG9iZS5jb20veGFwLzEuMC9tbS8iIHhtbG5zOnN0UmVmPSJodHRwOi8vbnMuYWRvYmUuY29tL3hhcC8xLjAvc1R5cGUvUmVzb3VyY2VSZWYjIiB4bWxuczp4bXA9Imh0dHA6Ly9ucy5hZG9iZS5jb20veGFwLzEuMC8iIHhtcE1NOk9yaWdpbmFsRG9jdW1lbnRJRD0ieG1wLmRpZDo1N0NEMjA4MDI1MjA2ODExOTk0QzkzNTEzRjZEQTg1NyIgeG1wTU06RG9jdW1lbnRJRD0ieG1wLmRpZDozM0NDOEJGNEZGNTcxMUUxODdBOEVCODg2RjdCQ0QwOSIgeG1wTU06SW5zdGFuY2VJRD0ieG1wLmlpZDozM0NDOEJGM0ZGNTcxMUUxODdBOEVCODg2RjdCQ0QwOSIgeG1wOkNyZWF0b3JUb29sPSJBZG9iZSBQaG90b3Nob3AgQ1M1IE1hY2ludG9zaCI+IDx4bXBNTTpEZXJpdmVkRnJvbSBzdFJlZjppbnN0YW5jZUlEPSJ4bXAuaWlkOkZDN0YxMTc0MDcyMDY4MTE5NUZFRDc5MUM2MUUwNEREIiBzdFJlZjpkb2N1bWVudElEPSJ4bXAuZGlkOjU3Q0QyMDgwMjUyMDY4MTE5OTRDOTM1MTNGNkRBODU3Ii8+IDwvcmRmOkRlc2NyaXB0aW9uPiA8L3JkZjpSREY+IDwveDp4bXBtZXRhPiA8P3hwYWNrZXQgZW5kPSJyIj8+84NovQAAAR1JREFUeNpiZEADy85ZJgCpeCB2QJM6AMQLo4yOL0AWZETSqACk1gOxAQN+cAGIA4EGPQBxmJA0nwdpjjQ8xqArmczw5tMHXAaALDgP1QMxAGqzAAPxQACqh4ER6uf5MBlkm0X4EGayMfMw/Pr7Bd2gRBZogMFBrv01hisv5jLsv9nLAPIOMnjy8RDDyYctyAbFM2EJbRQw+aAWw/LzVgx7b+cwCHKqMhjJFCBLOzAR6+lXX84xnHjYyqAo5IUizkRCwIENQQckGSDGY4TVgAPEaraQr2a4/24bSuoExcJCfAEJihXkWDj3ZAKy9EJGaEo8T0QSxkjSwORsCAuDQCD+QILmD1A9kECEZgxDaEZhICIzGcIyEyOl2RkgwAAhkmC+eAm0TAAAAABJRU5ErkJggg=="></a></p>
  </div>
  <div class="quarto-title-meta-contents">
        <p class="affiliation">
            <a href="https://medschool.cuanschutz.edu/">
            University of Colarado Anschutz School of Medicine
            </a>
          </p>
      </div>
  </div>

<div class="quarto-title-meta">

      
  
    
  </div>
  


</header>


<div class="callout callout-style-default callout-tip callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Tip
</div>
</div>
<div class="callout-body-container callout-body">
<p>What is the name?</p>
</div>
</div>
<div class="callout callout-style-default callout-warning callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Warning
</div>
</div>
<div class="callout-body-container callout-body">
<p>What is the name?</p>
</div>
</div>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-3-contents" aria-controls="callout-3" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Note
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-3" class="callout-3-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<p>What is the name?</p>
</div>
</div>
</div>
<div class="callout callout-style-default callout-important callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Important
</div>
</div>
<div class="callout-body-container callout-body">
<p>What is the name?</p>
</div>
</div>
<section id="embedding-people-analogies-in-personality-dimensions" class="level2">
<h2 class="anchored" data-anchor-id="embedding-people-analogies-in-personality-dimensions">Embedding People: Analogies in Personality Dimensions</h2>
<p>The HEXACO model of personality structure is a six-dimensional model of human personality that was created by Ashton and Lee and explained in their book, The H Factor of Personality,[1] based on findings from a series of lexical studies involving several European and Asian languages. The six factors, or dimensions, include honesty-humility (H), emotionality (E), extraversion (X), agreeableness (A), conscientiousness (C), and openness to experience (O). Each factor is composed of traits with characteristics indicating high and low levels of the factor. If you’ve ever taken a personality test, you might have encountered these dimensions.</p>
<p>We have three hypothetical colleagues, Jay, Kay, and May. Each has taken a personality test and received scores for two personality dimensions which we’ll call “Dimension 1” and “Dimension 2.” The scores are as shown <a href="#fig-people-embeddings" class="quarto-xref">Figure&nbsp;1</a> depicted graphically in the top left. We can take these scores and represent them as vectors in a two-dimensional space, where each dimension corresponds to one of the personality dimensions as shown in the bottom of <a href="#fig-people-embeddings" class="quarto-xref">Figure&nbsp;1</a>. Using these vectors, we can visualize the relationships between Jay, Kay, and May in this two-dimensional space as shown on the right plot of <a href="#fig-people-embeddings" class="quarto-xref">Figure&nbsp;1</a>.</p>
<div id="fig-people-embeddings" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-people-embeddings-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="../images/people-embeddings-figure.png" class="img-fluid figure-img">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-people-embeddings-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;1: Schematic of three hypothetical embeddings of people. Our embeddings are based on personality “dimensions” represented by two different scores (colored orange and blue).
</figcaption>
</figure>
</div>
<p>The idea of “embedding people” allows us to take abstract concepts like personality traits and represent them in a numerical space. This concept is extended to words in natural language processing, where we represent words as vectors in a high-dimensional space. These word embeddings capture the meaning and relationships between words, allowing us to perform various tasks like sentiment analysis, machine translation, and named entity recognition. Just like with Jay, Kay, and May, words that are similar in meaning are close together in this space.</p>
<p>In the case of personality traits the dimensions are derived from a psychological model, but in the case of word embeddings, the dimensions are learned from large text corpora using models like Word2Vec, GloVe, or fastText. These models learn to represent words in a way that captures their semantic and syntactic relationships based on the context they appear in.</p>
</section>
<section id="word-embeddings-capturing-semantic-relationships" class="level2">
<h2 class="anchored" data-anchor-id="word-embeddings-capturing-semantic-relationships">Word Embeddings: Capturing Semantic Relationships</h2>
<p>Text is one of the most abundant forms of data in healthcare, with sources ranging from electronic health records (EHRs) to published research articles, clinical notes, and even patient-reported outcomes. However, computers don’t understand words as humans do—they require numerical representations of text to analyze, model, and make predictions. The challenge is: how do we represent the meaning of words in a way that captures their context and relationships in a way that machines can understand?</p>
<p>This is where <a href="https://en.wikipedia.org/wiki/Word_embedding">word embeddings</a> come into play. Word embeddings provide a way to represent words as vectors (numerical arrays), capturing semantic relationships and making it possible to apply machine learning models to text. By converting text into embeddings, we open the door to a range of applications, from clinical text mining to predicting patient outcomes based on unstructured medical notes.</p>
<p>This chapter introduces word embeddings and explains how they allow us to map words into a vectors that encode semantic and syntactic meaning. We’ll cover why this is an improvement over older methods, how these embeddings are learned, and how they are used in medical applications.</p>
</section>
<section id="limitations-of-traditional-text-representations" class="level2">
<h2 class="anchored" data-anchor-id="limitations-of-traditional-text-representations">Limitations of Traditional Text Representations</h2>
<p>Before diving into embeddings, let’s briefly review older techniques for representing text. The simplest representations were based on bag-of-words (BoW) models and term frequency-inverse document frequency (TF-IDF) scores.</p>
<section id="bag-of-words-and-tf-idf" class="level3">
<h3 class="anchored" data-anchor-id="bag-of-words-and-tf-idf">Bag-of-Words and TF-IDF</h3>
<ul>
<li><p>Bag-of-words ignores the order of words and represents text based on word occurrences. For example, a clinical note with the text: “Patient experiences chest pain” would be represented simply as <code>["patient", "experiences", "chest", "pain"]</code>. The model doesn’t understand that “chest” and “pain” are related, or that their combination is meaningful.</p></li>
<li><p>TF-IDF refines this by weighing how frequently words appear in a document relative to how common they are across all documents. This addresses the fact that some words are very frequent and not informative, like “the” or “patient.”</p></li>
</ul>
</section>
<section id="limitations" class="level3">
<h3 class="anchored" data-anchor-id="limitations">Limitations</h3>
<ol type="1">
<li>Lack of Context: These methods do not capture word order or semantics. For example, in BoW, the words “chest pain” and “pain in the chest” would be represented the same.</li>
<li>High Dimensionality: BoW and TF-IDF result in large sparse matrices, making it difficult to work with longer documents.</li>
<li>No Concept of Similarity: In these models, words like “doctor” and “physician” are treated as completely independent, despite their similar meanings.</li>
</ol>
<p>This leads us to modern word embeddings, which solve many of these issues.</p>
</section>
</section>
<section id="what-are-word-embeddings" class="level2">
<h2 class="anchored" data-anchor-id="what-are-word-embeddings">What Are Word Embeddings?</h2>
<p>Word embeddings are dense, low-dimensional vector representations of words, where words with similar meanings have similar vector representations. The key idea is that these embeddings capture both the syntactic and semantic properties of words. The most popular models for learning embeddings include Word2Vec <span class="citation" data-cites="mikolovEfficientEstimationWord2013">[@mikolovEfficientEstimationWord2013]</span>, GloVe <span class="citation" data-cites="penningtonGloVeGlobalVectors2014">[@penningtonGloVeGlobalVectors2014]</span>, and fastText <span class="citation" data-cites="bojanowskiEnrichingWordVectors2017">[@bojanowskiEnrichingWordVectors2017]</span>.</p>
<div id="fig-word-embeddings" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-word-embeddings-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="https://journals.plos.org/plosone/article/file?id=10.1371/journal.pone.0231189.g008&amp;type=large" class="img-fluid figure-img">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-word-embeddings-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;2: Linear combinations of dimensions in vector space correlate with the semantic and syntactic roles of the words in the corpus[^1]. For illustration purposes, dimension d1 in the figure has a high positive correlation with living beings. A properly tuned word embedding model will map words with similar semantic or syntactic roles to adjacent regions in vector space. This property can be visualized through dimensionality reduction techniques such as t-SNE or PCA. Cultural concepts are also apparent in vector space as consistent offsets between vector representations of words sharing a particular relationship. For instance, in the bottom right of the figure, the dotted vector represents a gender regularity that goes from masculinity to femininity.
</figcaption>
</figure>
</div>
<p><a href="#fig-word-embeddings" class="quarto-xref">Figure&nbsp;2</a> effectively demonstrates how word embeddings capture the meaning and relationships between words in a numerical space, and how this can be visualized after reducing the dimensionality. Let’s break down each part of the figure to build intuition.</p>
<p>In the left section of the figure, you see word embeddings for seven different words: “dog,” “puppy,” “cat,” “houses,” “man,” “woman,” “king,” and “queen.” Each word is represented as a vector in a seven-dimensional space (d1 to d7), where each number in the row corresponds to a particular dimension in this space.</p>
<p>For example: - <strong>“dog”</strong> is represented as the vector <code>[0.6, 0.9, 0.1, 0.4, -0.7, -0.3, -0.2]</code> - <strong>“cat”</strong> is represented as <code>[0.7, -0.1, 0.4, 0.3, -0.4, -0.1, -0.3]</code></p>
<p>These vectors encode the <strong>meaning</strong> of the words, capturing their relationships to other words in the vocabulary based on the corpus they were trained on.</p>
<section id="word-embeddings-are-numerical-representations-of-words" class="level3">
<h3 class="anchored" data-anchor-id="word-embeddings-are-numerical-representations-of-words">Word embeddings are numerical representations of words</h3>
<p>Each word is represented as a dense vector of real numbers. The dimensions (d1 to d7) don’t have a simple interpretable meaning like “animal” or “emotion,” but the relationships between the vectors capture such nuances. 1. <strong>Similarity and Relationship</strong>: Words that are semantically similar or related (like “dog” and “puppy”) tend to have similar vectors, meaning that in seven-dimensional space, they are near each other. We’ll see how this manifests in the visualization on the right.</p>
<p>The right side of <a href="#fig-word-embeddings" class="quarto-xref">Figure&nbsp;2</a> shows what happens when we reduce the dimensionality of these word embeddings from 7D to 2D (for visualization). Dimensionality reduction techniques like <strong>Principal Component Analysis (PCA)</strong> or <strong>t-SNE</strong> are often used to reduce the complexity of the data while retaining its most important features. Here, reducing from 7 dimensions to 2 allows us to visualize the relationships between the words in 2D space. Note that the actual embeddings are learned in much higher dimensions (e.g., 100 to 300) and that the 2D projection is for visualization purposes only.</p>
<p>In the top-right plot of <a href="#fig-word-embeddings" class="quarto-xref">Figure&nbsp;2</a>, we see the 2D embeddings for “dog,” “puppy,” “cat,” and “houses.”</p>
<p><strong>“Dog”</strong> and <strong>“puppy”</strong> are close together in the embedding space, reflecting their semantic similarity. Both refer to canines, with “puppy” being a younger dog. This proximity in vector space is a hallmark of how embeddings capture semantic similarity. - <strong>“Cat”</strong> is a bit further away, as it represents a different animal, but it is still in proximity, highlighting some shared characteristics between cats and dogs (both are pets/animals). - <strong>“Houses”</strong> is far from all the animal-related words. This makes sense because “houses” is a completely different concept (object vs.&nbsp;animal). The fact that it’s distant in the embedding space highlights that the embeddings successfully differentiate unrelated terms.</p>
<p><a href="#fig-word-embeddings" class="quarto-xref">Figure&nbsp;2</a> is a simplified example, but it captures the essence of how word embeddings work and how they can be visualized in lower dimensions to reveal relationships between words.</p>
</section>
<section id="real-world-example-king-queen-analogy" class="level3">
<h3 class="anchored" data-anchor-id="real-world-example-king-queen-analogy">Real world example: King-Queen Analogy</h3>
<p>In <a href="#fig-king-queen-analogy" class="quarto-xref">Figure&nbsp;3</a>, we see a classic example of how word embeddings capture relationships between words. The figure shows the embeddings a number of words, including “king,” “queen,” “man,” and “woman” in 2D space. The axes have been adjusted to highlight the relationships between these words so that the y-axis represents the <strong>woman–queen</strong> axis representing a sense of royalty. The x-axis, aligned with the <strong>he–she</strong> axis represents a gender dimension.</p>
<div id="fig-king-queen-analogy" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-king-queen-analogy-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="https://p.migdal.pl/blog/2017/01/king-man-woman-queen-why/word2viz-queen.png" class="img-fluid figure-img">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-king-queen-analogy-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;3: GloVE embeddings are the inputs to this 2D plot. The words/points are placed based on their location along the <strong>queen–woman</strong> or royalty axis and the <strong>he–she</strong> or gender axis in the GloVE space.
</figcaption>
</figure>
</div>
<p>An amazing property of word embeddings is that they can capture analogies like “King is to Queen” as “Man is to woman.” This is known as the <strong>king-queen analogy</strong> and is a classic example of how embeddings can encode relationships between words. To use embeddings to solve this analogy, we can perform vector arithmetic. In this case, the vector operation we could use is given in <a href="#eq-king-queen-analogy" class="quarto-xref">Equation&nbsp;1</a>.</p>
<p><span id="eq-king-queen-analogy"><span class="math display">\[\text{vector("king")} - \text{vector("man")} + \text{vector("woman")} \approx \text{vector("queen")} \tag{1}\]</span></span></p>
<p>Here are a few ways of thinking about <a href="#eq-king-queen-analogy" class="quarto-xref">Equation&nbsp;1</a>.</p>
<p>This figure illustrates word embeddings in a 2D space, where the x-axis represents the spectrum from “he” to “she” and the y-axis represents the spectrum from “woman” to “queen”. The famous analogy “king - man + woman = queen” can be intuitively explained using this geometric representation:</p>
<p><strong>Vector representation</strong>:</p>
<ul>
<li><p>In this space, each word is represented as a 2D vector. The position of each word encodes semantic information about gender and royalty/status.</p></li>
<li><p>“king - man”: This subtraction shifts the vector from “king” in the direction opposite to “man”. Geometrically, it moves the point left and slightly down, removing the “maleness” from “king”.</p></li>
<li><p>“+ woman”: Adding “woman” shifts the resulting vector right and down, adding “femaleness”.</p></li>
<li><p>Result ≈ queen: The final position after these operations ends up very close to “queen”.</p></li>
</ul>
<p><strong>Geometric interpretation</strong>:</p>
<ul>
<li>Subtraction (king - man): Imagine drawing a vector from “man” to “king”. This represents the concept of “royalty” independent of gender.</li>
<li>Addition (+ woman): Now apply this “royalty” vector starting from “woman”. It brings you to a point very close to “queen”.</li>
</ul>
<p><strong>Semantic relationships</strong>:</p>
<ul>
<li>“king” is to “man” as “queen” is to “woman”</li>
<li>The difference between “king” and “man” (royalty) is similar to the difference between “queen” and “woman”</li>
<li>“king” and “queen” are at similar heights (y-values), representing similar levels of royalty/status.</li>
<li>“man” and “woman” are at similar heights, but lower than king/queen.</li>
<li>The gender axis (x-axis) separates male and female terms consistently while the royalty axis (y-axis) separates royal titles from less “regal” terms.</li>
</ul>
</section>
</section>
<section id="where-do-word-embeddings-come-from" class="level2 page-columns page-full">
<h2 class="anchored" data-anchor-id="where-do-word-embeddings-come-from">Where do Word Embeddings Come From?</h2>
<p>Word embeddings are learned from large text corpora using models like Word2Vec, GloVe, or fastText. These models are trained to predict words based on their context in the text, capturing the relationships between words in the process.</p>
<p>The word2vec model, developed by Mikolov et al., is one of the most popular methods for learning word embeddings. It comes in two flavors: Continuous Bag of Words (CBOW) and Skip-gram. The skip-gram model is particularly effective at capturing semantic relationships between words. It learns to predict the context words given a target word, effectively learning the embeddings that encode these relationships. <a href="#fig-skipgram" class="quarto-xref">Figure&nbsp;4</a> illustrates how the skip-gram approach applies to a sentence. The model learns to predict the surrounding words given the current word, capturing the context in which words appear.</p>

<div class="no-row-height column-margin column-container"><div class="">
<div id="fig-skipgram" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-skipgram-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="https://tensorflow.org/text/tutorials/images/word2vec_skipgram.png" class="img-fluid figure-img">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-skipgram-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;4: Learning word embeddings using the skip-gram model. Figure from <a href="#fn1" class="footnote-ref" id="fnref1" role="doc-noteref"><sup>1</sup></a>
</figcaption>
</figure>
</div>
</div></div><p>The word2vec architecture consists of a single hidden layer neural network with a softmax output layer. The input to the model is a one-hot encoded vector representing the target word, and the output is a probability distribution over the vocabulary. The model is trained using backpropagation to minimize the loss between the predicted and actual context words. This process results in word embeddings that capture the semantic relationships between words. <a href="#fig-skipgram-backprop" class="quarto-xref">Figure&nbsp;5</a> illustrates how the skip-gram model is trained using backpropagation.</p>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Note
</div>
</div>
<div class="callout-body-container callout-body">
<p>One-hot encoding is a way of representing words as binary vectors, where each word is represented by a vector with a 1 in the position corresponding to the word’s index in the vocabulary and 0s elsewhere. For example, in a “vocabulary” of the six words [“cat”, “hat”, “the”, “in”, “green”, “eggs”], the word “cat” might be represented as <code>[0, 0, 1, 0, 0, 0]</code> and “green” as <code>[0, 0, 0, 1, 0, 0]</code>. Thus, when we want to provide input to our word embedder for training, we supply the first vector for “cat” and for “green” we use the second, and so on. In reality, our “vocabulary” would be much larger, but this is the basic idea.</p>
<p>When a vector consists of mostly zeros, like our one-hot encoding vectors, they are referred to as “sparse.” Word embeddings provide a “dense” representation word embedding vectors do not generally contain zeros. The dense vector for each word is in a lower-dimensional space (typically 100-500 dimensions), capturing semantic relationships more effectively. Another way of thinking of word embeddings is as a “lookup table” that maps the words in the one-hot encoding to continuous vectors.</p>
</div>
</div>
<div id="fig-skipgram-backprop" class="quarto-layout-panel">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-skipgram-backprop-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<div class="quarto-layout-row">
<div class="quarto-layout-cell-subref quarto-layout-cell" data-ref-parent="fig-skipgram-backprop" style="flex-basis: 100.0%;justify-content: flex-start;">
<div id="fig-skipgram-backprop-1" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-subfloat-fig figure">
<div aria-describedby="fig-skipgram-backprop-1-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="skipgram-backprop-1.png" class="img-fluid figure-img" data-ref-parent="fig-skipgram-backprop">
</div>
<figcaption class="quarto-float-caption-bottom quarto-subfloat-caption quarto-subfloat-fig" id="fig-skipgram-backprop-1-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
(a) Model incorrectly predicts neighboring words.
</figcaption>
</figure>
</div>
</div>
</div>
<div class="quarto-layout-row">
<div class="quarto-layout-cell-subref quarto-layout-cell" data-ref-parent="fig-skipgram-backprop" style="flex-basis: 100.0%;justify-content: flex-start;">
<div id="fig-skipgram-backprop-2" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-subfloat-fig figure">
<div aria-describedby="fig-skipgram-backprop-2-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="skipgram-backprop-2.png" class="img-fluid figure-img" data-ref-parent="fig-skipgram-backprop">
</div>
<figcaption class="quarto-float-caption-bottom quarto-subfloat-caption quarto-subfloat-fig" id="fig-skipgram-backprop-2-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
(b) Model has “learned” new weights and now correctly predicts neighboring words.
</figcaption>
</figure>
</div>
</div>
</div>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-skipgram-backprop-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;5: The skip-gram model is trained using backpropagation to minimize the loss between the predicted and actual context words. The diagram illustrates the training process. The goal is to learn weights such that the model can predict correctly that the word “the” comes before “wide” and is followed by the word “road.” <a href="#fig-skipgram-backprop-1" class="quarto-xref">Figure&nbsp;5 (a)</a> demonstrates that the model has made a mistake; we can see that because the <span class="math inline">\(y_{pred}\)</span> vector representing the prediction does not match the <span class="math inline">\(y\)</span> vector which is the “correct” value. <a href="#fig-skipgram-backprop-2" class="quarto-xref">Figure&nbsp;5 (b)</a> shows the correct prediction after adjusting the weights and the <span class="math inline">\(y_{pred}\)</span> vector now matches the <span class="math inline">\(y\)</span> vector.
</figcaption>
</figure>
</div>
<section id="applications-in-healthcare" class="level3">
<h3 class="anchored" data-anchor-id="applications-in-healthcare"><strong>Applications in Healthcare</strong></h3>
<p>In medical contexts, word embeddings can capture similar nuances. For example:</p>
<ul>
<li><strong>Medical Conditions</strong>: Words like “diabetes” and “insulin” might cluster closely together because they frequently co-occur in medical texts.</li>
<li><strong>Drug-Condition Relationships</strong>: Embeddings might place medications and their corresponding conditions near each other, such as “metformin” and “diabetes.”</li>
<li><strong>Semantic Analogies</strong>: Embeddings could capture analogies such as “insulin is to diabetes as chemotherapy is to cancer.”</li>
</ul>
<p>Visualizing embeddings in medical text could help identify clinically relevant clusters, group patients with similar conditions, or even highlight previously unknown associations between treatments and conditions.</p>
<p>In an embedding space, similar words are closer together. For example, in a model trained on medical notes, the words “diabetes” and “insulin” might be closer to each other than “diabetes” and “antibiotic.”</p>
</section>
</section>
<section id="why-word-embeddings-are-powerful-for-medical-text" class="level2">
<h2 class="anchored" data-anchor-id="why-word-embeddings-are-powerful-for-medical-text">Why Word Embeddings Are Powerful for Medical Text</h2>
<p>The power of word embeddings lies in their ability to capture both semantic similarity and relationships between terms. Some key benefits include:</p>
<ol type="1">
<li>Contextual Relationships: Embeddings capture the relationships between words based on the context they appear in. For instance, embeddings might learn that “heart attack” is more related to “chest pain” than to “headache.”</li>
<li>Transfer Learning: Once embeddings are trained on a large dataset, they can be transferred to other tasks. This is particularly useful in medicine, where labeled datasets are often scarce.</li>
<li>Reduced Dimensionality: Instead of having thousands of word features (as in BoW or TF-IDF), word embeddings map words into a continuous vector space of, say, 300 dimensions, significantly reducing computational complexity.</li>
</ol>
<hr>
</section>
<section id="applications-of-word-embeddings-in-healthcare" class="level2">
<h2 class="anchored" data-anchor-id="applications-of-word-embeddings-in-healthcare">Applications of Word Embeddings in Healthcare</h2>
<p>Word embeddings have broad applications in healthcare, ranging from clinical note processing to biomedical literature mining.</p>
</section>
<section id="challenges-and-considerations" class="level2">
<h2 class="anchored" data-anchor-id="challenges-and-considerations">Challenges and Considerations</h2>
<p>While word embeddings are powerful, they are not without limitations, particularly in the medical context.</p>
<ol type="1">
<li>Data Quality: Embeddings reflect the biases of the text they are trained on. Incomplete or biased data (e.g., underrepresentation of minority groups in medical datasets) may lead to biased embeddings.</li>
<li>Out-of-Vocabulary Words: Traditional embeddings struggle with out-of-vocabulary (OOV) words, such as rare medical terms or abbreviations not present in the training data. This is addressed by newer models like fastText, which breaks words into subword units.</li>
<li>Interpretability: The embedding space is often not human-interpretable. We can visualize relationships between terms, but it is difficult to explain why certain words cluster together beyond their proximity in the vector space.</li>
</ol>
</section>
<section id="conclusion" class="level2">
<h2 class="anchored" data-anchor-id="conclusion">Conclusion</h2>
<p>Word embeddings revolutionized how text is represented in machine learning models, particularly in complex domains like healthcare. By capturing both syntactic and semantic relationships between words, embeddings allow for more effective processing of clinical texts, patient records, and biomedical literature.</p>
<p>In the next chapter, we will delve into how more advanced architectures, like recurrent neural networks, build on the foundation of word embeddings to handle sequential data, setting the stage for even more powerful models like transformers and large language models.</p>
</section>
<section id="exercises" class="level2">
<h2 class="anchored" data-anchor-id="exercises">Exercises</h2>
<section id="tp-exercise" class="level3">
<h3 class="anchored" data-anchor-id="tp-exercise">TensorFlow Embedding Projector</h3>
<p>The TensorFlow Embedding Projector is a web-based tool that allows you to visualize word embeddings in a 3D space. You can use it to explore the relationships between words and see how they are clustered together. Navigate to the <a href="http://projector.tensorflow.org/">TensorFlow Embedding Projector</a> and experiment a bit.</p>
<div class="quarto-video ratio ratio-16x9"><iframe data-external="1" src="https://www.youtube.com/embed/t5OXoOgaFWM" title="" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></div>
<p>By mousing over the points in the 3D space, you can see the words that are closest to a given word. You can also search for a specific word and see how it is related to other words in the space. If you click on a word, you can see a list of the words that are closest to it (based on cosine similarity in the embedding space, not necessarily in the 2D projection).</p>
</section>
<section id="word-embedding-exercise" class="level3">
<h3 class="anchored" data-anchor-id="word-embedding-exercise">Word Embedding Visualization</h3>
<p>In this exercise, you can play with a really cool interactive word embedding visualization tool. The tool allows you to explore word embeddings in a 2D space and see how words are related to each other.</p>
<p>First, watch the video below to see how the tool works:</p>
<div class="quarto-video ratio ratio-16x9"><iframe data-external="1" src="https://www.youtube.com/embed/0pCfH1RlNrk" title="" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></div>
<ol type="1">
<li>Navigate to the <a href="https://lamyiowce.github.io/word2viz/">word2viz</a> website.</li>
<li>Explore the controls and inputs on the right.</li>
<li>PLAY!</li>
</ol>
</section>
<section id="optional-playing-with-word-embeddings-in-python" class="level3">
<h3 class="anchored" data-anchor-id="optional-playing-with-word-embeddings-in-python">[Optional] Playing with Word Embeddings in Python</h3>
<p>In this exercise, you will use the <code>gensim</code> library to load pre-trained word embeddings and explore the relationships between words. Gensim is a popular library for working with word embeddings and provides an easy way to load pre-trained models or to train your own embeddings!</p>
<p>First, you need to install the <code>gensim</code> library if you haven’t already. You can do this using <code>pip</code>:</p>
<pre class="{bash}"><code>pip install gensim</code></pre>
<p>Next, you can use the following code to load a pre-trained word embedding model and explore the relationships between words.</p>
<div id="0f9e80af" class="cell" data-execution_count="1">
<div class="sourceCode cell-code" id="cb2"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> gensim.downloader <span class="im">as</span> api</span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-3"><a href="#cb2-3" aria-hidden="true" tabindex="-1"></a><span class="co"># Download a pre-trained word embedding model (if not already downloaded)</span></span>
<span id="cb2-4"><a href="#cb2-4" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> api.load(<span class="st">"glove-wiki-gigaword-50"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>The <code>model</code> object is now a word embedding model that you can use to get word vectors and find similar words. Someone else has trained the model already. Here are a few things you can do with the model:</p>
<div id="e76f8adb" class="cell" data-execution_count="2">
<div class="sourceCode cell-code" id="cb3"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Get the word embedding vector for a word</span></span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a>word <span class="op">=</span> <span class="st">"king"</span></span>
<span id="cb3-3"><a href="#cb3-3" aria-hidden="true" tabindex="-1"></a>vector <span class="op">=</span> model[word]</span>
<span id="cb3-4"><a href="#cb3-4" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Word embedding for '</span><span class="sc">{</span>word<span class="sc">}</span><span class="ss">': </span><span class="sc">{</span>vector<span class="sc">}</span><span class="ss">"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Word embedding for 'king': [ 0.50451   0.68607  -0.59517  -0.022801  0.60046  -0.13498  -0.08813
  0.47377  -0.61798  -0.31012  -0.076666  1.493    -0.034189 -0.98173
  0.68229   0.81722  -0.51874  -0.31503  -0.55809   0.66421   0.1961
 -0.13495  -0.11476  -0.30344   0.41177  -2.223    -1.0756   -1.0783
 -0.34354   0.33505   1.9927   -0.04234  -0.64319   0.71125   0.49159
  0.16754   0.34344  -0.25663  -0.8523    0.1661    0.40102   1.1685
 -1.0137   -0.21585  -0.15155   0.78321  -0.91241  -1.6106   -0.64426
 -0.51042 ]</code></pre>
</div>
</div>
<p>The <code>vector</code> variable now contains the word embedding for the word “king.” You can use this to find similar words or perform vector arithmetic. Here’s an example:</p>
<div id="4e39b24f" class="cell" data-execution_count="3">
<div class="sourceCode cell-code" id="cb5"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Find similar words</span></span>
<span id="cb5-2"><a href="#cb5-2" aria-hidden="true" tabindex="-1"></a>similar_words <span class="op">=</span> model.most_similar(word, topn<span class="op">=</span><span class="dv">5</span>)</span>
<span id="cb5-3"><a href="#cb5-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-4"><a href="#cb5-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Display similar words and their similarity scores</span></span>
<span id="cb5-5"><a href="#cb5-5" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Words similar to '</span><span class="sc">{</span>word<span class="sc">}</span><span class="ss">':"</span>)</span>
<span id="cb5-6"><a href="#cb5-6" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> similar_word, score <span class="kw">in</span> similar_words:</span>
<span id="cb5-7"><a href="#cb5-7" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"    </span><span class="sc">{</span>similar_word<span class="sc">}</span><span class="ss">: </span><span class="sc">{</span>score<span class="sc">}</span><span class="ss">"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Words similar to 'king':
    prince: 0.8236179351806641
    queen: 0.7839044332504272
    ii: 0.7746230363845825
    emperor: 0.7736247777938843
    son: 0.766719400882721</code></pre>
</div>
</div>
<p>You can also perform vector arithmetic to find relationships between words. Coming back to our earlier example of the king-queen analogy, you can use the word embeddings to find the word that completes the analogy “Man is to king as woman is to ___.”</p>
<div id="2553dd5e" class="cell" data-execution_count="4">
<div class="sourceCode cell-code" id="cb7"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Perform vector arithmetic</span></span>
<span id="cb7-2"><a href="#cb7-2" aria-hidden="true" tabindex="-1"></a>result <span class="op">=</span> model.most_similar(positive<span class="op">=</span>[<span class="st">"king"</span>, <span class="st">"woman"</span>], negative<span class="op">=</span>[<span class="st">"man"</span>], topn<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb7-3"><a href="#cb7-3" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"King + Woman - Man = </span><span class="sc">{</span>result<span class="sc">}</span><span class="ss">"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>King + Woman - Man = [('queen', 0.8523604273796082)]</code></pre>
</div>
</div>
<p>For those who want to try this themselves, I’ve created a <a href="https://colab.research.google.com/drive/1agWRlinHR-VEGlNxMtZKEOfTOzWcy_zh?usp=sharing">Google Colab notebook</a> that you can use to experiment with word embeddings in Python.</p>
<p>You can watch this short video to see how to use the notebook:</p>
<div class="quarto-video ratio ratio-16x9"><iframe data-external="1" src="https://www.youtube.com/embed/RLYoEyIHL6A" title="" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></div>
</section>
</section>
<section id="references" class="level2 unnumbered">
<h2 class="unnumbered anchored" data-anchor-id="references">References</h2>


</section>


<div id="quarto-appendix" class="default"><section id="footnotes" class="footnotes footnotes-end-of-document" role="doc-endnotes"><h2 class="anchored quarto-appendix-heading">Footnotes</h2>

<ol>
<li id="fn1"><p>https://www.tensorflow.org/tutorials/text/word2vec<a href="#fnref1" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
</ol>
</section><section class="quarto-appendix-contents" id="quarto-citation"><h2 class="anchored quarto-appendix-heading">Citation</h2><div><div class="quarto-appendix-secondary-label">BibTeX citation:</div><pre class="sourceCode code-with-copy quarto-appendix-bibtex"><code class="sourceCode bibtex">@online{davis,
  author = {Davis, Sean},
  url = {https://seandavi.github.io/IDPT-8079/book/nlp-section/word-embeddings.html},
  langid = {en}
}
</code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre><div class="quarto-appendix-secondary-label">For attribution, please cite this work as:</div><div id="ref-davis" class="csl-entry quarto-appendix-citeas" role="listitem">
Davis, Sean. n.d. <a href="https://seandavi.github.io/IDPT-8079/book/nlp-section/word-embeddings.html">https://seandavi.github.io/IDPT-8079/book/nlp-section/word-embeddings.html</a>.
</div></div></section></div></main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const onCopySuccess = function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  }
  const getTextToCopy = function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
    text: getTextToCopy
  });
  clipboard.on('success', onCopySuccess);
  if (window.document.getElementById('quarto-embedded-source-code-modal')) {
    // For code content inside modals, clipBoardJS needs to be initialized with a container option
    // TODO: Check when it could be a function (https://github.com/zenorocha/clipboard.js/issues/860)
    const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
      text: getTextToCopy,
      container: window.document.getElementById('quarto-embedded-source-code-modal')
    });
    clipboardModal.on('success', onCopySuccess);
  }
    var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
    var mailtoRegex = new RegExp(/^mailto:/);
      var filterRegex = new RegExp("https:\/\/seandavi\.github\.io\/IDPT-8079\/");
    var isInternal = (href) => {
        return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
    }
    // Inspect non-navigation links and adorn them if external
 	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
    for (var i=0; i<links.length; i++) {
      const link = links[i];
      if (!isInternal(link.href)) {
        // undo the damage that might have been done by quarto-nav.js in the case of
        // links that we want to consider external
        if (link.dataset.originalHref !== undefined) {
          link.href = link.dataset.originalHref;
        }
      }
    }
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      if (note) {
        return note.innerHTML;
      } else {
        return "";
      }
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      // TODO in 1.5, we should make sure this works without a callout special case
      if (note.classList.contains("callout")) {
        return note.outerHTML;
      } else {
        return note.innerHTML;
      }
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
</div> <!-- /content -->




</body></html>